(Music)

**Speaker 1:** The Naturalistic Decision Making podcast with Brian Moon and Laura Milletello. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress.

**Speaker 2:** Welcome to the Naturalistic Decision Making podcast. This is Laura Milletello from Applied Decision Science.

**Speaker 3:** And I'm Brian Moon from Peragine Technologies.

**Speaker 2:** Our guest today is David Woods. Over a 40-year career looking at systems of people and technology across the complete range of high-risk settings, David has generated a wide range of ideas, findings, and concepts about cognitive work. These range from models of cognitive work and anomaly response, visual momentum to avoid getting lost in computer displays, brittleness of AI systems, automation surprises, mode awareness and human interaction with automation, how to make intelligent systems team players, laws that govern cognitive work, models of coordination in joint activity, how people adapt to make messy systems work, and the discovery of graceful extensibility as a hard constraint on complex systems and many more. He was part of starting up the fields of cognitive systems engineering, naturalistic decision making, resilience engineering, and has been president of the Human Factor Society and of the Resilience Engineering Association. He's received many awards and advises many national and international organizations. His books include Behind Human Error, Joint Cognitive Systems, and Resilience Engineering. Thanks for joining us today, Dave.

**Speaker 4:** Well, it's a pleasure to be talking with you and Brian, Laura.

**Speaker 2:** Thanks. So, I wanted to go back to the very beginning and ask if you remember the very first paper you ever published and if you tell us about that.

**Speaker 4:** Well, I think uh rather than the very first one, uh which I considered a miracle. Uh, the um uh uh as my wife will tell you, uh when she knew me in graduate school, we I never thought I would ever have anything important enough to say to publish in a paper. Uh, but then uh I got lucky. And this accident called Three Mile Island in Eastern Pennsylvania of a nuclear power plant happened. And that changed the direction uh uh I was headed in and it created an opportunity where what I'd learned about cognition, how the brain work, what I would say now is reverse engineering the brain, um, uh met the real world of complex systems, interdependence, um, uh multiple players, uh disaster, risk, um, uh anomaly response, how do you understand these things and all of a sudden a lot of the microcognition stuff was simultaneously relevant and and incomplete and didn't really make contact with the situations and the technologies and tools and design directions that were possible. So, I mean the real issue was all of the early papers in the early 80s that came out were a miracle. Um, it was lonely. We were writing things uh there were just a few colleagues in uh Pittsburgh at the research center I was at and in Denmark of all places with a group of of brilliant people that had gathered around Jen's Rasmussen. A couple other people and what we were writing, I never thought anyone would publish. This was odd, it was in between the normal categories. It was uh, you know, it made everybody unhappy. It made the emerging area of artificial intelligence unhappy. Cognitive science wanted to do some things that were a little more formal. Uh, it was more cognitive and technology centered than human factors of the time. Uh, it was a kind of systems engineering. Uh, it was dealing with complexity in a way that people weren't ready to deal with. Um, so the that early period was one of uh uh I would say loneliness actually, as we were doing all this interesting stuff, much of which took, you know, four, five, six, seven years to appear in print in various outtings and some of those were obscure book chapters and various things, um to get actual journals to want to do this. There was a renegade journal out of England, um which uh later got it removed its genderist uh origins and became the uh uh Journal of Human Machine uh interaction or International Journal of Human Machine Interaction or Human Machine Studies. Brian again started that an AI/cognitive/human systems person uh out of England and that became our first forum for getting out papers like the original visual momentum and the original, the first paper on cognitive systems engineering, new wine and new bottles.

**Speaker 2:** Uh-huh, yeah, that's a classic. So, so you you you kind of said as a graduate student, you felt like maybe you'd never get published, which I think a lot of graduate students feel like. And then you very quickly moved into this, um, kind of high-profile space where where you were working on, um, really important issues. Um, and even there, it sounds like the approach you were taking felt so counter to the the current, um, kind of way science was, was, was broken up that even though the work you were you were doing felt really impactful, you weren't sure you'd be able to find a place for it.

**Speaker 4:** Well, we, um, I I think this is always the problem of, uh, interdisciplinary, cross-disciplinary. I would go further than that in terms of today's technology and situation. But, um, uh, but I think this is a classic difficulty and, uh, and and I think one of the the things that opened our eyes to it was, um, and and something that happened when I was in grad school that's relevant. I mean, it seems like ancient history to the people on on board right now. But remember the first book called cognitive psychology, the first label that used the first big thing that used that and popularized that label, even though there was a much longer history was a book in '67 called cognitive psychology by Ulrich Neisser. I'm in grad school in the 70s and '76 uh, Neisser publishes a second book which says, which basically says, I was wrong. Right? And he puts out the perceptual cycle and in there he has this great graphic of, well, the standard way of approaching, uh, understanding the brain, human, uh, cognition is a linear information processing sequence, boxes and lines. And they consist of processing with a line to another box that says more processing, with a line to another box that says still more processing. And the processing box is connected to another box that says memory. More processing is connected to one that says more memory, and the third box, still more processing is connected to a box called still more memory. And the graduate students and I all, we all looked at each other and went, you can say that and get away with it? Because we all sat there looking at this linear information stuff, and the way they were trying to do these micro nano experiments to tease out details of the uh sequence inside the head, and we're going, this is crazy talk. You know, this doesn't make sense. We don't want to be involved in those studies. You know, give us something that we can figure out like about how perception works and attention. Uh, and, uh, and in some ways you can say that has been a battle that went on long before I was in grad school and has gone on to today. Where people want to make linear simplifications, right? They can't deal with the uh interacting set of of processes, right? at multiple levels. And uh so I was prepared in many ways to all of a sudden walk into the post accident world where everyone in an industry and and even more than that industry, three mile Island triggered a large international uh uh re- examination of what it meant to do to create safety in systems and to see that these systems were in fact complex systems with lots of functions and interdependencies that were very hard to understand and that those complexities were the result of an incessant pursuit of narrow definition of optimality. And so I was in a by accident well prepared to come in and interact with people like Rasmussen and Hollnagel and because to understand perception was to reverse engineer the brain was to think functionally. was to model functions and not structures. Was to was to was to recognize things were complex. Uh, and we can go way back and I I don't know if the students like it anymore when I come back and go, well, that idea started in 1950. And that idea started in 1923, or and that idea started in 1890, because William James probably had almost every idea about cognition is probably somewhere in William James in 1890. Uh, I even had an a situation where we were talking about some uh principles and I was able to go back as some of my old old colleagues like to do too, even to 1860. Right? And so a lot of these ideas and and issues have been around for a long time. They keep getting buried and pushed aside by people trying to force a linear uh over simplified view on the world. And then and there is an advantage in that. In isolated situations, you can work out things. This reductionist paradigm. But scientists, as long as there's been science, has rebelled against reductionism in trying to understand the real complexity of the biological world that we all live in and can't escape from.

**Speaker 2:** Right. Okay, so this is this is this is great. So, so you started out, you were kind of primed to be thinking about complexity and move away from these over simplified linear representations of the world. Um, and that you carried that forward. And so, I'm, I, I know that you were at the very first NDM meeting and have been very influential in this community, but recently I have heard you say that NDM is about everything except decision making. And I wondered if you would just tell us more about how you're thinking about that.

**Speaker 4:** Well, I think that line, which you you just quoted me, is is exactly the better name. Now, you you were there in some of that debate about it's time to move past. Right. It started as a as a play off of narrow views of decision making as choice, choice among options. Uh, and there had always been a gulf between problem solving research and decision making research going back to the early 20th century. And those two lines of work crossed each other and interacted, but kind of went on their own ways. Um, and I think this has gotten even worse. Um, the, um, and so naturalistic decision making starts out, uh, much like we were starting out in 80 by saying, uh, if you want to understand cognition, cognitive work, decision making, whatever label you wanted to use pre from pre 1980, you had to look where the phenomena exist. And the phenomena exist in the real world, not in uh with college students in a laboratory at a university. And so, um, you had to go out where the phenomena was. And the phenomena were in responding to emergencies and crises. Uh, so what, what real world setting were you studying? And sometimes you could abstract out something else like chess, but chess didn't capture the openness, uh, of the problem solving and the complexity that went on because it's still a closed world within within the game. But somehow this fascination that cognition was was best exemplified exemplified in games seemed crazy. I mean, it is crazy.

**Speaker 2:** It is crazy.

**Speaker 4:** Well, right now, uh, intelligence is exemplified in micro targeting ads, which is even crazier than thinking it was exemplified by chess. Uh, the, um, uh, so, um, what did NDM find? So NDM, cognitive systems engineering, all of these were essentially empirical endeavors. Saying, look at the real world, isolate and observe these, these natural laboratories, going back to the beginning of the origins of science and the enlightenment, right? That Sir Francis Bacon talks about it in terms of its collection of observations of phenomena, diverse in nature to inform the mind, right? That this is where science really starts with observation and extraction of phenomena, the discovery of phenomena and what influences those phenomena. So whether it was Gary looking at fireground commanders or us looking at people interacting with AI systems in diagnostic situations or whatever, um, we were trying to look at it where it related to real situations where something was really at stake. Um, so it was an empirical base. And what happens when you use those empirical bases, you keep finding that option selection is rare. In fact, often option selection is because you've hit a wall. You're stuck or something is irreversible. And what was observed as in that first NDM meeting over and over again, is what we find is people try to avoid being in a choice situation, right? And expert operators, right? are navigating, they're steering, they're trying to understand what are the potential trajectories, they're expanding trajectories, they're pruning trajectories about how things might develop next, they become sensitive to cues that tell they they listen to the world well and intensely. So the world tells them early and quickly where the world is going because there's constraints on how the physical real world operates. Uh, so, naturalistic decision making's first discovery has been there's not much decision making. And I think since that has only gotten stronger and and, uh, my fear and my observation is that we still spend way too much time fighting the same battle that we fought in the late '80s, uh, with decision making framing. Um, that they're missing stuff, instead of being positive and pursuing what we understand. And what we understand is adaptive behavior. Uh, what we've understand, what we understand is people are good at adapting and we get stuck, uh, in a variety of ways, but we are an exquisite adaptive system and in fact, all of our, all of the technology and human created systems out there, are messy because of constraints in this universe. Constraints of limited resources, uncertainty, change, continuous change. And these messy systems in the end work, only because some people are able to adapt to make them work. So we find that it the the real focus should be adaptation. And so and one of the NDM meetings later, I said, what have I learned trying to boil everything down and popped up a slide in uh Virginia, not far from where you are Brian and, uh, and only had two letters on it, R E. And everybody's looking at where's all these slides? Dave, where's your big slide deck? What have we learned? Everything is about RE. Revise, replan, reframe. Right? It's all, all about your ability to change. And it's not building a plan, it's revising the plan, it's replanning. It's not getting a ha generating a leading hypothesis, it's revising it when the evidence doesn't fit anymore. It's our ability to revise and redirect and reframe. What, you know, I mean, what one of the classics from the early days and with a long tradition back 100 years, over 100 years, is people are a unique cognitive system in the ability to reframe. Right? Yet we still have yet another wave of artificial intelligence claims that ignore, that cannot possibly do reframing. Don't even begin to address the issue of reframing. And yet one of the stellar achievements of evolution is the human capability to reframe as they confront, uh, a changing world with finite resources, uh, and the the, uh, the fundamental intractable uncertainty of con of of working now and making taking actions now, uh, that you can't guarantee that they're going to be absolutely correct once you have, uh, information, uh, 10 minutes in the future. Right? This is this is this is an old story. Uh, originally from Richard Cook, um, uh, it's in the, uh, patterns book on joint cognitive systems and the laws, uh, but, uh, tech technology company representatives kept badgering a operating room physician of what technology, what features did they want in their, uh, in their next round of, uh, products. And they badgered this guy named Avery for forever. And finally in frustration, Avery turned around to these product reps for tech companies and said, you know what I'd really like your system to do? Give me a picture of what the world is going to look like in 10 minutes. If I could anticipate and see a few minutes ahead or some worlds maybe only 10 seconds ahead. All right? What a great, how great would my ability to steer through uncertainty and hazard to achieve goals and which goals were the most important to prioritize and which goals needed to be relaxed, uh, or sacrificed given the given the pressures of the given situation. Uh, and that anticipation, where's anticipation and choice? Where is anticipation in, uh, inductive AI machine learning? Where is reframing in any of this? So the, um, uh, as always, uh, technologies, technologists seem to as as which are humans, right? Right? Technologies seem to define the issue of success in terms of what can I make my machine do next that nobody else quite could do. That must be the signature of intelligence and expertise and capability, ignoring the continuing demonstrations of what is expertise, right? What are the real constraints on the world we live in? Right? And irreducible uncertainty is, is one of those, which is in stark contrast between a naturalistic, uh, view of, um, uh, how people, how cognitive systems work, uh, and, um, and a decision or choice view, uh, where one is trying to tame uncertainty, to beat it into the ground through unending computations, right? And that we can conquer uncertainty. And the other that we learned from the beginning in the 80s, uh, was that people act to take it, you know, to use uncertainty as a signal to live and and function despite uncertainty. To come to act, right? And what better demonstrates this than the current pandemic and particularly the situation the US is in. So, if you look at my latest piece on the pandemic, um, the I started four months ago putting out a working paper series and the last one which took me a little while to get out because of some arguments about, uh, making it a little more complete, um, is called betting against the odds. All right? That how how should you bet when all of our bets are against the odds in the context of the pandemic? Why are they bets against the odds? Because of the uncertainty, the novelty and the noise. Right? So here we have as as big and as crystal clear an example of the constraints on cognitive work and naturalistic adaptation. Right? Is that, right? Any of the bets, right? The basic how do you combat infectious disease bets based on past work on what what's worked in past epidemics, the uh what I call the density bet, right? Which is based someone on findings from past epidemics that, you know, areas of congregation of people is where high transmission occurs. So aggressive actions with, with large consequences and side effects are okay in those high density, high congregation, large gathering kinds of things, but they're not okay where I live because I'm low density or I can stay away from that stuff. So don't bother me. Only do it over there where you have to. And then the the third family of bets which we see a lot of which is essentially the natural course, which is a pessimistic bet that there's nothing we can do. We don't know enough, we can't know enough, uh, it isn't really that bad. It's only those other people who suffer. Uh, all these different variations that is essentially a pessimistic one and all three of these bets are playing out. But the point of the paper isn't the three bets. The point of the paper is the bets are against the odds. What does naturalistic decision making tell everybody? Well, I just blew it again. And I should I should say back to your original question, we can use the initials NDM but we should never spell it out. Right? And say decision making anymore. It's NDM. What's it about? Naturalistic exploration, all right? of how people actually handle uncertain situations.

**Speaker 2:** I like it.

**Speaker 4:** So what what have we learned from all this about betting against the odds? It's really simple. Hedge. Right? We have 35 years of results that say, what do people do in these situations is they hedge. You don't make an all out bet. You don't do your Bayesian computation and say this is the best bet because it still might be wrong. And if it's wrong, really bad stuff happens. Right. So instead of making a bet, even trying to improve the odds a little, it's still a get bet against the odds. So we watch people hedge. What do they do to hedge? They they they remain tentative and open to revise. Right? They're anticipatory. They're working hard to pick up early information. They interact and coordinate in new ways, right? So what do you, you know, so that what do you see over there? What have you learned from your experience? How does that apply to me? And so we see the emergence of new ad hoc horizontal lines of communication of sharing between uh similar uh roles and functions to try to figure out what's going on and develop better treatment protocols for people ill with COVID and fights over those as well. Um, but in the end, what's one of the lessons uh from acting under uncertainty is you have to be decisive. At some point you have to act, you have to pick a course of action and commit to a course of action. Uh, to not commit to a course of action is to fail. Uh, and but the paradox of our uh uh this this one kind of summary of our findings is that how do you be tentative and open to revise? How do you be anticipatory yet on the other hand, you have to be decisive as well. And these kinds of paradoxes that don't fit business school models of decision making and leadership. Uh, that's what's interesting. That's what the world tells us to do. That's a science-based approach. And so Wow. the naturalistic NDM world is as well is the most relevant thing to to understanding how all the layers of society and the different roles should coordinate and work together in this uncertain and risky situation and no one is following the rules from NDM. Almost no one.

**Speaker 2:** So this is this is this is a great framing and I I so I like the naturalistic exploration frame and, um, you know, the example you give is so, so compelling. Um, I wanted to just back up, you mentioned this paper series, which is really nice. Um, for our listeners where can they find that if they wanted to look at that?

**Speaker 4:** Well, the easy easiest place is go to uh, research gate, um, and resilience in a pandemic is the label or it'll just be there on my page at research gate. Uh, or you can go to Zenodo, Z e n o d o, which is a great way to publish quickly, um, uh, stuff, uh, and get a DOI number, so things are referenceable and trackable and stuff. Uh, just as an aside on your comment about, uh, you know, the limits of human systems and the, um, getting started and all all that stuff. I was reminded by someone that, uh, uh, they finished a, uh, a, uh, a PhD thesis that was, uh, what easily publishable and so they have to put a one year moratorium on releasing the PhD thesis from the university libraries. And the reason is because plagiarism software will detect the thesis and medical journals won't accept the paper because it'll have been pre-published as a dissertation.

**Speaker 2:** Wow.

**Speaker 4:** Uh, and the risk of that happening and delaying or blocking publication in a medical journal, which has pre pre- publication risks, uh, other places have done this as well. Uh, and, uh, meant that he's going to put a one-year embargo on it. Uh, and, you know, here's the kinds of breakdowns in coordination relative to goals that are the downside. Um, you know, because, you know, remember when we do the naturalistic explorations, we see the downside too. It's not that people are right all the time. It's that people have the have a confidence that machines don't have. And, uh, uh, uh, and we can understand their failures is where that and the and the in the form of the factors that break down that natural confidence versus the factors that build up, play into that confidence that people can exhibit in coordinated activity. Obviously, the US is exhibiting the downside of, right, of of, uh, human, uh, interaction in the fragmentation and working at cross purposes and inability to learn from past epidemics, uh, that's currently going on in the UK and the US.

**Speaker 3:** All right, Dave, I'm going to reframe, uh, you and ask, uh, you to share something with our audience that they probably don't know about you.

**Speaker 4:** I was born on the wrong side of the river in Washington, D.C. That's true. That is absolutely. Uh, I was, right? We I we grew I grew up in, uh, in the, uh, uh, across the Anacostia River in D.C., uh, in around children and grandchildren of immigrants. And, uh, uh,

**Speaker 3:** My mother was so excited, uh, because our daughter when uh my wife and I's daughter got her first job in uh in DC it was in DC and we got her first apartment in Georgetown so she could walk to work. Uh, she's very successful in terms of advising health care systems on how to provide better patient centered care. And uh, and my mother was like, she has an apartment in Georgetown? Wow, she's really made it. And I'm like, what do you mean mom? It's just Georgetown. I mean there's tourists there and all kinds of things and she's like, oh no, when I was young, we weren't allowed to go to Georgetown. No, they knew we didn't belong in Georgetown. That was where wasps, white white Anglo-Saxon Protestants lived. Catholic immigrants weren't really welcome there. And uh so no, we were really, you know, each era defines the wrong side of the tracks in different ways and puts up different kinds of barriers, some bigger and some smaller. Uh, but uh, but no, escaping, uh, but the ability to grow uh out of uh, a uh, out of the way place. Also, uh, in that era, uh, you know, a long long time ago, uh, people don't realize air conditioning was just happening and DC was a very sleepy, still kind of quasi Southern town. despite the government, the powerhouse and sprawl and uh money and so forth that we associate with DC now didn't exist in those days. We were really out we were we were in the backwater of that area. And, uh, only by accidents of good fortune, did things happen whereby I, uh, you know, um, got, uh, plugged into a better educational stream after we started to move around the East Coast, because some fifth grade teacher recognized I was bored as hell and plugged me into the advanced track classes, uh, because otherwise all I did was get bored in school and read books.

**Speaker 3:** I have another RE, uh, thing to ask you about. I I think this is true but it might not be. Uh, I I think at one point you said you were involved in reenactments, is that right?

**Speaker 4:** Yeah.

**Speaker 3:** Tell me about that.

**Speaker 4:** Well, uh, what happened is we went to Pittsburgh and uh, uh, started our career and family in Pittsburgh and that's near uh, many of the historical events, uh, before the American Revolution, um, as native different native nations uh struggled for their autonomy against the encroaching British, French, uh, empires and the colonials, uh, and their, uh, uh, pushed to expand westward. Uh, and so these events had reenactments and we took, uh, our first son to those and, uh, even as a tiny, tiny child, he, he was interested in the Indians and the Native Americans and he remembered George. And so we went back and he he wanted to visit more with play with George. And so in my typical research way, I said if you're interested in this, then we're going to be interested in this and we're going to research how it works. What goes on? And what we dug up and taught the kids and they got to see it live and in uh through cultural mechanisms and crafts and uh, the artifacts and uh history was the uh deconstructing the, um, the American mythology, uh, and taking a Native centered view of the development and history. Um, and many of the uh disasters, uh, you know, we we often say our research is is driven by disasters and it's important for our students to always know off the top of their head many of the famous disasters, Columbia, uh, right? Challenger, uh, Three Mile Island, on and on, uh, uh, Texas City, all these different kinds of ones. Well, there were plenty there in Western Pennsylvania, Braddock's defeat. And Braddock's defeat could be analyzed just like we would be analyzing, uh, deep water horizon or something in terms of how did this, um, Brit large British army, uh, get beaten by a quarter of Indians and a few Frenchmen in the woods. Uh, and, uh, and so you can lay out these things. But it's a it's a I think my whole interest in history over my life since I was about eight or nine years old has always been, uh, a recognition that the standard story misses stuff, misses important stuff and you have to dig behind the surface of the standard story to see what really went on. And that you can't take for granted, you have to be skeptical of what people tell you and you have to dig and figure it out for yourself. Um, and, uh, so the the historical bent, uh, it also plays very well I think into, uh, many of the techniques we talk about in understanding how operational personnel look at the world before outcome is known because of that uncertainty they have to wrestle with and you go back and try to put yourself in, what are the, what are the ways that people can behave and adapt under pressure, uh, and these periods of change that have gone on in in past epochs of, uh, of human experience. It was also, I think a great cultural, um, uh, uh, it gave our kids a different way to look at the world than a standard Western management, uh, uh, cultural way to look at people in the world and activities. So they were able to, um, I think it broadened and expanded their ability to be empathetic, it's particularly important in the kinds of struggles that we're going through currently, uh, as we try to, uh, reduce systemic racism because they learned about this in a 500 year history of of, uh, of, uh, various forms of, uh, oppression against native groups, uh, across the Americas.

**Speaker 2:** Wow, what a cool experience for your kids. That's really neat. Um, so I wanted to circle back. One so it seems like you have many times been kind of at the forefront of these very important movements and you're often the voice of a new way of thinking. And I just wondered if you kind of reflect on that, um, that's not always a comfortable place to be and and what have you learned about being that voice, trying to, to, um, get people to think about things differently in a way that maybe is counter culture and and and and, uh, and for some people feels threatening. How what are what are your kind of lessons learned from from being in that position?

**Speaker 4:** Well, um, you know, it's interesting, while I as I commented earlier that it was a little bit lonely at the very beginning of the first of several experiences that you're pointing to. Um, it was, uh, it was very exciting. All right? I mean, you know, stuff's happening. And people are willing to question and they're willing to pursue new directions, they're open to new possibilities. And when you can create that and be part of an atmosphere, uh, where you're integrating stuff from many, many different directions and able to move and and, uh, explore new possibilities. It's the best it's absolutely the best. I mean, that's what it's supposed to be. That's what they, that's what they teach in schools, science is supposed to be. I mean, in my experience, those periods are rarer than they should be. And I am tremendously fortunate to have been part of that in bigger and smaller episodes. Uh, uh, several times over my decades of of involvement in science and engineering. Uh, so it's, uh, it's, it's the way things are supposed to work. The, um, uh, let me give you two examples of this. Um, so, uh, the first one will be a little depressing I think. Um, it's the zombie problem. And in human systems, uh, all areas that touch on human activity, um, there's a special characteristic of people which is we're reflective. We reflect upon and build models of those we interact with, the processes we interact with, the things we interact with. We build models of them. And our models, our mental models or whatever are going to be incomplete and off. Um, they're they can be folk models that are completely, uh, uh, uh, disconnected in some ways from what goes on. If we have, if we're tied closely, our folk models aren't so folk anymore because they're tied to the experience of actually doing something. So the story elicitation methods that you've pioneered as well, uh, are capturing that stuff that only the people who do and have the experiences can tell you. So you get away from the folk models of distant parties and things. Um, but in science, we're trying to say, this is how the world really works, that there's hard constraints on how the world works. There's rules, there's laws, right? And and sometimes those laws are only empirical laws and sometimes those are hard constraints. Damn it, this is the way this universe works. And you can, you violate them at your peril, right? Uh, so, uh, and the problem we have is that some of the ideas that turn out to be wrong, however plausible they were or interesting at the beginning, they turn out to be plain wrong. But we can't say that. Or we can't accept that. And they're zombies that just keep coming back. I, you know, I showed up once at a uh human factors meeting armed with a big silver cross, garlic, and a wooden stake trying to kill the the, right, trying to kill off the zombies of miss miss about people interacting with automation.

**Speaker 2:** So I think that's for a vampire, Dave. I think you might have gone wrong there.

**Speaker 4:** I know, it probably doesn't really work. Uh, and as I I recently paired with, uh, some other, uh, veterans of all this, Ben Schneiderman and others fighting in particular about myths about automation and people. Uh, that these zombies aren't there and aren't aren't amenable to technical responses. They're not there because somebody's just stuck in one technical world view. Uh, they're technically wrong. They're just technically wrong. And completely wrong. But, right, they serve a purpose from a social perspective. They serve uh, and you can't fight them on mere technical grounds. They come out and, uh, they they serve these larger, uh, human system purposes. Uh, so the zombie ideas and how to kill them off and I and I think the the main issue there is we have to we have to do stuff that is productive, not just scientifically valid, uh, but we have to do stuff that's productive and helps organizations work better. Uh, in the end, the best thing we do and the most success we have is when we empower people to to do things and accomplish things in new ways that make systems work better. And so that design, uh, there our ability to deliver stuff that helps people make systems work better is our ultimate, uh, uh, card that we can play to, uh, move forward. Uh, because people do have options on how they design systems. Now, they can they can repeat the past and, right, violate the hard constraints on how systems work and then get surprising negative results. But they have this easy out, it's human error. And more technology will be the solution. And when that doesn't turn out to be the case, they can still say, it's human error and more technology will be the solution. Remember, I wrote in 1987 a piece titled a little more technology will be enough next time. Right? And you're like, whoa, wait a minute. Now that was the beginning. I hadn't experienced three, four, five waves of technology doing the same repeat. Uh, but the people I was learning from, the mentors who had who had a longer history than I had, uh, had seen this over and over again as well. Uh, and so when you come back with the empirical findings that cognitive systems of people and machines work differently than your model, your expectation, they went, no, I like my expectation. I like my model just well and I have a great rationalization to, um, uh, use to preserve my model. So human's ability to preserve models, uh, was simply that it's always the erratic people who undermine my otherwise brilliant system and technology. So trying to, uh, switch to resilience as the main focus circa 2000 was a big thing. We, um, Eric Hollnagel and I and others had been, um, we'd recognize that trying to get people, uh, to change the way they they develop systems, uh, because of findings on the safety of complex systems and what undermines it and what builds it, we weren't we weren't having a big enough impact. And so we consciously and deliberately switched, uh, in 2000 and the the 2000 to 2004 period where we launched resilience engineering, uh, to say that this is about helping all organizations, not just things on safety or just on the the safety critical part of that organization, uh, but all organizations lived and struggled with the complexities of the world. They were evident for everyone. And you needed ways to out maneuver complexity. And that meant we had to think about where adaptive capacity came from, how you supported adaptive capacity, how it decayed, uh, how it was lost, the fundamental brittleness of machines, uh, and so we, uh, we this this went as a positive direction to empower organizations to out maneuver complexity. Uh, and so we've had some success, um, in particular in the, uh, software engineering world, uh, because of the complexity of the distributed software systems that everyone relies on today. And don't think that Facebook or Google know how to make that stuff work. They have outages just like everybody else. Spotify had an outage last week. Uh, major outage and having your music is pretty important when everybody shut down in a pandemic.

**Speaker 2:** Right.

**Speaker 4:** Uh, so, um, uh, but, uh, you know, airlines have had major shutdowns due to IT failures that have cost them hundreds of millions of dollars. Uh, one head of one airline said to me, I know exactly why we lost, uh, why we had the shutdown, the the service outage and the shutdown of the airlines for 40, I think it was about 48 hours. Cost two to estimates started 200 million, I think closer to half a billion. And, uh, he goes, I know exactly why it happened. It was Bob. And you're looking at him like, really? Bob.

**Speaker 2:** One person.

**Speaker 4:** Yeah. Well, Bob, you know, right? They were doing a data center thing work was doing some maintenance in a data center and and uh something that uh later on on in hindsight turned out to be the wrong action which happened to result in a power outage which happened to take down the data center which happened to take down the IT infrastructure which happened to take down the airline which happened to cost 200 to 500 million dollars. Uh, and you're like, you realize that's linear causal thinking. In fact, you know, your system isn't robust to a single data center outage, your system isn't robust to a power interruption, to these things. Uh, wait a minute here. Uh, these are system level issues, it's not about components. And that's what Eric and I were saying in 1981-82 when we started writing new wine and new bottles. It's not about the pieces, it's about the interactions and what emerges in those interactions. And but people want to go back to a component level linear view one by one. And fighting that reductionist tendency of people because it's easier, because it makes everything look understandable and therefore manageable. You don't have to out maneuver complexity anymore, which is hard work. Instead, you can, uh, pretend that you're operating in a kind of one to one world. The, um, uh, now we get success when we can isolate out little islands where the linear assumption can hold temporarily. Um, we can make some great progress. But in the end, the real world means those islands are can only be maintained at great energy. But there is a kind of ephemerlism to them. Uh, and the fundamental, uh, constraints of our world about finite resources and change and uncertainty, um, and adaptation. We live in a network of other adaptive, uh, units that take advantage of our successes and ask the world to do more, do it faster and do it in more complex ways because you develop some new capability. So the lesson and the direction over the last 20 years has been to understand adaptive systems and complex worlds. These play out at layers. It's not about one layer, one level, it's not about one role, it's not about one interface, it's not about one piece of automation or, uh, one autonomous algorithm, it's not one machine learning algorithm. It's a network of roles. There's always multiple human roles. There's always multiple machine roles. The machines are heterogeneous and have different, uh, different legacy stages, not just the latest, uh, fanciest technology. The systems are always messy. They have to be that way. That's okay that your system turned out messier than you wanted or hoped or intended. Uh, and in the end you need to design so that some people can step up and make messy systems work.

**Speaker 2:** So I'm going to, I'm going to try to, uh, summarize some of the key points I heard in there about being this voice of change. So one is kind of persistence. So you have been, um, saying this message, even when people don't want to hear it. Another thing you mentioned is taking this and applying it to important problems and and and having solutions that work. That's really, really influential. Um, I think a third thing you said is to kind of understand and appreciate, um, the opposition and in in this case it's a lot of times it's this human tendency to want to simplify, to to want to deconstruct, to want to, um, um, make it look like it's all going to be neat and tidy. And so once you understand that tendency, um, you have a better foot hold for, for, um, kind of talking about the complexity and the messiness and and and and drawing those contrasts. Um, would you agree with those?

**Speaker 4:** Yeah. Well, the the the line I often use with the students is in the in the context of safety. Um, if you don't make people uncomfortable, you're not doing your job as a safety, uh, person. If you always make people uncomfortable, you're not doing your job as a safety person. Right? I mean, you have to know when to back off and when to press on. Uh, you know, have to when to step back and rearm and refit and, uh, when to when to when to shift your battle plan to, uh, a different a different, uh, field of fire. Um, uh, uh, and all all I can say in fighting some of the zombies, uh, as I said in this note, it was I I haven't actually eliminated any zombies despite all my efforts, but I can say I'm still in the field. I'm still well armed and I'm still ready to do battle.

**Speaker 2:** Nice. Nice. Well, the time is just flying here. There's one question I want to ask, uh, before we wrap this up that's just kind of fun. Um, so I wanted to know if you could instantly become an expert in anything you wanted to be, what would you choose?

**Speaker 4:** Uh, you know, that's a really hard question. Uh, uh, for someone who knows about these things, when you say instantly, you go, isn't that a contradiction for what we study? Uh, how fast we could go. So I'll give you, I'll give you the, um, I'll give you an ironic answer relative to all this, which is, what did I want? What did I want to be? Right? I wanted to be a basketball player, right? You know, it was like, you know, eight hours a day in good coaching and somehow I would be able to jump high enough and grow five more inches and be a good basketball player. Nice. So, uh, no, I think, uh, I think a better answer is, um, is to relax the instant and and remind people that, uh, that your ability that you're never an expert and you're always becoming an expert. Um, um, right, I I think one of the things that's illustrated in the current situation is that there are forms of expertise about integrating source experts, right? Specialists. Um, and I think one of the problems we've had is there's a variety of specialist knowledge that's essential in the current pandemic. But there's other forms of expertise that are necessary to integrate, uh, uh, these different forms of specialist knowledge, especially when we're dealing with an evolving uncertain situation. Um, remember, from our point of view as NDM, uh, naturalistic explorers, um, the, uh, when you're in the middle of the situation, right? It will it has novel features, but when hind when you have the advantage of hindsight, it will be it will appear much less novel than when you're in the middle of it. Right? The possibility for new things, different things, things that need to be done differently, will be loom larger and some of them will be important when you're in the middle. But afterwards you'll be able to pinpoint exactly what was new and different or what twists and turns had to happen on past plans and approaches. And so it will seem much narrower, simpler and more obvious. Um, the the the the story I always like to say is the operators at Three Mile Island had 10 minutes to figure out something they never told could happen and had never been taught about existing. Uh, but after six months and 60 million dollars of investments in many different specialists, specialists working on the problem, we could figure out exactly what they should have done and how exactly it it should have been obvious to them what to do when they were in the middle of this, uh, situation. Um, and, uh, I think that story is a great way to say, um, why a naturalistic exploration point of view can reveal so much about how adaptive systems, human adaptive systems work in complex environments where there's a large degree, large interdependencies and some of those interdependencies will be hidden until they bite you. And then you got to figure out what's connected to what and how to how to reconnect or unconnect, uh, and sometimes there's a great deal of time pressure along with other things, as the situation cascades and and worsens and deteriorates as you're as you're trying to figure out, uh, uh, and a stop what looks like it could be a train wreck very soon.

**Speaker 2:** Yeah, I mean, this is a great thought to leave us with. I I think we, the NDM community are often the voice of of of of, uh, how different it is in the moment from that after six months of studying it. That that first person perspective, the time pressure, um, is that's a really different situation than someone looking at it from the outside later on.

**Speaker 4:** That's

**Speaker 2:** The challenge for NDM right now is to scale up. Right? The pandemic illustrates what's been going on across many settings for at least a decade or more, uh, which is it's while it's full of individuals confronting these things, the the action and the leverage all comes from thinking about larger units of action, larger levels of society and you see that in the different jurisdictions and roles and kinds of units that are in play in a in rolling epidemics, uh, moving across the globe. Um, uh, where all the kinds of things that we study with a fireground commander or, you know, uh, someone leading a wildland fire fighting team or whatever. Um, the anesthesiologist running their team on a cardiovascular surgery. All of these, uh, uh, key lead people and roles that we focused on and the key teams they they, uh, uh, run, uh, are one scale. But the pandemic illustrates that this kind of stuff goes on at all scales. And how do we scale up and provide effective mechanisms so that people can reframe, revise, be decisive, but still be able to redirect as new evidence emerges and new effects become clear. Um, this ability to steer in, uh, world of multiple hazards, uh, where information comes in at different rates, uh, and that we by definition have to coordinate over multiple roles and levels in order to have enough capability to actually have a big impact and re redirect the the trajectory. And nothing shows that better than the trajectory of a pandemic. And if we don't work together and coordinate our activities to have a bigger impact, the pandemic overruns us. We don't, we don't steer the the epidemics into, uh, into safer waters.

**Speaker 3:** Well, thank you, David, that's extremely important. Um, and, uh, I think this podcast is certainly one way to get that message out. Um, so I think with that, uh, it's a good place to stop and Dave, I want to thank you very much for speaking with us today.

**Speaker 4:** Well, I thank you for being patient with me and and how kind you were to give me triggers where I could launch off on my long soliloquies.

**Speaker 3:** We expect nothing less.

**Speaker 2:** This was really

**Speaker 4:** It's good to interview and be safe.

**Speaker 2:** Thank you. And so on that note, thank you for joining us for the NDM podcast. I'm Laura Milletello.

**Speaker 3:** And I'm Brian Moon. Learn more about Naturalistic Decision Making and where to follow us by visiting Naturalistic DecisionMaking.org.

(Music)