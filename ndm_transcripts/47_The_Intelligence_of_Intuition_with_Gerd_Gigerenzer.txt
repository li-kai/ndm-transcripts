Speaker 1: The Naturalistic Decision Making podcast with Brian Moon and Laura Melatello. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress.

Speaker 2: Welcome to the Naturalistic Decision Making podcast. This is Laura Melatello from Applied Decision Science.

Speaker 3: And I'm Brian Moon from Paraian Technologies. We are honored to be joined today by Gerd Gigerenzer. Dr. Gigerenzer is director of the Harding Center for Risk Literacy at the University of Potsdam, Faculty of Health Sciences, Brandenburg, and partner of simply rational, the Institute for Decisions. He's a former director of the Center for Adaptive Behavior and cognition at the Max Plank Institute for Human Development, and at the Max Plank Institute for Psychological Research in Munich. He was formerly a professor of psychology at the University of Chicago and John M. Olin Distinguished Visiting Professor, School of Law at the University of Virginia. He's a member of the Berlin Brandenburg Academy of Sciences, the German Academy of Sciences, an honorary member of the American Academy of Arts and Sciences and the American Philosophical Society. He was awarded honorary doctorates from the University of Basel and the Open University of the Netherlands, Nezbaten Fellow at the Darden Business School, University of Virginia. Awards for his work include the Triple AS Prize for the best article in the behavioral Sciences, the Association of American Publishers Prize for the best book in the social and behavioral sciences, the German psychology award and the communicator award of the German Research Foundation. His award-winning popular books include calculated risks, gut feelings, the intelligence of the unconscious, risk savvy, how to make good decisions, and they've been translated into 21 languages. His academic books include simple heuristics that make us smart, rationality for mortals, simply rational, and bounded rationality with Reinhardt Selton, Nobel laureate and in economics. His most recent book, the intelligence of intuition is set to be published the week we are recording this podcast. Welcome Gerd and thank you so much for joining. We're super excited to have you here.

Speaker 4: You're welcome.

Speaker 3: Well, that introduction makes for a really challenging place to start, but I think to make it easy, let's go back to the beginning and and have you tell us how you found your way to psychology and in in particularly to the study of decision making.

Speaker 4: I have been a musician in an earlier life. And when I near defending my dissertation into psychology, I had to make a decision, whether to stay at the stage to play music, which I love, or to risk a career in academia. And for me, music was the safe option, and also where I earned more money and academia was the risky option. So I took the risky one. And this is an example why I got interested in how people like me make decisions and important decisions in their lives. And that gave me an impulse to look deeper in it.

Speaker 3: So you were your own inspiration it sounds like.

Speaker 4: I think most people are their own inspiration.

Speaker 3: How did you come to the psychology pathway to begin with? Was that something you had always been interested in as a child or

Speaker 4: No, I have beenvering back and forth what to study, but at the end it was something very typical, the inspiration of a teacher, a teacher whom I admired and loved. He was a biology teacher, but he had a diploma in psychology, and he always gave us pieces of wisdom, and that's an inspiration, and I went this way.

Speaker 3: I'm sure we could all point to uh those special teachers along the way that set that tone for us in terms of curiosity and enabling us to see that there's more to the world than just what's in their classroom.

Speaker 2: So your work has a very strong affinity with naturalistic decision making and and your ideas of heuristics offer a a marked contrast to the bias research community. I'm wondering if you can just give our audience a sample of your perspective on heuristics. and then also maybe talk about your professional experience and kind of countering the bias research community.

Speaker 4: So in my own life, like everyone's life, decisions are made by heuristics, such as what to study. There are very few people who try to make a excel spreadsheet and put numbers on the options and the possible outcomes and then make the calculation. And I've seen people who tried to do that, when they looked at the result, they decided, no, that's not what I want. So, the direct way would be to actually take heuristics, that is rules of thumb, like imitate what your teacher does, or just have the courage to try something new with your life, rather than go the path of the least resistance. So, these kind of rules of thumb are what keep people running. And so I looked at the literature, and the literature that that that in psychology started among psychologist, and then later went into AI like Herbert Simons, or work on AI where it was meant that one elicit the heuristics that experts use, such as chess players or managers andzes them in order to make computers smart. And that was the traditional view oftics is something useful for situations of uncertainty. And that all changed in the 1970s when psychologists like Danny Conman and Amos Tusky started to study heuristics, but they were looking at the classical decision theory, like the maximizing of expected utility and thinking that if people deviate, the problem is with the human mind, not with the expected utility theory. And then heuristic became a bad name. And that's to some degree still going on. And we have tried and I think successfully to remedy this situation and to change the question from wheresitics are good or bad, that's not the right question, to can we identify the situation where a given class of heuristics will work and where it doesn't. And the same question need to be asked for rules of logic or probability updating. None of these principles works all the time. That's overlooked, when one puts the blame on and believes that logic would be always the right answer.

Speaker 3: I'm really curious about what you just said a moment ago about having some success in sort of countering that perspective. Can you share with us where you've seen the success?

Speaker 4: Take the toughest area, economics, which is really reigned by the paradigm of maximizing expected utility theory and probability updating, there have been a number of noble laureate which have seriously worked with us on developing the science oftics. Reinhot Selton is one of them, and there's a book that the two of us edited called bounded rationality, and there Vernon Smith has been involved in our summer Institute for bounded rationality at the Max Bank Institute for Human Development, and of course Herbert Simon, the Godfather oftics. So, the and similar developments are now in areas like management, where it's becoming clear that what business school teach, namely, the right way is that you do some utility calculations, and the wrong way is that you use heuristics, because they are equated with biases, that that's not the way and also not very useful for management, because in the real world of uncertainty, you can't maximize anything. And also the story about the human mind who fails because it doesn't follow the abstract laws of logic is by now known to be a very naive story. And similar changes have been happening in the last years and in particular the concept of ecological rationality is making its road, which basically means that you shouldn't evaluate people against an abstract law of logic or consistency, but by their success in the real world. And that means more precisely than the study, can I identify the situations where astic like imitate or just go with one reason or way everything equal is better than, say, the conventional wisdom of a regression model or of expected utility maximization or some other kind of benchmark. And we are basically also doing the best to understand the marvel that the human mind is as opposed to the story that it's a kind of confused, miswired by cognitive biases. And also, that helps us to see where things go wrong. And I think that thetics and biases program has been in a cool the sac since at least 20 years. And one can see that the program of ecological rationality takes what Herbert Simon once wanted to do with heuristic seriously and develops it into something interesting and the heuristics that we have developed are investigated, studied and used in various real world situations as by the Bank of England for evaluating banks at time problem to medical decision making and to almost any era where one have to make decisions under uncertainty, that means not under calculable risk.

Speaker 3: I'm wondering if you have a perspective on on why that paradigm still continues to excite people and cause programs to invest in it. What do you think the strengths are in biases and heuristics approach and sort of philosophy that people sort of hang on to?

Speaker 4: Yeah, it's a good question and I may not be the best person to to answer that, because I've always wondered why one can be so enthusiastic about pointing out how dumb everyone is. Certainly, it makes good classroom lectures. And many of the problems are puzzling, but also, if you look closer, the errors are often not in the people who are accused of cognitive biases or not understanding statistics, but they are in the researchers. And it also teaches us that people tend to believe if they are told that logic alone can give you the right answer. And that is a strange thing. So for instance, if take a famous demonstration of so-called framing. Framing is considered something, so attention to framing precisely is considered as something you shouldn't do. So, here's an example. Imagine you suffer from a severe heart disease, and you have the option to try a dangerous surgery or not. So then the doctor could tell you about your prospects. So, the doctor might say, there's a 90% chance that you will survive the surgery, or there's a 10% chance that you die. So, what should you choose? According to the major proponents oftics and biases, you should not listen to how the doctor frames the problem because it's logically the same. But every psychologist knows that you can tell something by choosing words. So, in that case, if a doctor tells you there's a 90% chance of survival, it's an encouragement. If the doctor chooses to frame there's a 10% chance of you die, it's a warning. And actual experiments in psychology show that people who play doctors or real doctors deliberately choose a frame in order to signal something that that I know that's not in the words. And also, that ordinary people are intelligent to understand what's being signalled. So here, a form of social intelligence is confused with a logical error. And also psychology has become a source of error and logic is believed to be always right. This is a big misunderstanding and it's particularly interesting that it comes from psychologist.

Speaker 3: That that is a fascinating take especially as you started off with it makes for good lectures and maybe easy lectures, right? It's easy to get up and deliver the message of dumb humans. It's a lot harder to get up and deliver a more nuanced view of you know, a deep dive into a particular domain. That that takes a while. We know when we're trying to describe the the cognitive work in different domains, it takes a while. So I thought that was particularly insightful, but now it's it's the picture that you've just painted is also that psychology has created this mess and it seems like only logic or only, you know, AI can sort of fix the problem almost.

Speaker 4: Yeah, and there's a political message between the and biases program that extends to a certain interpretation of AI. So, if we are so dumb and commit all these cognitive biases, and as I said before, we know by now that many of the demonstrations of overconfidence, base rate neglect and so on have been shown to be no errors at all but adaptive responses to a world of uncertainty, as in the case of framing. So, if we are so dumb, and if they are certain, there is no hope for us really to learn to understand risks and probabilities, so if that would be true, then the conclusion is, someone needs to lead us to make good decisions. And then the someone is government. And the program that's known asudging is based on exactly this message. People need to be nudged into good decisions assuming that the choice architects who want to nudge us actually know better than we, what is good for us. This is called paternalism. It's a soft way of paternalism, because it doesn't close doors, but it steers us into certain decisions. And a similar argument is being made with AI and in part by proponents ofging, but also in part by the immensely rich hands of tech companies. And the argument is again that humans make all kind of errors and AI doesn't make these errors, at least not as much and we should better surrender to the recommendations of an AI system. That's called technological paternalism. And there are authors, best seller authors, that tell us that about Homodeos and tell us stories that are important made up about the brilliance of AI. But it's also meant to impress people and in this case to get hands on them, not only on our data, but also on our decisions.

Speaker 2: So Gerd, one of the things I love about your writing is you use all these rich examples. And I was wondering when you are talking to people who don't know anything about heuristics and you want to really illustrate to them the marvel that the human mind is, what is one of your favorite stories to help them kind of understand your perspective?

Speaker 4: Yeah, so if I have a picture, then I can show how baseball outfielders catch a ball, a fly ball. And they don't calculate the trajectory or better estimate all these variables that you need to calculate trajectory, but they use a very simple heuristic. The simplest is, if the ball is already high up in the air, start running, fixate the ball and adjust your running speed so that the angle of gaze remains constant. So if you try this and then you will see, if you keep the angle of gaze constant, you will be exactly there where the ball comes down. So, this is an example of a heuristic that relies on a single cue, the angle of gaze and nothing else. And it provides a safer catch than if you would try to do all these calculations and estimations. That's an example of astic.

Speaker 2: Yeah, that's a beautiful example. So, following from that, I'm always interested in methods. So how do you study this? How do you learn that that's what the baseball outfielders are doing? Yeah, what kind of methods do you use?

Speaker 4: So, we use multiple methods, and they can be experimental, and many are non-experimental. And they do different things. So, we do experimental tests in order for instance, to show what people in well controlled situations do. But we also work with doctors, with managers, and observe what they are doing and model what they are doing and then develop heuristics that they can actually use. And then of course, there's simulation and much of the method that we do is to simulate environments in order to understand how well a simple heuristic like just go with one good reason as the baseball outfielder does is actually as good or worse in a situation that can be simulated. And finally, we use mathematical tools, for instance, we have proven situations where relying on one reason cannot be beaten by relying on the same reason in many others. So, it's a multiple approach, and I don't believe that there is any method in science that is the best one. And just to to underscore this, in my own work of 20 years at as a director of the Max Planck Institute for Human Development in Berlin, I've always had an interdisciplinary team, usually from eight to 10 different disciplines. So, psychology, economics, mathematics, computer science, biology, and others in order to have different methods, different viewpoints come together, and also for a very selfish reason, I wanted to learn something new every day and I did. And there was nobody in the group who knew more than all the others.

Speaker 2: Wow, that sounds like a wonderful work environment. So, I'm still I want to ask a little bit more about methods because many people have a set of methods that they are most comfortable with, and that's kind of their core, and then they branch out or they find colleagues who have complimentary methods, but it's hard. Not many people learn to be really facil at lots of different methodological approaches. So, I'm wondering how did you find your way to this kind of science where you're really open to mathematical algorithms and observational research and experiments and simulations and and all of these things.

Speaker 4: Yeah, maybe my background is a musician. So, I was always playing in bands. And it was when I directed my research group at the Max Planck Institute, I was not a conductor. This was more a jam session with different instruments. There's no instrument who can trump all the others. And actually, it's also clear that they have to work together. And that's the same of methodology. You need more. You need a toolbox. And the illusion that the best way to do science would be to experiments, or anything else. That does never occur to me.

Speaker 2: Well, that metaphor really resonates with me. I'm I'm married to a musician, so yeah, that really makes a lot of sense. But has it been difficult? It feels a little counter culture. People tend to pick a discipline or a tradition or a, you know, a group and work through that. Has it been hard to create this environment that you have, where you have these multi-disciplinary folks?

Speaker 4: That's a good question. There are two ways to do science. One is to identify with a discipline or subdiscipline and to what everyone else does and try to do it better. Then you may be the big fish in the small pond. The second way is not to identify with a discipline, but with a problem. And such in my case, how do people make decisions under uncertainty, where expected utility and Bayesian theory is mute. Because uncertainty mean that new things can happen. As in, yeah, as almost everywhere in life. And then to by focusing on a problem, then you need people from different disciplines. What do philosophers know? What do economists know? What do animal biologists know about animals make decisions? Get that together. And then the next question is how to do this? Yeah, given the tendency of almost everyone to just sit with others from their own discipline. Now, in my research, I established very early coffee, every day at 4:00 or tea and where everyone comes together. And people may talk about personal things, which helps to bond them, or about science, which helps to exchange ideas. Also, we had of course, every week a talk by someone in the group, then we had the pleasure at Max Plank, the Max Plank Society owns a castle in Bavaria, so we went every year a week there. So, many things to get people interested and getting them together. Trust is very important in this group. And also something that's extremely important is an open culture that means that everyone dares to say what they really believe and not are anxious about saying something stupid or hurting someone. And to do these, I always had at least one contrarian in my group. A contrarian is someone who with no fear, but based on fact and respect, criticizes what I as a director say or what the group spirit is. That helps against group think. So, these are some of the measures that help that people form a group like a family, there is trust and there's no anxiety about saying, Now, what you're saying does not correspond to the facts, because the other person who is criticized knows that the first person likes him or her. And that's the basis of rough criticism. When visitors came to our group, they were often frightened by the directness of critique within the group, until they understood that you can only have that if you trust yourself.

Speaker 3: Yeah, I'm with Laura, that sounds very hard to do. And so you've laid out the model, it'd be interesting to see moving organizations from a model that doesn't look like that to implementing your model, just be interesting to see what that process looks like.

Speaker 4: If you're interested, I've written a paper on that. It's called simple rules to run a research group.

Speaker 2: I'm very interested. I'm going to check that out.

Speaker 3: Yeah, we'll add that to the show notes for sure.

Speaker 4: It appeared in a Chinese journal, in one of the major Chinese journals, and it also is in an adopted version in this forthcoming book. No, actually, it just appeared today. The intelligence of intuition because how to lead a group is much a matter of intuition. And that intuition is then put into rules like get a contrarian, make sure that there is one, or institutional rules like cake and tea for everyone. Cake rule is a very important one. You know the cake rule? Okay. So, the rule is, if someone publishes a paper, this person does not get maybe $5,000 as in some economics departments, but they have to bring cake to the entire group. So, it's a kind of inverse conditioning, but it works because, look, most of the ideas that are in a paper stem from all of the group. And also, the person who has published something gives something back to the research group and that has worked very well. Probably, there is really any research group that has published so much papers, say, in psychological research, as we have.

Speaker 3: I hope everyone likes cake. I I do want to turn as you've started to toward the new book, The Intelligence of Intuition. I think first of all, it's a brilliant title because you are countering all of the nonsense out there about what intuition is by coupling it with intelligence. So I think that was a a brilliant way to uh frame the book. And you've already sort of hinted at what's in the book in particular this sort of idea of the war on intuition. I'm curious about after having so many successful books, why you thought this one was necessary at this time?

Speaker 4: Yeah, we are still in a society where people hide their intuitive decision making. Not everyone. So, successful chess players like Trude Potia or Magnus Carlson, they openly explain that their success is a mixture between intuition and all the work they have done in learning chess. But at the same time, top managers in large corporations don't dare to say that I made this decision after looking at all of the facts, which weren't conclusive, based on my intuition and experience. You will rarely hear that. And the same companies spent lots of money to hide intuitive decision making and, for instance, to hire consulting companies who then for lots of money give the reasons for the intuitive decision and the term intuitive or gut feeling never occurs. That's a waste of time of intelligence and funds only because of the anxiety to admit intuitive decisions. When I work with large corporations and ask their top managers, how often is an important professional decision that you made or you participated at the end a gut decision. Then in a typical corporation, it's 50%. So, 50% of all decisions are at the end a gut decision. And I emphasize at the end because before, of course, these executives, they look for the data. But data is in a world of uncertainty, not always conclusive. What this example also shows, intuition and deliberate thinking go together. They are not opposite as some of my dear friends think, when they construct two systems of reasoning, one is intuitive and often wrong, and the other one is logic and deliberate and apparently never wrong. This is a misconception. Intuition is not the opposite of the deliberate reasoning, they are two tools. And their processes are very similar, mostly heuristics. In the intuitive case, it's unconscious. So, intuition is defined as a feeling that's based on first years of experience with a subject matter. Second, it appears quickly in consciousness, and third, we cannot explain it. I mean the person who has the intuition cannot explain it. So, it has nothing to do with a sixth sense or God's voice, and it's also nothing that only women have. We men also have intuitions. But the history and the war against intuition that I follow in the book, The Intelligence of Intuition in the first chapter, started with women. So, in the 18th century, 19th century into the 20th century, psychologist believed that women are intuitive, their mind worked by feeling, they are associative, they are not really reliable, and have no abstract moral feeling, while men are reasonable, rational, and obviously have an abstract morality. And you can can find these ideas into the writings of the first president of the American Psychological Association and it is this dichotomous thinking is no longer politically correct. It is still in some people's thinking, particularly about women, but it has returned into psychology in the 1990s and it's put to great prominence now in the form of the so-called two systems theories of reasoning. System one has the same properties as the old picture of the female intellect had, namely, it is intuitive, it's associative, and it's often wrong, and mostly unconscious and maybe amoral, emotional, whereas the system two is like the old picture of males, deliberate and logical, rational, rule-based, and so on. What we have constructed here is the return of an old dualistic system that wasn't based on evidence, just like the modern, this type of dual system theory, system one versus system two, is not based on evidence. It's so general, it's just dichotomous with general terms, and these are hard to falsify, but even the only thing that they say is that there would be oppositions, which is wrong. Intuition is not an opposition and or from deliberate reasoning, and also the association between the concept in each of the systems, they are not empirically founded. It is heuristics and intuition and unconscious. So, and being wrong, that doesn't work together. Every heuristic can be used unconsciously or deliberately. It's the same process. And heuristics are not generally leading us to biases. Logic can easily lead us to biases and big data has failed to predict the financial crises of 2008, and also failed to predict the success of Donald Trump. So, there is no method that's the right one. But we have reimported these old ideals. There's a good gender, male, and an inferior one, female, and now we have changed that into there is a good system one, system two, and a kind of problematic one that is system one, which system two needs to pay attention to and take care of too, just like in the good old times, male were held responsible for paying attention to their wives and their children. So, if you look at this, this is how the war in intuition started, and it is now going on in the work of the heuristics and biases program that has taken over much of behavioral economics, and some of the proponents say openly that their goal is to show that intuition fails. Of course, they would never say that it always fails. Sometimes, sometimes not, but I've never heard that logic would sometimes fail and sometimes not.

Speaker 3: It sounds like an interesting book in chapter one alone. And I think that these kinds of sweeping reviews of history and in sort of the paradigms and the and the dominant wins are very helpful for me personally just to sort of realize that as we try to promote the kinds of ideas you're talking about, they're coming up against some extremely entrenched perspectives and and entrenched institutions and we have our work cut out for us.

Speaker 2: Gerd, I know you have been an inspiration to many people in many ways. I wondered who are some of the people who have really inspired you or influenced your thinking?

Speaker 4: Among the people who influence my thinking is Herbert Simon, particular with his work on satisfying and heuristics, less so with his symbol, his ideas that the human mind is basically only is like the computer, so. But the his work on satisfying and also acknowledging that under uncertainty, the classical decision theory doesn't apply at all, and it's not a good idea to reduce than every problem to a small world in the words of Jimmy Savage, where one can optimize. So, this is one inspiration of my work. And I think that Gary Klein has also been inspired by Simon, by Simon's move out of the University of Chicago school into the real world where he encountered and also got interesting how real people and experts make decisions. Another inspiration to my work has been Egon Brunswick, a psychologist from Vienna who moved to Berkeley, who is more or less almost forgotten, and that's a sad story. His contribution was to make very clear that in order to understand the mind, you need to look at the environment. And this is one of the achievements that we still that are still in the future. If you look at psychology as a whole, most psychologist think a theory is about something in the mind or how it interacts with others. And concepts like risk aversion are just internal, or the entire idea about personality traits. And both Simon and Brunswick were pointing to we need to study the interaction, and that's what I call the study of ecological rationality. So, take a class of heuristic like one good reason decision making or imitation and analyze in what environment is this likely to work and where not. And that's the important question that was suggested by Simon, he hadn't worked it out. And also by Brunswick, which we take up. I would say, these two people have been very important in forging my interest to think about psychology in an ecological way. And then I could name a number of others who have inspired me, like early proponents of evolutionary psychology, like Leda Cosmides and John Toby, or writers in philosophy like Ian Hacking, a brilliant writer who recently died, and there are many clear thinkers out there. And in our field, we often need less experimental research and more thinking.

Speaker 2: Agreed. And I will tell you, I think within the NDM community, there are a fair number of Brunswickians. I do, I do come across the lens model and I think he has influenced many, many people.

Speaker 4: A comment on the lens model. Now, Egon Brunswick when he moved to the United States adopted to the psychology found. And the lens model was an outcome. The lens model is kind of a regression model. And I think here he went wrong. What really is there are heuristics that combine the mind to the environment.

Speaker 3: Your comment on Herbert Simon getting out of the University of Chicago and into the real world is very interesting to me because across campus, the sociology department in the University of Chicago was all about getting out into the real world and that that's an interesting example where we can have two different approaches, two different thoughts of how you should go about doing research even on the same campus, even in sort of the same general discipline of studying human behavior.

Speaker 4: I myself was for quite a few years, professor at the University of Chicago in the psychology department. And I loved this university and its diversity, and that I can just agree with that. The important distinction for me is between risk and uncertainty. And Herbert Simon didn't use the terms usually, but that's what he meant. So, in standard economic theory, is about situations of risk. A situation of risk means, you know all the possible states of the future, and you know all the outcomes for sure. And then, you may know the probability distributions. That's risk, or maybe not, that will be ambiguity. In any case, it's a small world where no surprises can happen, no innovation can happen, but you can use your optimization calculus. Uncertainty is the world in which the future, all states of the future are not necessarily known, nor their outcomes. And new things can happen. And it's the typically situation in which most of us are when they decide whom to marry, what shop to take, how to predict the flu. And also, this is the big asset of natural decision making, going out in the world and studying how experts make decision and should make decisions. While still today, we have many of my dear colleagues, particularly very intelligent colleagues, they flock to base decision theory. Now, base assumes a stable world. And it's a good tool for certain situations. For instance, I have taught a thousand gynecologist in their continuing medical education, how to reason about what a positive test result means. And you need base for this. And it's a fairly stable situation. And we have developed tools like natural frequencies to do this. But in many situations, you go wrong with base. An obvious example is the Turkey illusion. You know that? Okay. Assume you are a Turkey. It's the first day of your life. And the man comes in and you fear he will kill me, but he feeds you. Next day, the man comes again. You fear, he might kill me. No, he feeds you. Third day, the same thing. According to Bayesian probability updating, on day 100, the probability is higher than ever before that he will feed you and not kill you. But it's the day before Thanksgiving and you're dead meat. So, in this situations, based on updating doesn't work. And it also doesn't work in very channel for situations where things suddenly change and where the base rates of the past will mislead you. So, we need to have scholars who think more broadly, and not believe in one thing like base or expected utility theory or logic as rationality per se, but get an ecological view and pose the question, can I identify the situation where base rule is likely to be a good idea and where it's not? And that's the ecological rationality question.

Speaker 3: Gerd, I fear we could go on and on about this, but we are nearing the end of our usual time frame. So, we usually like to ask a a fun question at the end to help wrap up. And this question for you is actually all about you. We have seen the Volkswagen ad featuring the Munich Beef Eaters Dixieland band where you drive the Volkswagen and you play the banjo. For those who haven't seen it, I strongly recommend you give it a look. But the fun question is, are you still playing? Are you still doing music?

Speaker 4: I still play, but in a very limited way. Music is also was for me always was something to play with others. And and given now that I've chosen the academic career and writing books and articles and teaching people and teaching doctors, teaching managers, and teaching federal judges, the time has become little. I often regret that, but I've made this choice and I think it was a good choice.

Speaker 3: I am strongly inclined to agree. Thank you so much for speaking with us today. It it's really been a true honor to talk to you.

Speaker 4: It was a pleasure.

Speaker 3: For the NDM podcast, I'm Brian Moon.

Speaker 2: And I'm Laura Melatello. Learn more about naturalistic decision making and where to follow us by visiting naturalisticdecisionmaking.org.