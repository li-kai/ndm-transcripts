Speaker 1: If you have something you're passionate about, go put together your own plan and strategy and then start socializing it. Not a lot of people will have the will and the motivation to take the time to put together a thoughtful problem and a a methodology to a solution.

Speaker 2: The Naturalistic Decision Making podcast with Brian Moon and Laura Millatella. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress.

Speaker 3: Welcome to the Naturalistic Decision Making podcast. This is Laura Millatella from Applied Decision Science.

Speaker 2: And I'm Brian Moon from Paragon Technologies.

Speaker 3: We are fortunate to be talking with Kevin Odin today. Kevin is a fellow at Lockheed Martin where he's worked for 14 years. Currently, he leads research initiatives focused on human autonomy collaboration. In this role, he supports cross corporation efforts and has responsibility for engagements with universities, DOUD Service labs and small business partners. He earned his PhD in applied experimental and human factors psychology at the University of Central Florida, and he was a graduate research fellow at the Consortium of Universities in Washington DC. Welcome, Kevin.

Speaker 1: Hey, thanks for having me.

Speaker 3: Yeah, I'm so glad to get to talk to you today. I wanted to start by going back to the very beginning of your career, and I wanted I I I wondered if you would tell us how you got started. I think you did not start as a human factors person. So, where did you start?

Speaker 1: So, where I started was down, and I don't know I know maybe very few people that started in human factors, right? We all kind of discovered or something. Um, but I started down the path of wanting to be a therapist, right? I didn't want to work with um, I knew early on, I didn't want to work with uh computers, right? Now my business card is a engineering fellow, so go figure. Um, but uh, I started down clinical uh, psychology, and I was getting a master's degree, um, and working in a hospital with uh, children uh and families, um, in patient unit stuff. Uh, pretty nitty-gritty stuff. Uh, enjoyed it. Um, but then I uh, had a professor, a research methods professor, um, at UCF that was working in something called human factors. And, um, she would use the some of her her work as like examples, right? And I was like that's interesting. I never thought of that before. And I went for a visit, um, to her lab, met some of the students and then, this is back when, um, uh, right, this is a good memory test, right? Um, this was back when uh, infotainment systems were like, you know, just coming into vehicles and there were laws being passed about cell phones and driver distraction and they were talking about these internships at General Motors and talking about getting paid for that, and I'm like taking out loans for my clinical psychology stuff and, um, I was like, oh, interesting. So you these interesting problems, uh, um, and you have these opportunities to go work with these big companies where you have all these resources. And so, um, yeah, I uh, I then submitted an application, got accepted, and I remember my one of my first classes, I was talking with some of the other, you know, graduate students and I was sort of asking the question, what is human factor still? Like I'm in this graduate program, but I'm still getting my head around it. And they're like, oh, well, it's you have to be passionate. You're not going to make it through this program if you're not passionate. And sort of like these like, you know, I was getting nervous. I don't even know what I'm in yet, right? Um, but um, turns out it it was something I was passionate about and I stuck to it and from there, uh in Orlando, there's this uh large presence of simulation and training with the Department of Defense. And, um, I met up with uh one of the research leads uh in that group, a guy named Don Lampton, and he had an opening, um, for the research fellows program for for the Consortium of Universities and I started working with squads in the army. And I was like, wow, this was the first time I had been around such a collection of like experts working in these high-stakes things and um, I got really excited about it, right? It it's different from clinical, right? Where you had sort of people that were working at, um, levels where they were trying to get back to normal. Um, you had people that were working at the edge of expertise and stuff and you're trying to even sort of make that better and it was an interesting challenge. And then I just started like, uh, you know, like I said, I wasn't interested in technology, but then I jumped into these simulation environments and these things look like experiments, they're called training and uh, I've been rolling since then.

Speaker 3: So interesting. Yeah. So I've heard other people who start out in clinical talk about that switch from uh, psychology as a way to study dysfunction to psychology as a way to study highly functional people. Um, and that that's that's a a kind of interesting switch that a lot of people make.

Speaker 1: Yeah, and it was and it it became like the high stakes nature of it too, right? Where you see these people and that's where, you know, I really developed my sense of patriotism too. I maybe didn't have that before, um, as much, right? When I was an undergrad. Uh, I went to undergrad you at Florida and, you know, I my allegiance was to orange and blue. Um, but then I just started working with these uh soldiers and and seeing what they go through. like it just sort of motivated me, um, about uh, Department of defense stuff and it's just been like very rewarding, right? Like where there's a lot of reward in working with uh the clinical population. There's also a lot of reward in working with folks that are serving in our country and so it's been a real, um, just a real uh, lifestyle change or perspective on values and stuff and I I couldn't be happier with the work.

Speaker 3: Nice. Nice. So, it's uh, so human factors is pretty broad and at at some point you really did get interested in high stakes and and found your way to naturalistic decision making and cognitive engineering and and those topics. Um, do you recall when you first, um, started interacting with that community?

Speaker 1: It was through books. Um, it wasn't a part of my formal training. Uh this wasn't where our our group was focused necessarily or at least the people that I worked with. What happened was it's so funny, um, is uh, so I have a I have a significant visual impairment and it's hard for me to read paper books, right? Um, I just can't anymore. I used to be able to, but I can't anymore. And I was at, um, Human Factors conference and Ashgate publishing was there. And I saw some of the books and titles but I couldn't, this is before we had a lot of like iPads and digital stuff. And um, I read some of the stuff, I struggled through it. I was like, oh, gosh, I want to read more of this stuff and um, then uh, I there's a girl named Emily and they're like it turns out they're like in, you know, Europe, right? There's this British accent. I'm talking to her on the phone and we worked out like a waiver that I signed to they would send me PDFs instead of the textbooks. And and I didn't realize they were textbooks until I started getting emails asking me about Professor Odin our newest collection of whatever. So then I started getting like and there's a lot of themed around naturalistic decision making kinds of things. Um, one was a oh, gosh, scenario based macrocognitive decision something, right? And I was just so and the the writing was so good and I think I think what drew me in is that so much of the NDM world is around the narratives and the sort of cultural anthropology things and a lot of the examples in the research, they just resonated with me, um, compared to sort of other lab-based things that I I was sort of previously exposed to. All have their place and role, right? But for me, like I started reading the stuff and then I started seeking out presentations and conferences and and uh, that's how I met each of you, right? It was um, I knew of your work and uh, I met you at like human factors, right? And um, I started to engage the community. And so it kind of came through, you know, curiosity and what I was reading and then and then making the relationships.

Speaker 3: Nice. Yeah. So I've never heard of anyone who those uh, emails from the publisher about latest works, um, actually worked, actually got them hooked on something. That that's cool.

Speaker 1: Well, I didn't realize I was reading textbooks necessarily. I was just getting PDF files and I was like, I'm like, man, I've just reached a new level of nerd nerdum or whatever, right? Um, but that's what I know, I really got me, um, down the path of thinking about it differently. Lots of uh, lots of good authors in that community.

Speaker 2: Hey Kevin, do you remember any particular, um, narratives that struck you early on?

Speaker 1: Oh, that you know, the one that you jumped to, right? probably is always the uh the firefighter kind of work, um, that that happened, uh, with Gary's work early on, that one gets highlighted a lot. Um, but then actually through reading that that stuff, I remember I had to, uh, I worked for a small business for a while and they're asking about cognitive task analysis. I didn't know what it was, right? So I was I remember calling around people trying to understand it and I was reading some stuff. But, um, I would say that actually some of the narratives that I worked on, um, you know, not that I read elsewhere, but we started doing the work. Uh, Jado, I think that's how you say it, the Joint improvised explosive. So the Marine Corps had a program and we actually had a chance to work on that in that small business and I remember reading through the stories and can't share those here, I guess, but it's part of, you know, that was a part of a program. Um, but those stories actually, I think really even started to make the impression upon me about how important it is to understand the work, right? The work to be done, um, and uh, got me sort of more wrapped into wanting to make it a part of my, you know, how I approach my projects.

Speaker 3: Awesome.

Speaker 2: So, so you're at Lockheed Martin now, tell us a bit about the group you're leading there.

Speaker 1: It's awesome. I've been so fortunate and that's the, I guess that's the value of such a big company is there lots of different people and lots of different focuses. Um, and right now, the group I am working with, um, includes some small business partners, um, and, uh, and some engineers from AI, and some university partners at MIT, um, and really a group of engineers that I, uh, and and and some uh, human factors folks that are sort of in the user experience world and also sort of more focused on sort of cognitive systems engineering. So we kind of got this mix of people. You guess, you know, I think earlier when Laura mentioned a broad community and I think that's one of the things that, you know, I'm realizing through my group now is that all the, you know, there's not like one human factors person, right? You've got people that really good, really good at analysis and design and you've got the sort of like really bright and talented folks who are really good at translating that into, you know, visual presentation kinds of things, right? And it's when you get that mix of people together where you can start to, you know, identify these really hard requirements, right? And then you can start to come up with really interesting concepts and start to test those out. But, um, my fortunate part about the company is that, you know, we've got this resource of data analysts and AI scientists that we're able to sort of like, you know, really take our top-down problems and lay out some projects where they all get involved and have like really specific roles. But what's nice is is that, um, I think getting to share some of the they don't know they're, you know, looking at it from doing a lens like naturalistic decision making. But I'm telling you, when people sort of see that natural world problem and they understand what they're working on, everybody gets motivated. And we have some, um, some of our former operators, retired colonels and stuff that are, uh, members of the team and, um, the stuff that we're doing for them. I mean, it's a slam dunk. So, it's a it's a good mix of, uh, hardcore AI engineering kinds of things and, uh, the tough, uh, tough guys that I work with that were out in the field. It's, uh, it's a really, I don't know, it's a really rich, uh, set of experiences and talent.

Speaker 3: So, I imagine a lot of your work is proprietary, but I wonder if you can talk about some of the exciting things you're working on right now.

Speaker 1: Yeah, I mean, um, it's no, uh, it's no hidden secret, right? That, um, autonomy is, uh, one of the sort of technologies that's uh, you see it everywhere, right? Uh, from cars to your phone. Um, we see it across, you know, what our customer primarily D is interested in trying to figure out how do you successfully deploy this, right? It sort of like harkens back to the 90s when there were a lot of automation paradigms, but now we're on that continuum and autonomy is becoming like a you know, it is a real thing. It's deployed today. Um, and so right now, uh, looking at ways to think about, um, our mission systems, right? The things that sort of the technologies that you interact with to conduct the a mission, when we start to implement those into the system, how do we make sure that, um, we're maximizing our crew, the humans, uh, with the technologies that we're bringing, you know, into that system. And so, you know, the historic problems of sense making and trust and and, um, you know, managing workload spikes, um, those are all the things we're working on today and, uh, we have cooperative partners at the army that are they're they're, um, they're, you know, partnered in in that problem with us. And, um, I don't know, I think it's the the most interesting part of uh, what I've done in my career and so right now, the the path to deploying autonomy successfully so that we have the sort of joint decision making, uh, looking a lot at, um, sort of rotorcraft kinds of, uh, problem spaces is really interesting. Um, but we're also, you know, expanding that to sort of, you know, like I said, I work a lot across business initiatives, really thinking about how humans and autonomy are going to cooperate together. It's uh, it's a great problem space and that's that's really where we're where I'm spending, you know, most of my hours and days.

Speaker 3: So, I know this is a big topic in lots of domains right now in healthcare, self-driving cars, uh, military, and, um, I know that there are some pretty diverse views about what autonomy can do and what is safe, um, and how to design in this space. And I'm wondering, um, are there any key messages or insights that you find that you are often putting on the table to kind of get the team aligned or or remind folks from other backgrounds that we got to think about this part of it too.

Speaker 1: I think the thing that, um, that we're really doing well out now is bringing the requirements for the mission and the goals and sort of the, you know, sub goals of the operation up front and as compared to thinking, uh, and I say from a human and from an autonomy perspective, um, we're really fortunate, you know, to, you know, be working with a creative group, um, that is open to that. There's historically, you know, across the community, there's like this we're the AI folks over here and you know, we're the we're the human people over there and and, um, coming together is hard, but I think what we're really doing what what what I what my personal insight I guess is that framing the the human needs of how it's actually going to work in the environment and trying to estimate what that's going to look like given these are new technologies. Doing that as a part of the very initial concepts and concept of operations is probably the greatest uh, motivator for success. Um, it's really hard to when you start developing something to then retro organize it for, um, serving the humans. I think that's been like one of the really sort of key insights and I think the other is just thinking about what role do you have for design of the technology and then what role do you have maybe for, you know, things like training, right? Where, you know, I care a lot about humans, I grew up in the training simulation space. Um, you know, how do you equip the operator to to not give up on the system. And I think there's a a really sort of paramount kind of play for training in that space.

Speaker 3: Yeah, so that, um, so there are kind of two things in there that really interested me. So one is, um, I I was thinking about what you said earlier about how you were kind of drawn to narrative and that what you find now very effective is helping people try to imagine what, um, what this future world is going to look like and and framing the human needs in that context, um, and that you find that that is something that can bring a team together and help them get on the same page about what you're trying to do. So, that that kind of leap out at me as an interesting thing, this this theme of a narrative as a way of of helping helping people understand the problem or frame the problem.

Speaker 1: And it really moves the project forward, right? What it does is is, um, it helps move the conversation away from I I always talked to people, I've got too many solutions, not enough problems, right? Like everyone seems to know what to do. But when you start looking at the natural work of things, right? I, you know, I keep harping on that, but like that's really where it comes in. And then you say, well, how is it going to serve this problem? And I think it really makes it real for people. And once you get the scenarios worked out and you get everybody bought in and everyone has like, you know, an opportunity to reflect on it, it just motivates good work.

Speaker 3: Yeah. The other thing that caught my ear when you were talking is is is thinking about both design and training. I feel like in many context, those are different people thinking about those things, they're thinking about them in different points in time and you're kind of talking about them at the same time. So as we're designing this, also thinking what what the training needs will be because they're they're so related, right? So, often times people try to fix design flaws by better training and kind of vice versa, maybe we need less training if we can design this a little better. So, so thinking about them together, I think is pretty unusual.

Speaker 1: Yeah, I feel like it's, um, I don't know, it's something I don't have an answer for any of that stuff, right? It's just sort of something that I get, I guess because of my experience is coming through training now, you know, you know, you know, education, academic training and like all this design stuff and then and then working in a training space and then yeah, it really seem to come together and it's like this, I think it's across human factors, it's like this mis trade space kind of thing, like what do you design for, what do you train for? I think it I think it emerges just because of the way programs roll out, right? And like you're right there they're completely separate groups. You can look across whether it's government or, you know, sort of, you know, pick a large organization and they're just really separated and it's really hard to get on the same page. And so, um, right now as we're looking at this invisioned world, right, with these problems, it's just the lens I've adopted for it and we'll see if we can make some progress on bringing them together because I just think it's the best way to make sure our systems are used properly so people, you know, are effective and safe.

Speaker 3: Right and we we kind of know that autonomy brings some different training challenges.

Speaker 1: Yeah, it's, um, you know, they call it teaming, right? Um, and it it suggests this interdependency and uh, you know, you're relying on each other and you would never, you know, when I worked with squads, right? They would never operate without, you know, having after action reviews or some way to reconcile differences, um, and to understand what each other is actually doing. And, um, I think it's a, you know, that classic, uh, black box problem of autonomy, but, um, I think there are ways to educate operators and, you know, training seems like a good solution to me.

Speaker 3: Nice. So, you mentioned how much you enjoy working with these multi-disciplinary teams, people from industry, universities, government labs, um, different disciplines, and I have been lucky to work with you on some of these teams, lucky enough to do that. But I've been on a lot of these teams that didn't work very well. It seems like you are very skilled at pulling the right people together and setting the stage for success. And I wondered, do you have any insights you can share from that? How how do you make these teams work?

Speaker 1: Kind of goes back to a little bit we're saying about like the the narratives and stuff. I think the thing that it took me a while to appreciate was scope, right? And setting some a target or a set of like small targets or objectives and fitting them into a narrative because the narrative is powerful. I think that really makes it real for. But then the idea of having a set of targets that people can like make progress toward and giving them an ability to come up with their own plan, that, you know, whether it's a secret or, you know, how successful it is every time, always there's a little bit of nuance to it, but it took me a while to come to that point of, you know, giving people clear targets and letting them develop the plan. But but laying out up front what that foundation is and and having them, you know, you can't get people to be interested or motivated, that's up to them. But using the examples, um, like some of the work that we've done together and some of the reports that have around the human autonomy challenges, um, in UAV communities. When you share those, those examples, it doesn't have to be a story, it could be in a table, right? When you give people that realistic reflection, it creates traction and, um, it pulls them in and I think that's, you know, whether it's an AI, you know, scientist person, I mean, I say AI is for you know differentiate, but ultimately we're all sort of people trying to do better for our operators and they're thirsty for good requirements and then once they start to hear the problem, we've had real success of sort of facilitating engagements with SMEs between folks that would just sort of wait for the requirement and let them hear from the operator what the struggle is and and frame it and it's just, um, it's really the thing that I think when you have interdisciplinary teams starts to create like a common, you know, shared vision, right? And, um, that's, you know, emerge as being pretty successful.

Speaker 3: Yeah, I I feel like, um, your teams, you're really good at creating a situation where people aren't passively waiting. They're kind of reaching forward, um, and and engaged in the problem. Yeah, I like this this way you're framing this in terms of if we can help people understand this compelling problem, their own natural curiosity and desire to make a difference is going to help them know how to move forward as opposed to kind of waiting around and hoping someone's going to tell them what to do next.

Speaker 2: Yep. Right, I I can't help but point out that we could have taken that entire piece of the podcast that Kevin just gave us and put it in a therapeutic context as well and it would work equally properly. I mean, I'm just drawing on your uh earlier comments about how you got started. Uh and what you're saying about small goals and people need to motivate themselves and work for the longer context that that just feels very therapeutic and clinical to me.

Speaker 1: Successive approximations.

Speaker 2: So you are clearly drawn on some early skills here. Interesting.

Speaker 1: Yeah, yeah, I think psychology is a good field for me. I'll I'll I'll clamber on to any of the uh threads in it, right? I find it all interesting.

Speaker 2: So interesting is one thing. What about fulfilling? So when you think back over your career, what which project or projects have been kind of most fulfilling for you personally?

Speaker 1: Right, I mean, it's uh, right now the stuff I'm doing right now, it really feels like, um, I I think I I want to say the most fulfilling, but I'll, you know, just because we've had such a uh, a number of years to work on it and we've had the support from sponsors and all these kinds of things to kind of keep going. You know, I think that if I were to take a step back from a sort of a discrete project, it goes back to when I started working in the DOD space, right? And hearing uh from the operators and then working on solutions that we're going to uh help them overcome like their mission challenges and sort of, um, keep them safe and the security of our of our country and defense and all these things are just compelling to me and like it makes me really, you know, sort of proud of the work that we do and the work that I do I take ownership of some of that, right? So it's like, it's uh, it's been a surprise for me. Like I said, I wasn't in that space when I was coming out as an undergraduate, but it really has been and it's kind of, um, interesting when you we talk about the clinical time and and the military time and there have been opportunities where working, you know, through my company, we've leveraged, you know, sponsorship to things where I've helped facilitate, uh, sponsorship for sort of VR kinds of capabilities and rehabilitation labs, right? And so, I still do hold on to my clinical roots, um, and thinking about how you sort of do that. So I mean it just, I guess it's just been the, um, the thread of engagement with the military through all the course of my career that is the bottom line for me.

Speaker 3: Yeah, so, um, Kevin, I kind of want to ask you, uh, maybe the opposite question. So as you reflect, um, back on your career, what, what barriers have been more difficult to overcome than you expected? What is is there's been something you've maybe tried to make happen for a long time and just just haven't been able to get that idea out there in the way you'd hoped.

Speaker 1: I would say challenges. Um, I was probably forewarned about this. Uh, give a shout out to Clint Bowers in our professional development. Um, I one thing that stuck with me is he said know your value, right? He's like going into this field, you know, like I said, I had to discover human factors and very few people know about it. And so he said figure out what your value is. And uh that was, you know, to the whole sort of class. I was only professional development things. And, um, when you're trying to say that you've got this, uh, return on investment or something like that, right? And I don't want it, you know, you know, what's your calculation and what's the number? The challenge has been that I was immersed in my community, right? If I'm if I'm sitting with the two of you at a conference of our secret society, right? We're all like, oh, it's so obvious, it's so obvious. But obvious doesn't always win the day when, you know, everyone's got important things to do, right? And you've got to figure out what, what's the value. And so communicating that is always a challenge, not just for I think for our field, but I think that's when wherever you're putting together any project. And so trying to communicate it to others that didn't grow up in the field has been, it's been nice because, uh, I think when you sort of give the right education and frame the right message and sort of laid it out, I think, you know, I've had a lot of good leaders that have been supportive and helpful in that space. But it is, uh, you know, it's one of those enduring challenges that you always have to come down to because there is a limited number of resources and, uh, you really need to stand up and stand on some good foundation and you've got to work at that when it comes to describing the value. Um, it's got to, you know, it's got to come down to something that's comparable to, you know, other stuff and it's just part of my existence in this field that, um, I didn't anticipate having to occupy so much of my time.

Speaker 3: Yeah, so that's a great one and I think, yeah, I think that resonates with all of us. So what have you learned? How do you? I mean, do you try to make a a cost case or how do you make the case?

Speaker 1: Oh, gosh. Um, It really does come down to, um, keeping it in the scope of a project and it's actually funny right now, I'm going through right the, uh, Ancy standards just put out human readiness levels, uh, about a year or two ago. And they make a good case about it in that document. So I would I would refer you to that reading, right? And, um, there's a lot of citations there. And so, you know, like I said, it's an enduring challenge. I think it's something that I'm still working on.

Speaker 3: Sure. So, I think I'm just going to push a little bit harder because I know you're in meetings where you have to just kind of on, you know, the spur of the moment explain what it is and what you're trying to do and and why people should care about that. What what kinds of, what are some of the key points you bring up to people who don't know human factors?

Speaker 1: So you're pushing, huh? That's the strategy here. I am. All right. Well then, um, I I'll respond. Honestly, what really helps is the Department of Defense and the Service Labs and the think tanks. And, um, we're talking a lot about autonomy, right? It's really helpful to use those resources where people describe the problems, right? So, when you actually lay out where things go wrong, there was a number of airline accidents, right? That that sort of happened that way or, you know, you have recent, uh, mishaps in vehicles and these kinds of things. I mean, it's really, uh, easy for people to appreciate sort of how that could have, you know, how that happened and what role the design and the technology and sort of how the human was left out of the situation, um, and what the bad outcome was. So I mean, you can use those examples, I think are really good. The challenge then is, um, figuring out what resources would it take not to have that happen. And so, the leadership that I have now and the the the groups that we have in partnership at in the DOD, like, I think we have a real buy-in uh across the board on what how important it will be for the human human autonomy sort of collaboration piece. And I think that it's, um, the examples that we have of where where it hasn't worked well that sort of compels people and and and you're right at some level you have to divide up funds and costs and I don't really have a an example to share there right now, uh maybe next time. So this is this is me pushing back here a little bit, but I I really think it's the the leadership across the government labs that helps, um, frame the problem. And it's the we have a lot of uh retired war fighters or you know, that that work in our company and they become advocates for us as well, right? They really appreciate what we're trying to do and they know what it's like to be in the situation. That's actually been maybe as strong as anything else in terms of being successful and keeping our programs running.

Speaker 3: So sometimes we've referred to this as the ambulance chaser approach. Sounds horrible when you say it that way though. Um, highlighting real disasters and uh, I know, but but but I think it is effective. I mean, this idea of pointing out um, real world things that have happened that are possibly preventable. I think that is a powerful way to get emotional engagement and help people, um, begin to see why it's important to, you know, think about things differently.

Speaker 2: To get back to those clinical roots, it's also referencing the dysfunction that can happen, right?

Speaker 1: Yeah, I mean, yep, it is. We know, we're trying to promote healthy, uh, human system inter operation, right?

Speaker 3: So, what advice do you have for people who want to build a career in cognitive engineering or or naturalistic decision making?

Speaker 1: Uh, don't follow the rules or something, right? Uh, set your own plan, be your own advocate. Uh, know that 51% of your job is relationships. I always sort of tell, you know, everybody I was at some panel and I was like, you know, 51% of your job will be at least 51% of your job will be relationships, right? But when it comes to the field and, you know, figuring out what you're going to do, like do that thing of like define, even though no one's asking, no one's going to ask you to like lay out the problem and the approach and the solution and the how you're going to measure it and test it. But if you have something you're passionate about, go put together your own plan and strategy and then start socializing it. Not a lot of people will have the will and the motivation to take the time to put together a thoughtful problem and a a methodology to a solution. I think that would help. If you're, you know, early in your career if you're waiting for someone to do that for you, you might end up feeling dissatisfied because it really is, uh, what you're interested in and what the rest of the world is interested in serendipity is not a great approach. Uh, describe what you want to do. There's a book that I read many, many years ago and the character in the book, it was a Atlas shrugged, yes, the very thick long one. But everyone talked about it. I said, oh, let me dive in. And there was one line in the book and it was about this, uh, female character that was in the early days of railroad development. Through all this turmoil, she got to the top of the the change, she became the president of this company. And they asked her like, well, how did you get here, right? Or what's your success and she's like, well, I just started walking through doors and nobody stopped me. So I always said that was an interesting thing, right? Just sort of move forward. Don't wait for someone to open the door, just keep walking. It's kind of the the philosophy I think that's been successful at least for me and I would share with others.

Speaker 3: Yeah, I think what you're this this this focus on relationships and being able to effectively lay out a problem is so important and this is not the stuff you learn in school. I'm thinking back on uh a podcast we did with Missy Cummings and um, you know, she was talking about how to get more people with this perspective in leadership roles. I think this is not a natural bent for a lot of NDM cognitive engineer researcher type people. So I I think these insights are really, really important, um, for our community as as we think about how to have a a voice in in the right places to to really make the kinds of of differences we want to make.

Speaker 1: It's funny to go back to another one of your guests, uh Eduardo Salas was the chair of our program. He's actually the person I think that accepted my application in our program and he suggested or told us or something, right? always when it comes from that it feels like a direction, not a suggestion. Go read uh who moved the cheese, right? Because all the business people are reading this book. Um, and if you want to fit in and be successful and get money for your projects, you need to think like the business people do, right? Know something and it kind of goes into domain analysis kind of things, right? Know the community and group you're in. I think that that kind of idea of like learning it for yourself and not waiting, right? Like take it by the horns a little bit, right? That's probably what got me to thinking that way.

Speaker 2: So Kevin, you consider yourself a cognitive engineer, is that correct?

Speaker 1: Yes.

Speaker 2: All right. So let's say you meet a complete stranger who claims to also be a cognitive engineer and on the pain of death, you're given one question to determine if they indeed are a cognitive engineer. What would you ask?

Speaker 1: What would I ask? Oh, the pain of death. Well, you guys high stakes, man. You're pretty serious. Uh um I would ask them uh you're putting together a project, what's your first major step? And I would expect them to say something that sounds like domain analysis, right? If people even start jumping into I would go ask the experts or whatever, right? I would feel like you're missing the opportunity to understand the the realistic, the the natural world problem kind of thing. There's also this uh, at a Harvard Business uh school or whatever, there's a a marketing group that does something called jobs to be done or something. It actually plays a lot into this where they apply like this business model in the background about, you know, defining market space and stuff. But the upshot is is um, from a cognitive engineering and more specifically in NDM, if you really want to have solutions that you think you can deploy, you got to first on your own, read a book, watch a movie, observe people in the job, right? Build up your head on and it's fun, right? I think that's the interesting part about learning about how things I've never thought of before, how people do that work, right? Now you're in a better position to select the right experts to work with, right? It's too easy to grab, uh, I'm doing an army project. Let me go get the first, you know, army kernel I know, right? It sounds like you're getting uh a good SME or stakeholder, but you really need to jump into the domain first and that's what I would expect someone to respond with.

Speaker 2: What domains have you jumped into that you recall that first swim?

Speaker 1: Yeah, um, Army aviation. aviation, I always thought the Air Force, right? And I cannot remember the movie, so I thought about movies it's a documentary and I just did not appreciate the level of, you know, notionally I got the level of threat and that kind of thing, right? But I just not appreciate the danger it is and the scout work that they do and the risks they take, right? And that their job is to support the ground, right? There's all these complexities about sort of what they do and I just had no real notion of it and I'm sold, right? I'm like it is a is a tough uh, honorable job and I'm really proud to be working with those guys.

Speaker 3: So Kevin, you've mentioned a few names along the way, but I want to ask, um, who are three people that have influenced your approach over the years?

Speaker 1: I think I'm going to cheat a little bit here. I'm not going to go I'm going to kind of go with groups, right? So let me just, um, Gary Klein and the naturalistic decision making world, right? Laura and Brian, uh, your all's work and all the others that fall in that community, like I said, I got started through textbooks. So by proxy, I'll just take the NDM community, right? It's uh, I'm grateful to have found it because it's I think it's been a useful useful set of tools and methods, right? And then I've got uh, friends, right? I've got Pete and a buddy Jonathan and like these are people that have uh influenced me and just sort of like uh knowing me as a person, help me uh figure out how to think about having good ideas and selling good ideas in that order. Pete Terence is uh, he's a graduate uh colleague of mine that we're still still friends and if I ever have a really nerdy thing that I need to think through, I've got this like collective other brain to tap into that, you know, really helps. And uh the final sort of is this uh group within Lockheed Martin is called the Advanced Sim Center and there's sort of engineering talent there, it's, um, Mark, Dave and Richard and they always sort of help me work through that kind of stuff. But there was a to round out the sort of like uh influence for me. There was a senior manager this guy Wayne Savinkus and he was probably the first one of my career that just sort of gave me some freedom and sort of said, uh, reinforce that message of walk through the doors, right? Have a plan, sort of like don't let someone else's bad template ruin your story, right? So, uh, he was a program manager that really, you know, said, if you have a good problem, don't give up on the first try. And I think that, you know, as we talk through this podcast, I am sort of like you talk about therapeutic stuff, Brian, I'm starting to have my own session here, right? realizing how I got where I am. He was the one that started saying just hang in there, chase the right problems and don't worry about the other stuff and and by and large he's been right. Probably that group of folks has really helped me um, feel like I've had a successful career.

Speaker 2: We will bill you after the session. Yes.

Speaker 3: Gosh. So looking forward, what challenges would you like to see the cognitive engineering and NDM communities tackle?

Speaker 1: Oh, let's continue on the human autonomy things. I need more funding there. So, I think that's part of it, you know, I I expect to see that. One thing that's interesting about me is I have this visual impairment and it's not fair because, you ask me the community, I'm sure the community might be doing things I'm just unaware of. It's probably my fault for not raising my head up and looking. But, you know, sometimes I think about, you know, what I might want to do in the future and maybe it looks like supporting people with disabilities, right? That's a part of my community and I've got this, you know, I'm legally blind as a person and I have my challenges. It'd be interesting to see, you know, the engineering, uh, methodologies that I love so much be applied to things that matter to my personal life. Um, and I'd like to see maybe more focus and training too. I think that, you know, we talked before about different groups and communities. I know there's some things, but beyond design, it would be interesting to think about how do you create content for training. I think that could be a something that would grow over time.

Speaker 3: Cool. Yeah, those are three exciting areas. So, I now have uh, a sort of fun question to wrap things up.

Speaker 1: Fun. I'll be the judge of that.

Speaker 3: So, I'm going to ask you to tell us two truths about yourself and one lie. And Brian and I are going to try to guess the lie.

Speaker 1: Oh, good. Let's see. So, uh one is that, um, one time I won a mechanical bull riding competition. I was the vice president of the PTA and or I used to be a cheerleader.

Speaker 2: Hmm.

Speaker 3: Okay. Brian, do you want to go first?

Speaker 2: Not particularly. I will say that you are never involved in PTA. That's the lie.

Speaker 3: I'm going to say that you are never a cheerleader. That's the lie.

Speaker 1: I rode a mechanical bull once. There was no competition, but I felt like a loser. So, um, that was the lie. I am currently the vice president of Sunrise Elementary, my son Slade is a proud first grader and I'm so busy with work that I figured volunteering and working in that group would help keep me involved in his school stuff. So, I'm a proud member of the Sunrise Elementary Go Eagles. And uh when I was in high school, yes, I spent uh a long, I don't know, three or five uh sessions as a cheerleader for Deltona High School where uh yes, I didn't make a career out of it, but I do have that experience. So, sorry guys.

Speaker 2: Neither one of us got that one. We we need to stop doing this. Yeah. I am particular, I'm doing terrible at these, but I thought about just giving uh, you know, sort of all lies or all truth and seeing how that would play out, but um, I feel pretty successful here, so that was good.

Speaker 3: Well done. You fooled us both. Well Kevin, thanks for speaking uh with us today. This has really been a pleasure.

Speaker 1: Pleasure's all mine. I totally enjoyed it and uh like I said, you know, it was through your all's work and writings that sort of pulled me in and thank you all for your good work. I enjoyed it.

Speaker 3: Thank you. So on that note, thank you for joining us for the NDM podcast. I'm Laura Milatella.

Speaker 2: And I'm Brian Moon. Learn more about naturalistic decision making and where to follow us by visiting naturalisticdecisionmaking.org.