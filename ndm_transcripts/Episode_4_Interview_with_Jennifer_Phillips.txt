The Naturalistic Decision Making Podcast with Brian Moon and Laura Millettello. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress.

Welcome to the Naturalistic Decision Making Podcast. I'm Brian Moon from Perigen Technologies.

And I'm Laura Militello from Applied Decision Science.

Speaker 1: Today we welcome our pal, Jennifer Phillips. Jenny is the CEO of the Cognitive Performance Group, which she co-founded in 2006. Her work focuses on expert decision-making, primarily in the military training community. She and her colleagues at CPG have pioneered research into the development of skilled performance and design innovations in the areas of decision center training and assessment, including the development and application of mastery models. Among her many publications is a chapter in the Oxford Handbook of Expertise, exploring mastery models and their value in supporting the acquisition and assessment of expertise. Welcome Jenny and thank you for joining us.

Speaker 2: Thank you, Brian. I am really happy to be here with you and Laura.

Speaker 1: So we want to just give the audience a sense of the kinds of projects that you've worked on and you can you can deliver them as you choose. But, uh, yeah, just give the audience kind of an idea of the sorts of projects you've worked on.

Speaker 2: So yeah, the kind of the projects that I typically work on have to do with how individuals develop expertise in a particular domain. So the the application area for that work is typically in the training and education community. So many of my projects focus on how we can develop training to accelerate expertise and what are the sorts of instructional strategies that one would use to do that? Um, and also in the area of assessment. So how would you know whether someone is uh is improving in a particular area and whether they're um developing additional cognitive skill. So I've gotten to sort of specialize whether it was intentional or unintentional, I think it was entirely unintentional, specialize in the uh Marine Corps ground units, um specifically small unit decision making. So I've done a lot with um what what is tactical thinking and how do small get better at tactical thinking. Um, I've worked with Carol Ross and others on developing an assessment battery for small unit decision making. I've worked with instructors in the Marine Corps. I've worked with intelligence specialists in the Marine Corps. Um, I guess one of the main threads and you mentioned this in your introduction is is mastery models. Um, many of these projects have focused on how do do you develop over the course of your career through stages of development from a novice to an expert and if we can understand what each of those developmental stages looks like, within the mastery model, then we can both diagnose where an individual is on their developmental cycle right now, and then we can also prescribe some strategies to help them get to the next level of development.

Speaker 1: Right. So in the mastery models, tell us what you mean by sort of stages? So is is this explicit, um, sort of explicit stage gates where you see people passing through stages or what does that mean to be in a stage or passing through to another stage?

Speaker 2: Sure. So the the mastery model is a term that that uh we coined. I don't know that you'll find it in the literature except in in our literature, in our publications. Uh, but it's it's a developmental model and it's based on Dryfus and Dryfus's five stages of cognitive skill acquisition. Um, a novice being the first stage, then an advanced beginner, then a competent performer, a proficient performer, and an expert. So a lot of the research in the NDM community used to focus on expert novice differences and identified all of these, um, all the things that an expert can do that a novice cannot do and compared and contrast those two extremes. But, but what we've found very interesting is all the intermediate stages between a novice and an expert. And if you think about it, most of the people that you work with and most of the people that we interview are probably somewhere, uh, they're they're neither novices nor experts, they're right in the middle. So the mastery model uses those five developmental stages. There are kind of hallmark characteristics of performance associated with each of those five stages. Um, and it's it's really interesting, no matter what domain you look at, you see those general characteristics of how people perform come through. And so what we've done with this mastery model approach, um, is really generate a means of, um, of eliciting knowledge from performers in a particular domain and describing in detail what each of those developmental stages looks like for their domain, uh, and using that as a basis for assessing a person's current level of proficiency and recommending uh, feedback and instructional strategies and other sorts of approaches to get them to focus on how do I get to the next stage up from where I am right now.

Speaker 1: So can you give us kind of an example of for any of the domains you've worked in of um, sort of what what a couple different stages might look like for a given person or role?

Speaker 2: Sure. So one of the, uh, mastery models that that I think I'm most proud of or that was a a project that was the most fun to put together and this was an effort that I teamed with Carol Ross and and others at CPG on was the instructor mastery model and this was a project we did for the Marine Corps. Um, what we found was you would have individuals who were given a a an assignment in a Marine formal school who had been out in the fleet and who were infantry Marines or intelligence Marines or pick a specialty area, and they were subject matter experts in that sort of a job but then they got to the school house where they were instructed to teach and, uh, they didn't know it was a completely new skill set instructing from from doing their their day job there, uh, you know, being a Marine rifleman or or what have you. So it was very interesting to look at how individuals transition, um, once they get to the school house and they're asked to instruct. So for example, at the novice stage, stage one, they really are focused on a procedure, a script in the classroom. So they, um, they have their PowerPoint slides and they're told that this is a procedure that you can use to gain students' attention right off the bat and it's very uh formulaic and and scripted in terms of how they present a period of instruction. Um, as they get to become uh an advanced beginner, a stage two performer, they start to realize, it starts to dawn on them, oh wait a second, this is not about my performance and what I do as I stand up here in front of this the classroom. This is really more about the students and the learners and, um, how to facilitate their understanding of these concepts. So they have a pretty pretty big uh switch in their mindset of how they even think about the job that they're performing. Um, at level three, the competent performers, they, they get pretty uh, good at delivering instruction but they get pretty locked into the, the plan that they have for that classroom or for that class period. They get pretty locked into, um, what they have prepared for the session and they have a hard time adapting if students don't understand their examples or if uh, students have questions that are not ones that they prepared to answer. So you see them, um, and this and this is one of the big hallmarks of performance for a stage three performer is they're very good at putting together a plan but they really don't want to do anything other than the plan that they've put together. So so they get locked in. Um, at level four, they become a lot more adaptive and they recognize that they need to rely on the expertise or the experience at least that's in the classroom among their students and they can be pretty fluid and and um adjust to student questions that come up, to other examples that students might have and, um, and can start incorporating that more into their instruction. So, so it's really interesting to see, um, this this maturity and this this skill unfold over the course of those stages.

Speaker 1: Yeah, that's a tremendous amount of detail at each stage. That's what always impressed me about the mastery models is how much you all are able to unpack in each stage. Um, and so obviously mastery models is kind of a big part of, uh, of the solutions that CPG, um, promotes in terms of business development. Are there other sort of skills or or specialty knowledge that you and your colleagues are trying to promote as you go about business development?

Speaker 2: So one of the areas that we've found ourselves very involved in is assessment of decision skills and assessment of of performance and cognitive skill development. So the mastery model is is one foundation that we've used and we've generated, um, observation rubrics and other performance rubrics to match what you see in a person's performance to a descriptor of one of those five stages. Um, it's uh behaviorally anchored rating scale is the the, um, type of instruments that we've developed. Uh, but, but beyond using mastery models for assessment, we've also gotten into, um, other measures of decision-making and complex cognition, um, measures of adaptability. We have a project that we're doing right now. Uh, Allison Hancock is running this effort on how what is adaptability to a a small unit leader? And, um, what are, we've hypothesized that there are four steps in that process of, of adaptability. One is recognizing the indicators in a situation. Another is understanding what they mean for how the situation has evolved. Another is figuring out what's going on right now, and then the final one is actually making a decision to adapt and knowing how to adapt. So, so we've worked on developing metrics for adaptability. And more so than that, how do you capture those in a in a repeatable manner where you're not requiring a human uh, a human observer, um, a human rater to provide a subjective opinion of performance at each step. And, uh, this has been a really fascinating area. So, so to answer your question, I guess in general, what we've focused on is how can we leverage technologies, how can we identify in the realm of the data that is available, the big data that's available right now through training exercises and such.

Speaker 1: So it sounds, so it sounds like you're, I mean, you're really expanding this idea of sort of the naturalistic part of naturalistic decision making to take fuller advantage of everything in nature if you will, right? So it's not just interviewing and observing, uh, but really to look even within the environmental context and the artifacts that people create and get left behind here. You're really expanding that sort of, you're expanding nature if you will in the NDM, uh, paradigm.

Speaker 2: For sure. And, um, I think that it's been, it's been fun to look at, um, not only ways that you can collect data that have to do with smart subject matter expert observers providing ratings of performance but also other indicators that would be available from other sources in the environment. So, um, video, data that you can derive from video uh, videos of how people are moving around on the battlefield or data that you can derive from audio communications, um, and and blending all of those together in a manner that paints a paints a picture about what people are doing, um, when they are triggered to make an adaptation, when, you know, what's the time between uh, the time that that an event has occurred and and a person knows that they actually need to do something about it, uh, and and putting it all together in a way that tells you something about that individual's decision skills or, uh, tactical thinking skills or ability to adapt.

Speaker 3: Cool. So hey Jenny, as you're talking, you were saying that you feel like your career has kind of been by design but some of this niche stuff has has really just been opportunity. Um, and so I'm thinking about your focus on training and assessment and all this work in the Marine Corps and I'm wondering, are there certain kind of influencers as you reflect back on your career that that helped you find your way to to where you are now?

Speaker 2: I think, um, the two main influencers in my career have have really been Gary Klein, who I know you talked to earlier in one of these podcasts. Um, and Carol Ross. Those, those individuals have, um, shown me how to do research in a in a naturalistic setting, which, um, which means a lot of things, right? It means, uh, you're never going to get it right the first time. It means, um, you're going to have to be as adaptive in your research as you're the experts that you're interviewing in whatever domain have been. Um, it means you, it means you really need to look at what is the interesting question to be asking. Um, the the way that you pursue a a research plan or pursue a project is is never what you thought it was going to be when you when you started it off. And and there's always another interesting question to ask and to address. And so, um, the ability to, you know, to look at what's the need, look at what the what the operators really need in order to do their jobs better and, um, and look at what are some potential solutions that are out there, whether it's technologies that exist or, um, or other examples to use as, um, you know, as as kind of templates to to apply in their domain. It's it's kind of a matter of piecing those those pieces and parts together. And I think that's something that that I kind of learned as I watched Gary and Carol in in their work.

Speaker 3: Yeah. And so the path. Sorry, please go on.

Speaker 2: And so the path just takes you where it takes you as you, as you work to solve real world problems with scientific research.

Speaker 3: Yeah, so that really resonates with me. I know we have a lot of the same mentors in our background. Um, but I'm also wondering if you think outside the NDM community, as you've gotten more involved in, um, training and education, um, and even this kind of big data assessment. Are there, are there folks from outside the NDM community that you kind of have pulled their work in and integrated it in interesting ways?

Speaker 2: One of the things that, uh, where I spend most of my time and technical work right now is actually in the, uh, Dr. Peter Squire's program in the Office of Naval Research. And he has performers from Lockheed Martin and Soar Technologies and Charles River Analytics and, um, Design Interactive and a number of other organizations that I would say, uh, are are not NDM sorts of organizations but they're definitely human performance and, um, artificial intelligence and machine learning sorts of organizations. And, and the people in those organizations are, they're they're lots of them, the individuals who I've had an opportunity to work with through Peter's program. Um, so certainly, certainly I've been influenced by, um, the Richard Shafer and Brian Stanzrood and and, um, James Nihouse of the world who understand what technology can do and what it can capture. Um, so, so that's one area of influence. Certainly they've opened my mind to what's possible and and what we can capture, for instance, for, uh, assessment and how automation can pair with humans to give a better answer. Um, the other kind of group of people that I've found that you have to have on any project and any work that you do are the are the tactical experts. Um, so we've, we've worked pretty closely with an organization called Covan. Um, Marcus Mines is one of the individuals who's the, um, the barnstormer there in terms of, um, pushing pushing techniques forward for doing better after action reviews and and supporting the development of of small unit leaders, um, and other, uh, battlefield commanders. So, so that marriage really of the the tactical experts and the technology experts and the the researchers has worked so nicely and I, uh, I I don't, I don't want to ever do a project without the the support of those other sorts of teammates.

Speaker 1: So, so you mentioned Peter Squire and, uh, and as as one customer example. What what are you finding, um, from Peter and others that that seems to be most, uh, attracting them to your work? So, uh, what kinds of, uh, what kinds of aspects of what you all do and and what you in particular do, do you think that they're really, um, sort of gloming on to as we have to have Jenny and CPG do this, uh, because nobody else can do it this way?

Speaker 2: I think there are a couple, um, contributions that we bring to those programs. And, and one of them is the focus on the com complex cognitive skills. So the, um, as, as you all know, because I know you work in these same domains, decision-making and problem-solving and situation awareness and and all of those complex skills are are tough. They're, you know, there aren't a lot of people that like, that really, uh, want to dive deep on those. And, and so there's some some pretty wicked problems to figure out how you operationalize them and how you how you how you define what decision-making and adaptability looks like in a real world environment. And so taking that context and and bringing it to a place where you can, you can measure it, where you can measure skill in the real world in the wild, I think is certainly one of the areas that that CPG brings to the table in those programs. And I think the other thing that that we bring is, uh, we've always had individuals in our organization who have experience in the military and experience in the Marine Corps and the Army. So that understanding of the user community is certainly another element that we bring, being able to do the translation between how a marine sees the world and how a how a scientist or a technology developer sees the world and finding the marriage point between those two. I think that's another thing that we've brought to these programs.

Speaker 1: Yeah, it sounds like that translation, uh, between customers and uh, and researchers is particularly important when dealing with the military, um, and and you all have sort of, uh, cracked that nut and being able to sort of talk both ways. Uh, so just from your perspective, um, I I know you never served in the military, uh, but you've done lots and lots of work in military domains. And and I'm wondering, um, have have you, uh, has it been a challenge for you to come into, uh, military domains that you weren't previously familiar with or, you know, sort of get up to speed and, uh, and and learn the lingo and understand, you know, how those people operate. Has has it been a challenge in your work?

Speaker 2: It certainly is a challenge in some ways because the domain is always evolving. For example, as soon as you think you know what an accra what an acronym means, they go and change it on you. You know, there's I think there's a built-in, um, requirement in the some unwritten requirement in the Marine Corps that, um, whatever the concept is that you're dealing with right now, it must not last for more than three years, it's going to have to change. So it's difficult to keep current, that is for sure. However, I think that the NDM community is in a unique position compared to others, uh, in terms of understanding the user group because we do cognitive task analysis. And it's these cognitive task analysis interviews, um, where we're eliciting knowledge at a really deep level that allows us to understand the domain much, much better than any any other researcher or technology developer could, uh, because they're doing, you know, they're doing site visits and they're talking to the user community, the military user community, but they don't dig into these people's experience, their, uh, challenges, their, the tasks that they do on a daily basis in a way that we do as interviewers. So that's certainly, that's an activity that gives you that's kind of dual purpose, not only does it allow you to meet the project goals and describe what that expertise looks like, but it also gives you a very good flavor of of how the user community views the world and what they need to do in order to be successful, both from a cognitive perspective as well as like an organizational culture perspective. And it's fascinating.

Speaker 3: Right. Is is there any, uh, area that you have tried to sort of get traction in and this could be a domain or particular customers that maybe you thought would be more receptive to to these kinds of approaches? Have you kind of struggled to get traction anywhere? Um, you know, are there things you've tried to pursue, pet ideas that you just can't seem to get folks interested in or or get them to sponsor?

Speaker 2: Certainly one of the areas that I see a lot of application of what we do, uh, is law enforcement. Um, talk about people that are making split second decisions, high stakes, uh, just very ill-defined sorts of sorts of uh environments. Uh, law enforcement, I have a whole lot of respect for the tough job that they do and it would have been it would have been very neat to be able to apply some of these methods and and apply some of this work to law enforcement, but, um, that's an area that I've that I've tried to tap a few times during the course of my career and it just never seems to pan out.

Speaker 3: Okay, so I have another question for you Jenny. I know that you have done lots of field research in your life and I'm wondering if you have a favorite story from some kind of observation or interviews or, um, just a really fond memory of a time when you were immersed with with some some, uh, folks who have to make tough decisions.

Speaker 2: So that question takes me back to a project that I worked on, um, with with many others, um, the IED defeat work, the improvised explosive device defeat work. So this was, this line of research was soon after 9/11, um, we the military had troops in Afghanistan and in Iraq and if you remember, um, we as a nation had a well, all of the coalition forces had a pretty big problem with these roadside bombs, these IEDs. And so at that time the Department of Defense was trying to throw a lot of money at advanced technologies to detect these devices and better protection and armor and such in the vehicles to protect Marines and soldiers, um, and one of the areas that we had the opportunity to get involved with was the human element of this, the human expertise element of detecting where the devices were going to be in placed. Um, and the reason that this this project was so interesting to me and so rewarding, um, it truly felt like we were in a position to make a difference in, um, in Marines and soldiers lives and I and I think we were, uh, we got to interview a number of young Marines who had done some really, really challenging jobs, um, and who had seen some terrible things in their lives and and to be able to extract their expertise and and see, um, not only what they had been through but also the the skills that they developed. I mean, talk about richness of, um, of a domain. Every single expert novice difference that exists out there, you see in this in this domain of, um, of IED defeat, of of being able to notice these these roadside bombs and and kind of anticipate where they'd be located, um, you see, you see these Marines seeing the invisible, um, recognizing when things that should be there aren't there, you see how they put themselves in the perspective of the adversary and think about where they would in place, um, given the terrain, given the time of day, given where the sun is in the sky. I mean, this whole range of rich factors and cues that they would rely on too to know that they were getting into a danger zone was just fascinating intellectually, but it also, um, I guess was so rewarding because we were making a difference in terms of how people were being trained to deal with the IED problem. Um, so that's a certainly an experience and and a program that stands out in my mind, uh, one that I'm, I'm proud of how we were able to support our war fighters.

Speaker 3: Yeah, that's sort of the dream of every applied researcher is to be able to do something quickly enough and get it to the people that really need it that it it makes a difference. That that that's awesome that you're able to be a part of that.

Speaker 2: Yes, definitely, definitely, um, you know, it's fun to, it's fun to talk about these experts and it's fun to talk about what we're seeing in their cognition, but Laura, I think you nailed it on the head. What we really care about is generating solutions that make things better for them. And so, um, any opportunity we have to to turn around a product that's that's actually working for someone or to turn around a new process or or new training or whatever it is that actually gets used is, um, that is a day on the beach.

Speaker 3: Right? Yeah, that's that's the dream. That's the dream. Very cool.

Speaker 1: So I happen to know a little bit about that work, um, and what I thought was particularly challenging, uh, in that project, uh, was, you know, we we think about experts and they sort of develop expertise over time, uh, in this particular domain because everything was happening so fast that is, uh, you know, the the the adversary was adapting even more rapidly it seemed than, uh, than our folks. And so expertise in that sense, uh, was extremely contextualized and both in sort of time and space. And so, um, even as a Marine might develop expertise in a particular area and and understand the social cues, um, those are going to change when they go to the next region, right? And so I always thought that was an interesting aspect to the work because if you think about expertise in nuclear engineering, for instance, yes, there are changes over time in that domain, but not at the rapid pace that you saw, um, with the IED defeat.

Speaker 2: You're absolutely right. So we were looking at Afghanistan and Iraq, so two very different areas of responsibility. We were also, you know, you would find even within one of those countries, the different regions, the different neighborhoods would have the insurgents would have different techniques for, uh, implacing and and triggering and all those things. So you would hear stories in the interviews about, um, in one town anytime there was a rug that was hung over a balcony, then that meant that there was going to be an attack that evening. Okay, so that's a cue that we, you know, you would pull out in your interviews, but that's not one that that is going to transfer to a different context necessarily. So, so what do you do with that? It's, yeah, it goes back to the question of, well, how do you take this information and and build something that's going to help someone else, um, in in any context. So we, we did have to work pretty hard on identifying some of those commonalities. Um, so one example of a commonality might be, um, a a trigger point. I think that's what we called they called them trigger points. So if you've got a radio controlled IED, um, you need to have a spotter that's located somewhere in the terrain who can have eyes on the road and they need to be able to judge where the the blue forces, where the the Marine are located or, or, you know, at what point to trigger the device based on where they're located on the road. So in some context you would find they would use a a post, a telephone poll post. In other context, they would build their own little rock formation right next to the road. Um, in other cases, they would use they would, you know, use spray paint or something like that to mark a section of the road. So the the concept, the technique was similar across domains even though it might have been implemented, I'm sorry, across context, even though it might have been implemented a little bit differently depending on what was available in that particular context. So, so there are, there were some ways that we were able to find to make lessons learned from one context apply to another context, but, but, um, but yeah, you're right Brian, we had we had to be careful about that.

Speaker 1: And the the application there was, um, I think you mentioned it into sort of a, a a game, a video game, uh, where the, uh, Marines could sort of play the adversary and consider where they might, uh, try to, uh, hit, uh, with an IED. And so can you talk just for a few minutes about, uh, this idea of using games and using, uh, uh, video games in particular and and your sort of, uh, mantra that I've heard you and Carol mention about this cognitive fidelity, uh, and how some of the training applications, uh, ought to be focused a bit more on this idea of cognitive fidelity.

Speaker 2: Sure. This was, uh, this was just so interesting. I mean, one of the big findings that that we, uh, that came out of that CTA was the the Marines who were really doing a great job at being able to, um, recognize a danger zone in advance were the ones who were thinking like the adversary. I mean, it sounds like a pretty simple thing and and like no kidding, of course they were able to to put themselves in the adversary shoes, but, but we thought this is something that young Marines, the individuals who are deploying for the first time don't know how to do. They've never had the ability to, um, you know, outside of a training environment and that's not something that was really taught in training, at least not in a standard way. They've never had the opportunity to be, um, to think from the the other guy's perspective. So we used the VBS technology, we teamed with Bohemia Interactive and we built out a video game, a module in VBS where the Marines were role playing the adversaries and they were responsible for implacing IEDs in the environment. So we were essentially putting them in a position where they had to think through how they were going to, um, be effective in in denoting an IED of whether they were going to use a self-detonating IED or, um, uh, you know, another sort of IED, they had to they had to really think through when is the blue force convoy going to come through? What is the time of day right now? How can I disguise it? Um, what would be a good ambush zone, all of those kinds of considerations, um, that are happening in the real world. Now, if you, if you know VBS, you know that it's got pretty good physical fidelity but not great physical fidelity. So to your question about the cognitive fidelity really mattering, it it it didn't matter that the that the physical video game environment was perfect or that, you know, the leaves on the trees were were blowing in the wind exactly as they're supposed to. What really mattered was we were putting the Marines in a position where they had to think through the problem, um, through it from a different perspective and, um, and that ended up being very successful.

Speaker 3: Nice. So I am going to switch gears a little bit, Jenny. I know, um, you're the the CEO of CPG and so I imagine now you're in the role of actually mentoring some young researchers. And I'm wondering, um, what is surprising to you as you work with uh, young people today?

Speaker 2: Surprising that they're so so technically savvy. They know they can build things in technologies that I just can't do. Um, they they are simplifying a lot, I mean, a lot of the things that we used to do by hand, um, data capture and data processing and, you know, all these, uh, you know, note taking and things. They're, um, they're able to make so much more speedy now with their, um, by by quickly throwing together a macro and Excel that's going to do the job for us. Uh, it's it's amazing to me their their ability to work with tools and understand how to make a tool work for you for a whole new novel purpose. It's really wonderful. It's really wonderful. That's probably not what you were getting at with that.

Speaker 3: That is a great response. Yeah, yeah. I I I I mean, that's resonating with me too. It is fascinating. I feel so spoiled when I work with young people who can just figure that stuff out. Yeah. Yeah.

Speaker 2: Yes. Well, and I found that you yes, it's um, articulate the question, articulate the problem that you're trying to solve and just let them go after it and they will come back with some with some solutions that that I would have never dreamed of, you know, here I am 25 years into my career and we we study expertise, right? And so presumably I'd actually have some expertise in in what I do but the solutions that others that these young younger researchers are coming up with just blow my mind. Yeah. It's really neat.

Speaker 3: And so it does make me think of our days long ago working at Klein Associates where I feel like there was a lot of that same strategy, like just give us a problem and and see what we do with it. Um, and it is, I I recall that as being very rewarding as a young person to to, I mean, it was stressful, but then once you came up with the solution, you felt really good about it. So I think that's a great mentoring technique.

Speaker 2: That's right. That's right. Well, and I've, um, you know, this the mentoring and the the coaching is something that I that I think about a lot because, you know, right, because it's, um, I I don't want to be one of those lone wolf researchers that's very that, you know, that's that's good at what I do but is not also, um, developing others to also be be good at these things. And so that means kind of, you two know me a little bit, right? I'm a little bit of a control freak. I got a little bit of OCD going on. So that means, um, letting go of some things and and just posing a problem to someone else and and letting them wrestle with it and and letting them, um, letting them come back with you to you with an approach and then just kind of talking it through with them. Um, I found that that I learn as much from them as I think they're learning from me, which is, which is really, which is really great.

Speaker 3: Yeah. Yeah. That's really nice.

Speaker 1: So you talked earlier about identifying expertise in the various stages of expertise and I'm wondering, uh, how we think about expert NDM practitioners. So, uh, let's say for example, you you meet a complete stranger who claims to practice NDM, uh, and you only have one question to determine if they do indeed practice NDM, uh, and are an expert practitioner. What what question would that be?

Speaker 2: So this is the easiest question that you've asked all day, Brian. Uh, my answer to that question is, um, they need to so if they're one question to determine if they do indeed practice NDM. The question is, tell me about the recognition prime decision model.

Speaker 1: Oh. Fancy.

Speaker 2: I think I still come find myself coming back to that, um, if they, if they understand what it is, and if they understand the very that there are actually variations on it, uh, then then they are a true NDM researcher.

Speaker 3: I like that.

Speaker 1: Interesting. All right, so so now I'm going to ask you the hardest question you've heard all day.

Speaker 2: Oh goodness.

Speaker 1: All right, we want you to tell us two truths about yourself that our audience probably doesn't know and one lie, right? So we want to we want to hear three things from you about yourself but only two of them can be true. And Laura and I are going to guess which one is the lie.

Speaker 2: Okay. So, I used to do triathlons. I've worked remotely for 20 years of my career and I was my high school's Miss Pac-Man champ in 1991.

Speaker 1: Laura?

Speaker 3: I don't believe you were the Miss Pac-Man champ in 1991.

Speaker 1: I don't believe you've ever completed a triathlon.

Speaker 2: Ding ding ding for Laura. That's right. So I've completed triathlons. That doesn't mean that I did them well, but I, I I used to be, so I, I used to be a swimmer. I was a swimmer, uh, for my, yeah, through through college and, uh, I went to Kenyon College, uh, coach Jimsteen, uh, a marvelous, marvelous person, I guess another big influence in my life, um, used to require that all students did triathlons at the beginning of every season and I used to hate them. They were terrible, terribly painful, terribly painful. Um, and then after that I turned into a runner, um, which which is also I never I never imagined I would do that, but

Speaker 3: Do you still run?

Speaker 2: But life. You know, I, um, I try to run. I try to run. Um, the older I get, the more injury issues I have, so I'm kind of, I, I, I'm in for a while and then I'm rehabilitating an injury for a while and then I'm back in for a while and that seems to be my cycle now.

Speaker 3: Same with me.

Speaker 1: All right, one last question. So, uh, so where are you looking to take your research uh, next? What's what's up next for CPG and you?

Speaker 2: The thing that I am most interested right now in is making mastery models work, um, on a on a larger scale. We have had this is this methodology and the representation of how expertise develops in a domain resonates so well with the user community, resonates so well with, um, everything that I've seen in my career, this ability to be able to identify five stages of development and define them and assess people on the basis of that and and focus on how to, um, how to get them to develop their skills to the next level, um, it works, it just it works. It works really well. But the challenge is how to how to scale that in a way that, um, people other than CPG or people other than an NDM researcher can do that, can can elicit the knowledge, can describe those five stages, can turn that into assessment tools and and training tools. So that's my, um, that's the nut that I want to crack over the next five years of my career is, um, mastery modeling for the masses.

Speaker 1: Fantastic. Do you have a name for it? Yeah, I, I I think that's super important. Um, and the point about, you know, others being able to do kind of, uh, what we do and and others to be able to take fuller advantage of NDM, uh, and the theories and the and the techniques. I think that's incredibly important for our community. Um, you know, in as much as we would all love to have non-stop work and be able to train, uh, people to work in our companies and that sort of thing. Um, this idea of of sort of proliferating the ideas out so that others can, uh, scale them up as you said. I I think that's incredibly important just for the community in general is to figure out better ways to do that. Um, and that and that's a very hard problem, I think. Um, it's almost like how do you, how do you proliferate expertise, uh, and we're experts in the NDM approach and, uh, in the science and the and the applications, but getting that out in such a way that it doesn't get watered down, uh, I think is the other important challenge there. So not just scaling but scaling in ways that retain, uh, you know, the the the true principles that, um, drive our work. I think it's really important.

Speaker 2: Yes, I I agree and that, you know, that we may need to make some decisions about tradeoffs, right? So, um, so if we can get an 80% solution, I guess that's one of the other things that I've that I've learned and I've come to really, um, understand and incorporate into what I do is, you know, if we can get an 80% solution on ideal or even a 70% solution on ideal, it's still better than where we were before, um, and and we're still, we're still helping the war fighter do do a better job than, uh, or or support them in ways that they didn't have before. So, so baby steps and quick wins are what work.

Speaker 1: Agreed. So, uh, thank you very much Jenny for speaking with us today. I look forward to someday challenging you to a Miss Pac-Man duel. That sounds like our next, uh, key adventure together, but it's been a very, uh, pleasurable time speaking with you and on that note, uh, we are for the NDM Podcast. I'm Brian Moon.

Speaker 4: And I'm Laura Militello. To learn more about naturalistic decision making, follow us at naturalisticdecisionmaking.org.