(Music)
Speaker 1: Very much the direction of travel has been on automating, automating the tasks to take away some of the, you know, the manual work from people, you know, take away the potential for the error and things like that. And it's incredible what we can now do with technology, but there's a few challenges with that. One of which is that if you're automating things, what is it you're losing in that? You know, the skills that people had, although they might have been laborious and manual. Are you losing some ability of people, you know, in their, their development and how they learn.

(Music)
Speaker 2: The Naturalistic Decision Making podcast with Brian Moon and Laura Militello. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress. Welcome to the Naturalistic Decision Making podcast. This is Laura Militello from Applied Decision Science.
Speaker 3: And I'm Brian Moon from Pareg and Technologies.
Speaker 2: Today we're fortunate to speak with Wendy Jefferson. Wendy is founding CEO of Let's Think, a new startup which produces domain specific technology, designed specifically to support complex analytic thinking. They specialize in engaged intelligence, enabling their clients to think brilliantly. Dual qualified as a commercial lawyer and business psychologist with domain expertise in health care and financial services. This is Wendy's second startup. As co-founder of Cybernetics, Wendy was instrumental in their original vision, the growth phase and the acquisition of her first company by Nasdaq. At Nasdaq, she was head of research and ideation and led a unique team of experts that combined behavioral science, financial domain knowledge and advanced analytics to bring diverse thinking and cross industry experience to designing and delivering technology to solve some of the biggest challenges challenges facing the financial sector. recognized as a leader in her field, Wendy regularly delivers keynotes around the world on topics as diverse as artificial intelligence, surveillance, technology design, cognitive engineering, organizational resilience, and conduct and culture. Wendy also previously served as a board member for the Copenhagen, Helsinki, Iceland, and Oslo Nasdaq exchanges and currently acts as an adviser to the alliance for innovative regulation. She chairs the advisory board of the University College London's doctoral Research Program, Ecobrain. Welcome Wendy, thanks for joining us today.
Speaker 1: Thank you for having me. Real pleasure to be with you.
Speaker 2: Yeah, so I'm so so excited to get a chance to talk with you. I wondered if we could just start um at the beginning and if you would tell us a little bit about your early career and how you got started.
Speaker 1: Yeah, it's it's funny. I was thinking about that just a minute ago about I I feel like I'm on the beginning of my third career now because the first one was obviously law, which I always say I decided when I was 12 that I was going to be a lawyer because I liked watching a program called Crown Court which used to do a kind of mock trials on TV. Um I thought they earned lots of money and I liked arguing. So that sort of made seemed like a good career choice. Um and I and actually, you know, it followed through and um was a was a brilliant career. It took me into the pharmaceutical industry which I loved. Um but then while I was there, I was really uh noticing because as a lawyer, you're giving advice on on the legal position of something, which always is, you know, there's always an element of of grayness to the law, um and therefore an element of risk, which people have to make decisions about. Uh, it was interesting noticing how people made those decisions, um how they could, you know, how good and uh some people found it particularly challenging. At the same time the the company I was working for, Lily, um, was developing products for mental health, like Prozac for depression and and for schizophrenia. So also learning about the medical side of it and the neuroscience side of it to some degree of what that meant. And that led on to a conversation with my brother who was a fund manager at the time who had preman been reading sports psychology uh to try to understand, you know, decision making in in his financial world where there are enormous pressures, um when you're dealing with significant sums of money, very uncertain environment. Um so he was reading sports psychology because he really felt there was something in that uh science literature that might be able to help along with science with data and technology. And that sort of, so this is 20 plus years ago, we were having a conversation that uh, you know, going into behavioral science would be an interesting adjunct to analyzing data and with with technology. So I made that decision it took, you know, it took a few years to for it to come to fruition of going back to university to study psychology, but I left Lily saying to the board that I was sat on there as well that uh I wanted to go and improve financial decision making rather grandly. And I I think I'm still on the journey to that. But uh it's been a fascinating ride going along that route into psychology and business psychology and then into into the startup of Cybernetics. So I feel like having gone on that journey, um, sort of sort of falling into becoming a tech entrepreneur. That's the beginning of the the third career, I would say is is where I am now. So we'll see where this goes.
Speaker 2: So interesting. Okay, so you started out as a lawyer, working in the pharmaceutical industry, learned a lot about medication, learned a lot about the law, got interested in psychology, when got another degree, is that right?
Speaker 1: Yes, that's right. And a masters, yeah, in occupational organizational psychology.
Speaker 2: Wow, and then from there to a startup.
Speaker 1: Yes, which uh my brother had founded already because he really believed in that the understanding data and technology in an asset manager. Um so while I was studying my masters, um which again was really trying to think about um financial decision making. Um he'd got it going already. So that's that's the company that I joined actually as I finished, but I my masters was actually sticking heart rate variability monitors onto 30 fund managers uh and getting them to play a trading game and seeing to see if we could measure emotional responses as they made decisions. So that was the that was the very beginning of trying to take behavioral analytics into the financial world.
Speaker 2: So interesting. And so could you were you able to make any observations about their emotion using heart rate data?
Speaker 1: I mean, I still I still love the the study that we did, which, um, so we managed to to measure 10 second windows of responding, as we gave them different emotion regulation strategies, one of which was distraction, to look literally look out the window and not think about the trading position that we'd put them into. Uh they didn't know we'd put them into it, but we had, of making a loss or a profit. Or so they could choose either to distract themselves or to um reappraise their situation, which is obviously what farm managers are doing most of the time, they're reappraising the situation. And then they had to make a decision whether or not to buy, sell or hold. Um, and what we found was that they had much greater heart rate variability, which is associated with better emotional responding, when they were distracting themselves and they were also less likely to hold on to a loss when they distracted. Um, and you could measure all that within a 10 second window and see it didn't have an impact on whether they're in profit, but it changed that kind of bias towards holding onto your losses when you're um, when you're losing money, which is is well documented in the literature. Um, but what was particularly interesting about it was feeding it back, and, you know, brilliant felt, you know, this was fantastic learning to understand how you could measure emotional responding and you could, you know, really see a statistically significant difference in how they'd um how they actually then made decisions following a choice of how they they kind of tried to control the emotion in the in that in that moment. Um, and then they said to me at the end of it, so Wendy, this is, you know, this is fascinating. So what should we do about this? And and that was a real wake up call to, well, you know, of course a lot of the psychology taught world is about experimental controlled trials. It's great to be able to understand how people what people are doing and the fact is important to baseline behavior. But actually, that's the beginning of the next part of the journey is really understanding their world, the systems they use, if you're going to design something that's going to help them make a difference, and that's where really coming into the NDM world and human factors literature was that was the starting point of that journey of beginning to understand there's an awful lot more to delivering solutions that can help people in the day-to-day moment than just doing experimental controlled trials.
Speaker 2: So interesting. Yeah, and I think that insight that um that it's one set of skills or perspective to really maybe understand a phenomenon and then another set to really think about what kind of interventions would help. Those aren't always the same the same thing. That that it's a really a shift in focus.
Speaker 1: Absolutely. Yeah.
Speaker 2: So interesting. Okay, so, um, that's an amazing, uh, Master's project. Very impressive. So, so you said that's when you started reading about the NDM stuff.
Speaker 1: Yeah, it really was. Um, and I and it was alongside actually, I serendipitously met Dr. Truy Taylor, who's a great friend of mine, who is a big NDM practitioner and in the the human factors world of applying safety. In fact, she has a startup called Island B, uh where she's providing consultancy services to um improve safety in high risk organizations. And uh she her PhD was in expertise and so she's applied the NDM methods to understand, you know, what's happening in the system of the organization. And just again, it's one of the there's a lot of luck in in many successful careers. I think that uh a friend told me I should meet this friend of hers who thought she thought might be doing something similar to me. And I pinged her and 20 minutes later we were having coffee talking about, you know, what we were both trying to achieve. And uh I was saying, look, I I've read about NDM methods and qualitative research and but have never done it, you know, beyond doing a little bit within my masters. It's not my natural skill set. You've been doing this for ages, will you come along on the ride for me. And she was extraordinary to be in, so we went into a very large asset manager and and ran interviews and what you can pull out as you both will know, and anybody else in the NDM community, what you can pull out from people through um the questioning methods and capturing that information just lays out the picture for you of the world that you've got to navigate with anything that you've got to design to to embed it. It's just such a remarkable toolkit. It's amazing.
Speaker 2: Nice. So so I love how your your career sounds like it's driven by your own curiosity, but then also by by these connections you make along the way, this conversation with your brother, uh meeting up with someone doing similar research, opportunistic it sounds in some ways.
Speaker 1: Very much so. I mean and actually I mean there's a the great story with Truy who um I'd been reading Eric Hogle's book or one of his many books. I said, look, I I think he's got some of the answers to what we want to be doing here. And uh she ping me to say that there was a conference for John Wilson who is um a huge, a huge um name in obviously in in the human factors world. and that Eric was going to be there because obviously he lives in Denmark. So I thought, okay, let's go. And uh the night, I think the night of the two-day conference, the night of the first uh day, there's a big table and there was one space up near Eric at the end of the table. And Truy got 10 people I think to move down one so that she and I could sit at the end that Eric was at so that I could have a a chat with him. And uh the so there was a small conversation that night and then the next day, probably it was I think it was a half day conference and I just out the corner of my eye during the middle of one of a talk, I could see Eric leave the room. I thought I haven't had a proper chat with him. And I left it for about 30 seconds and thought, I'm going to have to go because he's he's this could be it. And I literally chased him out into the car park where he was getting into a taxi. I said, oh Eric, I really wanted to talk to you about being on our advisory board for Cybernetics. And uh he said yes, and said, here's my card, um, let's talk more. And that was the beginning of kind of getting to know Eric. So and he was amazing. We flew him over. He trained Truy and I in my kitchen on how to do the, you know, the method methodology. Just a a wonderful, you know, giant. I think you've got a symposium coming up shortly with Titans in human factors and the resilient engineering for world. Um he really is an extraordinary character, but yeah, there's I think a lot of my career has been reading about things that I think they strike me as part of the answer and everything's only part of the answer. And then going in asking people. And amazing what people will do when you go and ask.
Speaker 3: Right, and it sounds like you're touching on some skills that uh younger NDM researchers will need to develop like uh the the willingness to chase people out of rooms and and move people down at tables. Those are those are all skills that we need to get to that right place or that right person.
Speaker 2: Yeah. So tell us you mentioned Cybernetics already but uh tell us a bit more about that. So this company was eventually acquired by Nasdaq and uh, so far as I know, you're one of the few folks uh in the NDM community who's built a business uh to to that level. So tell us how you integrated behavioral science and finance and advanced analytics at that company.
Speaker 1: Yeah, that, I mean, it's it's a fascinating journey and it's a real privilege to get to get oneness as well. And it was really especially at the early days when we were first starting out of course, the thinking fast and slow was at its height having just coming out and there was a huge interest in that side of things um in financial services and there remains to be so. But very much looking at the behavioral analytics side of it and, you know, first access to data was just becoming more available along with the technology power that was capable of actually processing it. So you could get out um data in a way that, you know, wasn't really hadn't been possible at that point. So Cybernetics had developed the technology that could analyze, you know, all of the trading decisions that were happening and start to begin to build profiles of the fund managers and how they were making decisions over time to be able to feed that back as a performance technology. And behavioral science comes into that in several different areas. I suppose there's the understanding the the problem space and understanding the people and the jobs that people are doing and how they're making those decisions, so that you know what, how how to um develop the algos that are going to you're going to apply to the data. And there's also the design of the technology itself because you want to make sure that it can be used. You know, you can design technology that somebody could spend all day long playing with, but actually if they've only got 10 minutes of their day, they're never going to use it. And then you so adoptable technology is is a super important part of anything being successful and understanding when somebody can use your uh the information provided by your technology is key to success. So there's an element of designing the technology as well and the combinations of data to provide the right information at the right moment in time in a way that makes sense. But at the same time as we were developing developing the performance technology, the then head of Man Group's compliance function, Robin Gru said, if you're looking at how people are making decisions from performance perspective, I want to know, I want that kind of data from a compliance perspective because I want to be able to see when people might be doing something they shouldn't be doing because that's exactly their role. And Robin Gru is actually a real, she's, you know, very much a thought leader, visionary ahead of the curve. She was doing this at a time when the asset management industry weren't required in the same way as banks have been for many years to have technology to monitor um the activity of for managers that they all do have that obligation now, but they didn't at the time we were developing it. But her kind of philosophy was that um she didn't want she wanted to make it so clear to people that Mangroup was not a place that this kind of conduct happened. And if if you even thought about that's the way you wanted to kind of run your portfolios, don't even apply at Mangroup was her and having things in her toolkit that could support that, that's what she wanted. So that's what we then went on to do. Again, it's looking at, well, what what are the markers of particular types of market abuse like insider trading or market manipulation, and those can be encoded in rules. But then actually we also went on to develop behavioral fingerprints, the elements that might tell a compliance officer a bit more about somebody's trading as to why it might be more suspicious. So for insider trading for example, if somebody's um, you know, trades ahead of a significant price move, if a compliance officer went and said, uh, well, look, you've you seem to have traded ahead in front of a, you know, big price move where there was some sensitive information that's come out, tell me about how you've done that. The fund manager's likely to say, look, it's my job to know, you know, be ahead of the market and make money, you know, that is my job. Um, whereas if a compliance officer was able to say, look, I see that you've you've traded in that way, but when I look at what you've done, compared to how you typically trade, you've traded in a stock that you haven't got very much experience, typically you would go in in a much smaller amount than you normally than you have in this particular instance. So they would they would be able to ask more specific questions that would then lead them on to be able to say, look, tell me about your investment thesis behind this. I need to understand the rationale so we can understand how you got to that point to being able to make that really good call. And that just led to much better decision, you know, conversations between the fund managers and compliance, which is what you want to get at. You want to be able to really um support that conversation between the people who are making the decisions and the ones that are monitoring them so that the defense can be created if it's needed and and compliance are tooled up to really be able to dig in where they have to take action and it's necessary. So that was the toolkit that we developed, um that actually Nasdaq who are market leader on in the banking and and the regulatory side of things, hadn't yet developed in the asset management world. So they they bought Cybernetics to cover that side.
Speaker 3: Really interesting. So so the switch from sort of performance analytics to compliance analytics, did that happen while Cybernetics was still an independent company of Nasdaq or was that after?
Speaker 1: So we developed both, um, and the the reality is that the compliance tool took off in a much better you know, bigger way and that was driven by regulatory requirements. There was an element of compliance officers, um, so one they've they they're required to get some systematic tooling in place. Um so that helps support getting budgets for it. Um compliance officers are looking at other people's trading decisions. So there's it's not um any kind of personal challenge to them. Something that we found with analyzing fund managers is uh when you feed back to them how they're they're making decisions, um sometimes they're not so keen to hear what, you know, to see what you're revealing about them and be able to learn from that. And again, that's about being able to develop really good supportive tools. But if you've never seen your performance exposed in a way in in that kind of way and other people aren't also seeing the same kind of data, then quite often the response you get is, well, one, first of all, I think your data might be wrong, but two, I think I'm good, I'll carry on doing what I've always done and I'll wait till other people are starting to use this kind of stuff. So it was just a harder sales process. And we would have continued with that but Nasdaq's focus is very much on on the Fin crime anti-fin crime. So they they wanted to really develop the compliance side of things rather than the performance side. So that kind of has stopped as we went into Nasdaq sadly.
Speaker 3: Got it. Yeah, this there's just so many interesting questions wrapped up in here. So the the piece about the feedback, you know, we we know that expertise develops with feedback and it's a it's a requirement for expertise development but we hear about domains where it's very hard to get feedback. You know, precise sort of first order feedback of your performance. And it sounds like you had that, but finance and stock picking is is sort of one of those areas where we've traditionally believed it's hard to get feedback but it sounds like you had enough detail in the analytics that you were generating to give that uh kind of feedback. Did Do you have any thoughts about you mentioned earlier people can ignore it or or explain it away but do you have any thoughts or even anecdotes of giving that feedback and then seeing it improve performance?
Speaker 1: Um I think yeah, there were definitely people who were learning. You could and the interesting thing about it is you can see people learning over the years and evolving and that you can so if you can represent how um somebody's expertise is developing it's particularly interesting. You know, something that you see people's ability to cope with loss and can you could see the time window for how long they could hold onto something while it was losing get longer with experience because they could just ride out the feelings of discomfort um as they were going along. And being able to kind of demonstrate that, one, it's kind of it's it's good feedback to show how much somebody has come along and enable them to go back and reflect. One thing that was incredibly powerful is every time we would show somebody charts of the trading alongside the price moves and things like that. Everybody immediately leans in and starts wanting to read the story from it. I mean, as you know, people are storytellers and farm managers in particular, you know, the way they they work is they have stories of their investments in their head and they're constantly updating it. As they learn and get new information coming in, it's all being stored quite often in their heads. Um so we think there's a real opportunity actually to be able to support that kind of um you know, collection of information and progression uh via technology. It's something that lets think is going to be working on um how we can support that kind of cognitive thinking. So yeah, lots lots still to do, but uh lots lots lots of potential out there, lots of um lots of problems to solve in that field.
Speaker 3: Right, the the other interesting question I was thinking about as you were telling the story was more from a sort of an NDM business perspective. So, you know, as you said at some point the compliance piece sort of took off, but you're talking about gathering data about performance and that has different applications depending on which perspective uh you might take and then you mentioned the compliance piece required some additional research and development, but I wonder if you could walk us a bit through um, you know, that decision process of of of realizing compliance might be the better pathway in terms of of a business perspective or was it just obvious because, you know, the the financial upsides were were there for the compliance pathway.
Speaker 1: Yeah, I think it's one of those things you have in a in a startup you have to be um willing to pivot, pivot, pivot, um and go where because you're you're a small organization, you obviously can't do everything that you would like to do. And we very much wanted to start at the performance side of things, but it was clear that the drivers in the market were around the regulatory side. So there was a point at which we just thought, actually, we need to get, you know, the that that's the place to get in. It would when we thought, we thought we'd start first of all with performance because, you know, working with the decision makers themselves, they are the drivers in the organizations. It's where a lot of the funding is actually. Um, but actually the reality of all the obstacles to get to that point, um, what what made compliance a particularly good place to start. It was still always an intention to go back to performance and potentially via risk on route to it was that there's a regulatory driver in in compliance, you're getting all of the organizations data in in one go and going through the whole clean cleanup process in one go for everyone, whereas performance it was very much individualistic. Um, the farm managers themselves typically, you know, they they are masters of their own domain and could decide whether or not they wanted a particular tool or not. So you're you're doing it in dribs and drabs, whereas compliance is you get all the all the data in in one go, you clean it all up once, which is a big job. And then you can start looking at it from the different angles. So it was very much, okay, so compliance is looking at this because they have to, um they're getting great insights out and they can start feeding back some of this information to um, you know, people who are making the financial trading decisions. At the same way, risk is also a part of the firm that's trying to look at and advise the farm managers on the decisions they're making. So again, there was there was a thought that we could built develop tools for the risk function, again using the same data, different perspective. Um, and then you come back again to the performance side of it, so that the farm managers themselves would say, well, look, if everybody else is looking at this data on me, maybe I should have a look. So that was that was always the game plan. I think it's definitely still um got the potential as organizations are bringing in all of this data. It's it's just being able to kind of think, how can we look at this data around particular individuals and teams from those different angles within an organization.
Speaker 2: So I think one of the things that's extraordinary about your work is lots of people who do this kind of analytic, um, based on, you know, things you can count, don't do a very good job of then putting that in context and understanding what that really means. And so you're talking about this as if it just happened, but but that's no small thing. The people that do that kind of analytics tend to speak a different language from the people who think about behavior and it's hard to bring those together. So I just wanted to kind of reflect that I think that's really remarkable.
Speaker 1: It is very hard. There is no doubt about that. There's definitely been many times when I've just thought I we're not even on the same corner of the same page or you know, opposite corners of the same page and trying to get that that across. I mean, I think that that is one of the big biggest challenges is blending the different skill sets together to come up with a product. That that is definitely the hardest thing. But I I probably from my early training as well of having been a lawyer in house, where you have, you know, a deep expertise in certain parts of law that are relevant like regulatory law, um, but you always then have to go out to your external law firms who are experts to bring in say employment law or construction law or IT or IP law. So you know enough to be able to bring in the experts and work with them. Um, so I think that's kind of informed my approach and that's why I think I I'll go across all all of the different areas of behavioral science to try to find the answers for the particular problems and I'm I guess I'm not scared to to go and talk to technologists and data scientists working on AI and all the rest of it because I know they know something I don't and they will have part of the answer and then together we can figure out if you can get the right people in the right room, you can figure out how to to solve it and it always includes the clients, they're such a key part. We've had some amazing development clients who once they've kind of gotten over the, oh my god, you want to sit in a room with me for an hour and you're a psycho, you know, psychologist, what are you going to do to me? Once they've gotten over that and actually together you realize as you both will know, you pull out from them things that they don't even realize they know or don't realize other people don't know, and you can capture that in a way that other people can everyone can see it and you can start to dig in and analyze what are the problems or what are the multiple complexities that you're trying to design for and have to take into account now and maybe in five years time as you, you know, you kind of grow a product towards it. So that's, you know, that's both the biggest challenge of every day and um the fun part in a way because it when you get that working, it's amazing.
Speaker 3: Right.
Speaker 2: Yeah. So let's let's talk about let's think the the newest venture. Um, tell me more, you you you've used this phrase engaged intelligence. Um, tell me more about your vision for for Let's think.
Speaker 1: Yes, I mean so very early days, so uh still so well in stealth mode. Um, but so engage intelligence, this is this really kind of came from the direction of travel with technology, which has been extraordinary watching that over the last 10 years. And I say that as if nothing has happened before 10 years ago, just that's when I started noticing it. But the journey, the journey that I've been on I suppose over the last 10 years when, you know, from the beginning when Fintech became a thing even though like I say that had been around for a long time, but as a a category and, you know, these tech sectors that have suddenly become, you know, this massive thing and supported by a whole ecosystem of um accelerators and and programs to support entrepreneurs in their startups. So, so watching that kind of technological development, um there's been amazing progress. Very much the direction of travel has been on automating, automating the tasks to take away some of the, you know, the manual work from people, you know, take away the potential for the error and things like that. And it's incredible what we can now do with technology, but there's a few challenges with that. One of which is that if you're automating things, what is it you're losing in that? You know, the skills that people had although they might have been laborious and manual. Are you losing some ability of people, you know, in their their development and how they learn. One example of that I was thinking about was amazing technology now for smart contracts that does all the work and makes sure all your cross referencing are right. And having been a trainee solicitor, I had to read through contracts and check that the cross references are right and all that kind of stuff, which would take hours. And you know, I can I can see why it would be a great thing not to have to do that, but at the same time while you're doing it, you're learning what different clauses, how they interact with each other, how they relate to each other, what difference will it make if you end up in court, if you have slightly different wording interacting with something else. So there's a concern about a loss with automation and the automation bias of course, that if we're losing what you might learn from it, but also what you might notice because it's just been automated and then it it goes wrong, what you do. But also, you know, lots of these applications are being developed because they're actually very difficult to develop even simple applications. They're timely, they cost a lot of money. You have, you know, startups that are solving lots of these things in silos and then you have lots of applications which still results in the person using it having to do the integration. So there's still a certain amount of work to integrate all of these things, being laid on the person. And the other part of it is that they're not necessarily thinking so much about engaging the person and and the way that we can think. So engaged intelligence is really, you know, how can we design technology that delivers the information you need in a way that really enables us all to be feeling engaged with our brains fully functioning and fully firing, which is when we're at our most brilliant. And that, you know, for me as I was thinking about it is, you know, I love having the ideas as you're listening to people talking, you're talking with them. Truy has a phrase saying conversations are reciprocal and dynamic. So, you know, whenever you're talking to people, you're listening, you're updating your knowledge base and how you think about things and retraining the the kind of tracks in your brain as you're doing that. And but I also love doing it on my own with the tools of technology that enable me to kind of fly around the knowledge of the world and interact with that. But it would be, I'm sure that there are better ways to help me do that. So in part, it's design we what we want to do is design the technology that really works with people who engaged in that complex analysis, but also in a way that helps capture that, um so that other people can see how they've done it, especially in regulated environments where say you have people who've got to audit that, you have to create reports that might end up going through a whole system through different divisions of an organization and externally say to regulators. You how do you capture that and support that complex back and forth of cognitive work that goes on, support it, capture it, allow it to be replayed, learn from it, improve it, but and be engaged with it. That's kind of the premise that we have behind let's think.
Speaker 2: Yeah, this is this is great. I um, I like the emphasis on helping the humans be engaged, thinking of technology as a way to help humans stay engaged and think brilliantly. It's a little bit, I know so there's this term human machine teaming that's been somewhat controversial. So some folks have have felt like this is a great analog as we think about humans and automation working together and other folks have said, um maybe we're setting up unrealistic expectations. Machines can't be team members. Are we just encouraging people to um anthropomorphize and have unrealistic expectations about what technology can do for them? I wonder if you have any thoughts about that argument.
Speaker 1: I'd say, yeah, I I I think it depends on the way you approach and this is where I really think the tools from NDM as well as other areas of behavioral science, that if you start with the people, you start with understanding how people think, how they engage in their teams and their organizations, the tasks that they've got to do, the systems that they're working in. So you start with that understanding and then you look at the information that they're trying to make their decisions with and work with. And then you look at the technologies that can deliver it. So it's that kind of order. Then you can look at the, you know, what's the most appropriate technology, at well, starting with the information in the first place. Quite often the information that we have isn't the best information to make decisions on. Um, so you might be actually that part of the problem space analysis and we found this, is that actually what you need to do is develop better proxy information for whatever it is you're representing. Then you look at the technologies and quite often people start either with the data you've got and move onward instead of asking the questions of what data are you missing? Um, and or they start because they're technology, you know, fanatics and they love the technology and they want to use the technology. So they'll start there. We very much want to start with the the people and how we can really support that decision making and then and design for that purpose. Now, it's going to be impossible to say, yes, you can always nail that. But I think it is possible to do to to design in a way that really gets people engaged and I've seen it happen where they're just getting sucked in and they're doing what they want to be achieving. They're seeing the picture in front of them with the toolkit and and navigating it without thinking about the tools, thinking about the picture that they're building, which is what they want to be doing. Um and in a way that other people can see it as well and therefore join in the conversation. That, I think is possible. And if that technology could then be seen as part of your team, well, that's one way to describe it. Um, but they're never going it's not going to be a teammate in the way that a person is. I wouldn't go that far. That's where I would come on it.
Speaker 2: Yeah, those are great insights. So we've been talking a lot about some of the highlights of your career. I'm wondering if you think back over your career, what are some of the biggest obstacles you've had to overcome?
Speaker 1: I mean, I hear it a lot from people who are are working with behavioral science is is trying to explain what it is. And that challenge of, you know, when you apply it as you again will both know and anyone working in the field is it takes an awful lot of work to say to come to a conclusion that the minute you've said it, it was it's obvious. And yet it wasn't the minute before you said it. And I see that time and time again and I've experienced it and and quite often even when we've put pictures of um hierarchical task analysis in our analysis right at the beginning of the product and then we've shown the product that we've come up with and and everyone's going, God, yeah, that's brilliant. That's, you know, that's we didn't know we needed that, but that's exactly what we need. And then at the end you hear this line that comes out that says, so so where's the behavioral science? And I actually just laugh now and the people that, you know, I've I've kind of people in the team who're not behavioral scientists also now laugh because they've been on the journey and kind of going, why can't they see it? We literally showed them and told them. But often, I think what people are expecting is numbers. They're expecting behavioral analytics numbers. And just because they don't know what the methods and the processes are. And I think that's the advantage of being a product company both at Nasdaq and at Let's Think is we don't need to explain how we're going to go about this. We are going to develop and deliver products that people don't know they want but actually turn around and say, this is what we need even though we didn't know we needed it and it's worked and I can see how you've it's going to work in my organization and make it better and be engaging to use. And then they might say, how did you come to that conclusion, in which case you'll say, well, obviously it's because it's based on behavioral science methodology, but it I don't mind that being our secret source in a way if people don't get that as long as we can deliver the products that deliver that engaged intelligence. But that is the biggest challenge if you are a practitioner in the field and you want to try and get in the room with people, you're trying to get them on board to even start working with you. I think that's sometimes the biggest challenge. They love it, they think it sounds really cool, they love the stories, they just don't quite know whether they want to do it with you. But everyone who's done it with us ultimately loves going on that journey with us.
Speaker 3: Yeah, so that that very much resonates with me. Very similar experiences. This is this is not what people expect, um, but then they're thrilled with the outcomes, yeah.
Speaker 1: Yes. Exactly.
Speaker 3: Yeah, I'll I'll third that motion. Um I mean it's hard, you know, we've been at the NDM practice for for decades now and and there's only a few examples that we can point to where people were successful in producing that outcome to the point that, you know, it's it's benefit can be proven. And so what I find is that we're we're still often trying to make that case that this is the right way to do things. but I think Wendy, what you're telling us is if you can get past that piece and actually develop something and show that it works, that's going to be more rewarding and valuable in the long term than trying to convince people from the start that this is just the right way to do things.
Speaker 1: Yes. Yeah, I know, I completely agree with that.
Speaker 3: So you've you've been in uh pretty influential places and I'm kind of wondering if you have advice for folks, uh, you know, NDM researchers who want to get into the kinds of rooms that you've been into, to take on more leadership roles and contribute at a strategic level. Do you have guidance for younger folks who are or even older folks uh who who are looking to get into those places and have that kind of influence.
Speaker 1: Yeah, I mean, I I think the skill sets you have from being an NDM researcher are, you know, kind of almost perfectly placed to be in a board because it is obviously some board members are directly involved in the businesses um themselves. But you know, often when I've been on a board, it's not in that role, it's part of the governance role. In which case, you're trying to get a a picture of what's happening in the organization from the, you know, lots of information you get provided and the people that are then presenting the information that you're asking questions of and you're you're looking to get a sense of how well the organization is run, um, any areas that are potentially risky or concern, um, you know, why does it work as well as it does? And those listening and questioning skills that you develop as a researcher to look across, you know, the people that you're you're working with, set you up really well for that, to listen, to to try to, you know, the the making sense of what's happening, how well things are sacking up, what's not being said underneath what's being said, digging in the skill sets are there. So I would say feel confidence that you go into the room and you have the the tools to be able to participate and notice and observe and usually kind of distill it down into what's going on, which I think is key as a board member. So that's what I would say. And and there are plenty of organizations that are looking for uh say an NED role or something like that. So I would start putting your hand up and saying you're interested. Bring the experience you've got, often you've been working in lots of complex organizations, high risk organizations anyway from this field. You've got a huge knowledge to bring. I think having been in different industry, even if it's not you're in an industry, but taking cross industry knowledge is super helpful because you'll look at and see how somebody's tackling something. You'll say, I've seen this before and this is how it is solved elsewhere. Um, those kinds of insights are really valuable at board level as well. So that's what I would suggest.
Speaker 3: So I think that's great advice. Like have the confidence to raise your hand if this is what you really want to do. Even if it even if it's if it seems like they're just research skills, they're they're very applicable in this leadership role as well.
Speaker 1: Mhm.
Speaker 3: Nice. My next question is about kind of looking back on your career and and I'm wondering what has been the most rewarding experience as you think of all these domains and environments you've worked on?
Speaker 1: I would say, I love working in an interdisciplinary team where we have a real cohesion, completely different skill sets and yet you can take a look at the problem and it's having having the kind of faith in the whole team to say, look, I'm going to tell you everything that I'm thinking about of how where this can go and what the problems are, and trusting that people can take in that information. And I say that because quite often if you're working with developers, quite often some people say, just give them the spec at the end. Don't kind of tell them the whole story, just give them the spec what they got to build and let them get on and build it. But actually the the the experience that we had designing um investigatory tools was very much, look these people were on board as we were uncovering the information with our clients and what we were feeding back to them. And what we found, you know, the developers could start to begin to relate to the problems that the compliance officers had because it's complex analysis, they're trying to troubleshoot, they're trying to find information. In fact, it's something I think that's your one of your previous podcasters that you had on was saying right at the end how he felt that, you know, tools for cognitive support are are something that are coming. We believe it is because we're going to be bringing that with Let's think. But they they could begin to kind of see that this complex analysis, the searching for information, trying to build a picture, just the same for them as as software engineers, as they're trying to troubleshoot a bug. So they got the concept and then together, as we started to bring in more and more of the requirements, um from the actual, you know, problems and the needs and and what we felt might be good solutions, then they could take on board because they understood the problems and come up with their own suggestions for how things could be designed and built. So each time, what I loved in that team was, we'd go away and then somebody we'd come back and somebody would have just thought about it that little bit more and and delighted all of us with the next thing that they'd come up with and everybody was contributing. So it's that was just a fantastic team working together. I think you when you can bring together people like that with completely different disciplines from technology, data science, behavioral science, design, technological architecture, they're looking at the cyber security of it, and the the client compliance side of it. All of that coming together, it's amazing when it all people can all bring in their perspectives and you can build together. That's the most wonderful thing.
Speaker 2: Yeah, so, so the the the name that was escaping me that was John Ospa.
Speaker 3: Ah, yes.
Speaker 2: Who who started out as a software developer and got interested in resilience and and NDM sorts of topics. Um but the other thing you're making me think of is um Emily Roth, who is one of the giants in our field. I mean probably 20 years ago I remember talking to her and she was relating how powerful it was to have software developers come along on some of the data collection.
Speaker 1: Yeah.
Speaker 2: So they really understand the work context and hear the kinds of questions you're asking and and begin to um just be able to have that context as they're developing the tools.
Speaker 1: Yes. Absolutely.
Speaker 3: Yeah. That's a great insight and um it doesn't happen very often.
Speaker 1: Yes.
Speaker 3: Yes.
Speaker 1: It's a hard thing to do as well. Yeah.
Speaker 3: Right, right. So let me ask a different kind of question. Um as you think back over um the years and and as your career has shifted, what changes in society or technology or those sorts of things have had the biggest impact on your perspective? If you think back to you as a young lawyer to um you now, what are some of the biggest changes that have really changed the way you think about things?
Speaker 1: I think the most amount of change seems to have happened in the last 10 years. And I think it's always actually happening over time, isn't it? But it feels like it's sped up that um technologically the explosion so so what's extraordinary is I look back 10 years ago to the companies that we were out on the startup circuit with that are now listing and you know, big companies and so there's there's now a whole ecosystem of tech startups that are all have been on that journey. They're thinking about how to achieve integration because they're all accepting that you know that that change from big software companies where the goal was to own everything, be the only um the visual, what's the word? I can't think. so you know that that your screens get your space on your screen, your real real estate essentially, your visual real estate and try to be everything has now kind of going actually, no, we can we can just develop apps and they can be integrated into Google or any kind of, we can all be interoperable. So there's there's this enormous ecosystem now alongside the legacy and there's an enormous amount of legacy and that's one of the most important things to recognize as well is if you're going to try and to work at, you know, at scale and impact, you know, and we want to be working with big organizations across the globe like the banking industry and what have you. You have to accept that they've got legacy that's incredibly difficult to change. Therefore you need to design in a way that can complement it and will allow slow change over time if they're ever going to change. So that's really important. And I think but that's really helpful as you think to design a fresh that you can you have an ecosystem of technology companies who've actually been around for 10 years and know how the system works and are really supportive of each other. Because like I say, they are tackling different parts of the problem. There's a one called um Niya one who developed a tech sand pit that can enable you to test new applications with large clients that, you know, don't want to bring you into their organization and run any kind of risks. they have synthetic data that allows you to test it out with clients on it. They can be part of the UAT system too again test it as you're starting to onboard it. So they're solving part of the kind of testing and onboarding problems that startups quite often have with new technologies. And and organizations like that that know they're part of the system of bringing new technology in, are really collaborative and supportive. So that I think that gives us all a huge advantage going forward. But I think also the way organizations have work. I mean, clearly the pandemic has massively changed how people work. But again, that ecosystem of startups where people just work differently, you know, it's not uh go to the office, sit down, work 9 to 5 and it's very structured and rigid. Really seems to have changed over the course of the years, even without the pandemic having seen people wanting to work in that way, which has just changed the whole dynamic of how we work anyway. So those two things combined, I think are supportive of creativity, agility, adaptability, which if you want to innovate and and change the world, really, really great, you know, way for the world to be working right now to support that.
Speaker 3: Nice. So we are um, we are running out of time, but I wanted to ask one at least one fun question here at the end. So I wonder, will you tell us one thing about yourself that the audience probably doesn't know?
Speaker 1: Okay. I think, so, I like to tell the story that when I was 12, I had tea with the Queen mother, so the mother of the our current Queen. And I say I was taught to courtesy and she was very pleased I could make it, is what she said to me. And then, then I usually tell people that she probably said that to the other 200 people who were also there. And it was one of these weird things that at school, I would, you know, one of these after school hobbies, there was a crochet club that somehow I ended up in. And uh it was sponsored by the Queen Mary Guild and two people got picked out of a hat every year to go and and have tea with the Queen mother and she gave her talk about the Queen Mary Guild and then tea at Clarence Palace, I think it was afterwards with um, and the corkies were there. And I think I was too scared to eat anything, but it was amazing. She was very pleased I could make it. That's all I can say.
Speaker 3: Wow. That is an amazing experience. And it helps us to understand why you're not afraid to chase people out of the room because you've already been in the room with royalty.
Speaker 1: Right. Maybe that's where it comes from. I had I've never thought of that.
Speaker 2: Well, thank you Wendy for speaking with us today. This has really been a pleasure.
Speaker 1: Oh, it's always always a pleasure to speak with you both. You're both amazing.
Speaker 2: Thanks. So, and on that note, thank you all for joining us for the NDM podcast. I'm Laura Mittello.
Speaker 3: And I'm Brian Moon. Learn more about Naturalistic Decision Making and join the NDM Association at Naturalisticdecisionmaking.org.
(Music)