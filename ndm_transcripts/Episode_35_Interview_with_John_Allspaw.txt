**Brian Moon:** The Naturalistic Decision Making podcast with Brian Moon and Laura Milatello. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress.

**Laura Milatello:** Welcome to the Naturalistic Decision Making podcast. This is Laura Milatello from Applied Decision Science.

**Brian Moon:** And I'm Brian Moon from Paradigine Technologies.

**Laura Milatello:** Today we welcome John Allspaw. John is an engineering leader and researcher with over 20 years of experience in building and leading teams engaged in software and systems engineering. He is co-founder of Adaptive Capacity Labs. Previously, he was chief technology officer at Etsy. He has also worked at Flicker, Friendstar, InfoWorld, Salon, Genentech, Volpe National Transportation Center and a bunch of other places as a consultant from time to time. John has spent the last decade bridging insights from human factors, cognitive engineering, and resilience engineering to the domain of software engineering and operations. His publications include the books The Art of Capacity Planning and Web Operations, as well as the forward to The DevOps Handbook. His 2009 velocity talk with Paul Hammond titled 10 Plus Deploys per Day, DevOps and Corporation, helped start the DevOps movement. He holds a Master's degree in Human Factors and System Safety from Lund University. Welcome, John. Thank you for joining us today.

**John Allspaw:** Thank you for having me. I'm really excited to talk with you guys.

**Laura Milatello:** Great. We are looking forward to it too. So, you know, I always like to hear about how people got started. I wondered if you would tell us a little bit about your early career? Did you start out in the software world?

**John Allspaw:** I didn't. So my undergraduate degree was in mechanical engineering, actually. And after I graduated, I took a job for the Volpe National Transportation Systems Center, which is the USDOT where we did vehicle crash worthiness simulations, you know, dummies and airbags and seat belts and all that sort of thing. And it was super fun and that's where I, just as a necessity, I learned Unix, and other sort of complicated computer stuff. And then this thing called the internet started and I thought, hey, maybe I could, you know, sort of flip my career or because I like these computers, and, uh, and that's what I did. And so I picked up, I left the Boston area and moved to San Francisco where I stayed for oh, a little over a decade and worked at a bunch of, a bunch of places that were all online services. You know, so I didn't really start in in software. I sort of that's where I landed.

**Laura Milatello:** So your time in San Francisco was that during the dotcom boom in the 90s there?

**John Allspaw:** Yeah, like, you know, I got there in the very end of the 90s and stayed, stayed there till about 2010. Uh, still in the same industry but moved to Brooklyn where I live here uh to take the job at at Etsy, which is an e-commerce site here. But, uh, yeah, it was it was it was a really wild time in San Francisco at the, you know, when I was there.

**Laura Milatello:** Yeah, yeah. So you went from kind of crash test dummies to, um, tech industry that was just like, um, I I I happened to be living in the San Francisco Bay area at that time also, and it was an exciting time. Um,

**John Allspaw:** Yeah.

**Laura Milatello:** So many new, new things coming out and going up and ideas everywhere. So then how did you find your way to cognitive engineering and resilience engineering and and those kinds of things?

**John Allspaw:** Yeah, yeah. So, you know, I was left, I, so I found myself, oh, let's see, 2006 or so, 2005. I was working for a company called Flicker. Uh started uh, is a photo sharing website. And we were, we were acquired by Yahoo, which was a big deal at the time. And um, and we just had to, you know, we went from, you know, well, it was reasonably big, um, Flicker, that is to say, the number of people using it and the number of photos and and and all of that sort of thing. But then after we were acquired, it just sort of exploded as far as the, you know, usage and we had to, you know, figure out how to scale all these technical things and I was managing a small group of, uh, oh, six or seven engineers. And, um, and like something like the first 18 months or so, we went from, you know, Yahoo has all these properties, like Yahoo Sports and Yahoo News and Yahoo Astrology and all that. And so Flicker was one of those properties. We went from being like the 25th most trafficked Yahoo property to like the fourth within a very short period of time. And I, as an engineer, also as I guess maybe as a manager, I couldn't understand, I kept sort of wondering like, how are we doing this? This is on paper, this should not work nearly as well as it as it should, right? And I thought, well, and I didn't have good explanations. I you know, we had outages and lots of problems to solve, but we managed to handle them and I just couldn't understand. So I got trying to understand how how do software engineers make sense of things? You in software, you can't really you can't really see anything, right? It's not like, uh, you know, in in the in the physical world, you know, you can see things, you know, moving very fast. You have some, you know, perception of like risk and that sort of thing. But in software, it's like entirely, you know, up in your noodle and how do, uh, how do people make decisions and all that sort of thing. So I went reading and somewhere around that time, I in in the in the small circles that I ran, uh in the in the industry, uh a friend shared this this paper, this article, called how complex systems fail. And, uh, and I looked at it and I I read through it's a couple pages and and I saw the the author's Dr. Richard Cook. And I thought, initially I thought, oh, this must be some sort of PhD from Google or something like that. Because clearly, clearly he's he's he's writing about software as far as I could tell. This is it's spot on. It gave me, uh, lots of vocabulary and descriptions. I'm like, yes, yes, I kept reading. I'd come upon another paragraph and I'd be like, yes, he gets it. This is exactly what's going on. And and then I looked up and wait a minute, he's a medical doctor. And, uh, and, you know, that was, you know, that story I just told by the way is, you know, for those folks in the software world, you know, how complex systems fail tends to be, more often than not, seemed as a, seen as like a a gateway paper. And, um, and, you know, if you read read Richard Cook's works, you're not too far from a whole bunch of other names, David Woods, and Emily Roth, and Emily Patterson, and Sydney Decker, and so on and so on and so on. I kept pulling on those threads and, you know, uh, that's that's the short story. Um, uh, I a little bit later, uh, after reading how how complex systems fail, I was writing this book. I was sort of editing a sort of anthology of articles for a book called Web Operations. And I emailed Richard and said, you know, you don't know me, I'm just a guy from software, but is this this paper is absolutely astonishing and can we, you know, I want to know if we could include it in the book? And I it was like 15 minutes after I sent the the email to him and I got this a very long and thoughtful response. And, uh, you know, I as the years went on, I they included it in the book and I got to know Richard and uh convinced him to speak at a at some conferences that I was chairing in in technology and the sort of software operations and and so on and so on and so on. And next thing you know, I'm in a master's program in Sweden.

**Laura Milatello:** Wow, that is a great story.

**John Allspaw:** Yeah, I I have to say that I'm I am, I feel absolutely grateful because I, you know, I I saw these connections, I didn't have vocabulary, still working on vocabulary on how to connect, you know, what, what a lot of research and a lot of science had had worked out in these other what we would call maybe traditional safety critical domains, you know, aviation and medicine and power generation and transportation, all all all of the, you know, usual suspect domains. And, um, I was feeling pretty confident and then over time, I got to meet, um, uh, a lot of folks that were as, you know, my heroes, really. Um, and, you know, I said, is this, are these connections real? I think they're real. And David Woods said to me, I managed to convince him to to come speak at this at this conference, the velocity conference. And he said, yeah, I get it. Yeah, this is this is these connections are real. And so that was you know, it was encouraging. So, and I'm still trying to do that.

**Laura Milatello:** Very cool. It's I I'm as you're talking, I'm I'm remembering the first time I heard Richard Cook speak, I hadn't read his stuff first, but I it was an early NDM meeting, um, back in the 90s. And, uh, he is kind of amazing at taking these experiences in his world as a physician and presenting them in a way that they are are relevant to all kinds of things.

**John Allspaw:** Yeah, yeah, absolutely. If if I can be as uh as eloquent and, you know, effective with language as Richard, uh, then I I I couldn't ask for anything better.

**Laura Milatello:** Yeah.

**Brian Moon:** So John, tell us about Adaptive Capacity Labs, uh, which you co-founded a few years ago. Um, I see you talking a lot about organizations learning from incidents. So what what kind of incidents do you all deal with?

**John Allspaw:** Yeah, so for the most part, we work with organizations, our our our clients all have one thing in common, and that is that they're online services, right? Um, and when I say incidents, I mean things like outages. Outages of all sorts of shapes and sizes. And it sort of runs the gamut, uh, from music streaming, online medical health records, financial trading systems, social media, e-commerce, and that sort of thing. So when we say incidents, um, and in particular, what effective learning from incidents looks like, um, or productive ways on on improving that, and demonstrating what effective analysis, um, that might lead into effective learning is that's primarily where our focus is.

**Brian Moon:** So can you give us a concrete example, um, maybe a recent one where you've helped an organization learn from their incidents?

**John Allspaw:** Yeah, well, interestingly enough, I because we signed NDAs, I I'd love to be able to tell you the name of the company, but uh suffice to say, pretty well known, in the hundreds of thousands of of people, I mean, staff wise, right, company population wise. Um, and uh, the case that we were helping them with, uh this was what we call an aftermath project. And so it's usually when a company has like some really visible outage, you know, stuff you you'd read in the news and they asked us to come and and and do an analysis of the case. And while it did get press, the the crux of the incident was really something that was an internal, like internal tool, internal like uh system that everybody in the company uses and it was a, you know, it was weeks, uh, many weeks long, almost month long outage and it was a sort of really like a whole suite of things that includes all of the stuff that that people use to communicate inside and outside the company. So in that way, it's a little bit different than, you know, customers can't watch uh a movie or the audience or so to speak, were the people inside the company, but the fact that the company is so huge, I mean, multiple continents, uh, um, was was what made it significant and uh, and yeah, and, you know, we we we we we tried our best to keep it contained in time, uh, because, you know, one of the things that happens in software is, uh, the analysis to try to have it contained in time because incidents happen so frequently, even pretty large ones that they come and go and sometimes people forget, uh, that they, you know, it's a little bit like a, uh, you know, like a news cycle, really. Uh, they come and go and, um, it never comes up until the next time an incident that kind of looks like it happens again and they say, oh, darn it, we didn't really understand that last one. So, no wonder it's sort of repeating. So, yeah, we we work with all kinds of organizations, but, you know, sometimes we're really surprised. Some of the household name, well, well known organizations, you really never know until you get inside and look at the real messy details, sometimes they're way more effective at learning from incidents than they think they are. And sometimes it's the opposite.

**Brian Moon:** So in this kind of aftermath situation, so you're you're trying to understand what all went into the lead up to this incident. Once you understand those pieces, how does that then transfer to learning and and opportunities for the organization to learn?

**John Allspaw:** Right. I mean, the most straightforward way that these things usually go and did in this case is that we're doing uh, uh, a certainly, we're being opportunistic. We're not being as uh, say structured, I was going to say rigorous, but that's not really the word I'm looking for, maybe structured, not like, um, something you would do for a a thesis or a dissertation, but little bit of approaches for from cognitive work analysis, uh, uh, you know, uh, critical incident, uh analysis and we will borrow and steal from stuff that that that you and Laura have written quite a bit. And sort of synthesize, uh, ends up being really a thematic analysis and we present those sort of results. We don't usually put I guess recommendations per se. We would sort of outline what we call areas of opportunity where, you know, what they what the organization want to do with those is, you know, sort of up to them. It ends up in being in a report where we do, where we also do like a highlight reel presentation. In the case of aftermath, um, the audience is largely leadership in the organization because those are usually the folks that that reach out to us. In other projects where we are doing coaching and training for incident analysis skills, we're usually much closer to sort of hands on practitioners, boots on the ground, uh, folks.

**Laura Milatello:** So John, before I met you, it had never occurred to me that these online providers whose tools I use all the time have these like time pressured critical incidents where they need to very quickly figure out what's going on and react.

**John Allspaw:** Mhm.

**Laura Milatello:** So I this is is fascinating to me. I've been using these tools for years and I just had never thought about what's going on in the background there.

**John Allspaw:** Yeah, you know, it's that's that's that continues to be uh, what gets me out of bed, which is that, you know, the the issue with technology especially, think about how effective it's been during the pandemic for for society to sort of adjust and adapt, especially with, you know, online services and, you know, video conferencing and other sorts of chat and collaboration, all sorts of, um, you know, food delivery and news and all that sort of stuff. The thing is is it works so well almost all of the time that it doesn't really tend to get a lot of attention until it doesn't.

**Laura Milatello:** Mhm.

**John Allspaw:** In which case it gets a lot of attention. And so I I I very much, you know, whenever I I do have a chance to talk with folks from human factors, uh NDM, uh and you know, people who's, you know, whose books I own and whose articles I've read over and over, you know, you know, I'll point out to them, all right, we're on Zoom. Imagine if this went down. What do you think would happen? There the they're there's certainly differences, but they're the differences and similarities aren't really intuitive and obvious. And so that's what's really kind of exciting.

**Laura Milatello:** Yeah, and and this community's even adapted this uh incident command metaphor from firefighting and um crisis management.

**John Allspaw:** Yeah, yeah. I would have to say this is going to sound a little bit, uh, a little bit snarky, but the tech industry, it's quite insular. And so examples like that where organizations have genuinely tried or there's there's there's real traction happening where they see something happening in another industry and want to bridge translate it into the world of, you know, software like incident command, it it's it's pretty rare and to be blunt, it's understandable that it's rare because people in software, I say this because it is my industry, we're pretty full of ourselves. And we're pretty sure that if something is good is in the world, it's probably because of us. And, you know, we're we're happy to reinvent the wheel and convince ourselves that, um, that what we're doing is original, when the fact of the matter is, it's, it's not at all. Um, but yeah, the more that that can happen, the better really.

**Laura Milatello:** So among the many things that you are known for, DevOps came up quite a bit when I googled your name. And so this idea of focusing on making development and operations work better together in organizations has become a really important movement in tech companies. Um, and you were kind of one of the people that helped with this mindset shift. And I wondered if you could tell us just a little bit about how you came to this insight.

**John Allspaw:** Yeah, so the way I like to think about it is, there was a world when mainstream, when I say mainstream use of software, right? You you would, you know, you'd wake up one day and there'll be a, you know, a CD on your front doorstep from AOL, right?

**Laura Milatello:** Right, yeah.

**John Allspaw:** And and you literally, people literally, not figuratively, uh companies literally would ship you software, right? So in that sense, they'd have some release with new features and bug fixes and that sort of thing, it would be a new version, they'd send it to you, and then you'd run it on your computer. The difference between that, it sounds pretty obvious now, but that and the growth of the growth of the web, you know, if you go to Etsy or or we're recording this in on a recording application that runs in my, you know, the Chrome browser here. In that way, the software is running, certainly running on our computers right now, but it's also running on the the the people that make this tool's computers, right? So when you have access to all the computers, or at least uh a good portion of the functionality running on the computers you have access to, then there's a whole bunch of things that you could do that you wouldn't be able to do if you were shipping CDs around. And so, you know, the idea that operating software is different than developing the software with different concerns, you could, it's not hard to imagine from there that, oh, you could, you could develop software in a way that makes it easier to or harder to operate once it's running. And that's like the the sort of the fundamental idea. And and when DevOps became a thing was really just a reflection by myself, my my colleague Paul Hammond at when we worked at Flicker together, and a couple of other people was, you know, hey, there's this seems like a pretty manufactured artificial distinction, you know, you've got developers who write application code and then they would say, okay, I'm all done, here you go and they'd give it to, you know, systems people or ops people or operations engineers. Now, you go ahead and deploy it and if it breaks, good luck. Uh, wake up in the middle of the night and tell me what happened the next day, you know? And so this sort of what what we used to call it sort of a throw it over the wall sort of thing. DevOps was about, hey, I think this is doesn't have to be like this, and in fact, it would probably be better if we under, you know, ops people and and developer folks understood each other's goals and what they're work, what they're worried about, the things they look out for. If you get an understanding about how they do their work in both directions, then I think we'd be better off. I have to admit though, that this idea wasn't, you know, it wasn't a strategic like we didn't come up with, oh, hey, this was you we weren't explicit, Paul Hammond and I about this is a brand new thing and, you know, engaged in like sloganeering or anything like that. It was just, hey, I think stuff that we do here at Flicker seems like it's a little different. And we just did it because we thought it was it could work. It was the best way we came up with. We didn't really put much strategic thinking into it. What I now know is there's we just developed a collection of practices that because nobody else was, nobody was telling us that we were doing it wrong, or different, and we just, all right, well, then we gave this talk at a conference, said, hey, here are these things that maybe are different than how you go about your work. And it it it it, you know, kind of somewhat took hold from there. So, yeah, I don't I'm not entirely sure, uh, you know, some 10 plus years on that it's, uh, permeated in a real concrete way throughout the industry. I'd say that if you believed how often DevOps is mentioned on web pages, it probably paints a more optimistic picture than what's actually happening.

**Laura Milatello:** So, so this is interesting to me. It it so it sounds like kind of the world was changing. So so so organizations had this kind of natural break between development and ops because operations you had to ship something, you didn't have much control once you sent it out. And so but then the world was changing and and these things were starting to merge and you and your colleague saw this kind of opportunity.

**John Allspaw:** Right. Yeah, well, we just said, well, look, you know, we, we were making changes. And like I said, you know, like I said earlier, like Flicker had to we had to make change quite a bit because, you know, we, you know, originally built Flicker to sort of accommodate this number of users for with this number of features and like when all of that grew, we're like, uh, we're out growing this part of the architecture, this application needs to be rewritten and that sort of thing. We just said, all right, look, uh, given the choice between spending a lot of time up front, writing a lot of code, and then arbitrarily saying, okay, this is a release and we're going to a new version and we're going to just deploy that all at once, this big, you know, sort of big bang version change. like, we have control over all of the computers. Why don't we just make smaller changes more frequently and just change the stuff, you know, and and if you're nervous about it not working, um, which all software engineers are, regardless of how much testing you put into it, right? Bug-free code is it's a impossibility. It's a, it's a fallacy that it's even possible. And so, well, I'm a bit nervous about this change and I've tested it a bunch, but, you know, what, I'm just going to just make this small change in this direction, put it out there and maybe only have people who work here use that feature. Okay, oh, that looks good. Okay. All right, well, now let's have it so that only people from the US who come to Flicker use it. Okay, that looks good. Oh, wait, there's this weird edge case. All right, let's just flip, you know, undo that, which is easy now because it's only a small little bit. And so, um, we just did it out of, like I said, we just did it out of necessity and we just kind of described the rationale behind it. But you know, there's there's there's a big part of describing this. It's it's in the that category of you just describe it in a way that sounds obvious, but it it's not always obvious, especially for folks outside of technology.

**Laura Milatello:** I yeah, I think that is the nature of much of, um, human factors and, you know, uh, situations where you're trying to really support human performance, after you've done it, it's so obvious.

**John Allspaw:** Right.

**Laura Milatello:** So, so John, you're talking about working with large organizations and also talking about sort of early days in what at the time were smaller organizations. I wonder if you can give us any insights into some differences between those small teams, uh, who are working both sides of the coin, right? They're doing the development, they're running the operations, and then these large organizations which have, you know, siloed those sorts of functions. Is there any any lessons there to be learned?

**John Allspaw:** Yeah, a couple of things. I mean, the first is that so from a science perspective, you know, I I would I would just say that we've seen situations where small, so small companies in the world of online software tend to be startups. And, uh, startups are primarily looking to demonstrate that whatever they're building is worth something. And so they tend to go with the simplest thing that could possibly work. And, uh, you know, you're not really, you know, it's not like you're protecting some sort of revenue stream because you don't even have any revenue. And so they're much more willing to be fast and loose and, uh, take a lot more or let's say, uh, bigger risks or, um, speculate a lot more on on the technology choices, all that sort of thing. Uh, once you get to be a bigger organization, then, um, then yeah, like there's you you've you've got something valuable that you kind of don't want to screw up. And so it's a different set of, you know, focus areas. The really, really large organizations almost certainly hit exactly what how you describe, which is, you know what, group A of a couple of thousand people, you do this, and group B, a couple of thousand people, you do this other thing and, you know what, we'll we'll talk to each other in very narrow ways, uh, you know, on a quarter basis or, you know, in in in really formal ways and that sort of thing. And to some extent, it's the thing that we see is really about the ability for smaller organizations because you're all talking to each other, uh, on a on a daily basis. You're sharing stories about what's what's going on. And, um, it's much more likely for for people to be more verbose about, huh, that's interesting. Did you know that application A does X and Y, uh, but only at the end of the month or, you know, real really strange things come up in conversation a lot more organically, whereas in those more siloed organizations, in some cases they don't have much, let's just call it water cooler opportunities where eating lunch together, virtually or non-virtually, where, hey, here's an interesting story for you. So the the thing that that struck us is, well, when incidents happen, that's that tends to be a a situation where giving time and attention to understanding the incident is, it's, it's not really, people don't think that that's weird. Like, oh, of course, we'll try to understand what what happened here. And so absent an incident, those opportunities don't really arise. And so that's, that's why, uh, no matter what the size of the organization is, we sort of hide, well, Dave Woods doesn't like us, doesn't like me to use the word hijack, but we're piggybacking. Piggybacking the attention and the, uh, and energy surrounding an incident, kind of Trojan horse, right? Because what we end up doing is, regardless of the size of the organization or whatever they do, is get in to answer as much of the question, how did this not go nearly as bad as it could have, as much as what went wrong. It's, it's amazing, it blows people's minds. It's such a perspective shift that's, um, it's, it's going to be a little while before I think it's sort of mainstream, obvious in hindsight.

**Laura Milatello:** Sure. But it sounds like at least in your experience, sometimes with a smaller company, the kinds of communications that really promote these kinds of insights and lessons learned happen organically and with a larger organization, you have to create a space for those kind of information sharing to happen.

**John Allspaw:** Exactly, and that's exactly it.

**Laura Milatello:** So John, you have worked on so many things and in so many contexts over your career, I was wondering what what work has been most rewarding for you?

**John Allspaw:** Oh, boy. I feel just so incredibly blessed. Um, I I don't know, it's it's very hard to answer that question. Um, it's uh, there are definitely things that come to mind that I'm the opposite comes to mind much easier. You know, any opportunity that I have to talk with folks from the NDM community, like yourselves, and find those bridging conceptual, sometimes academic, if I'm at uh, if I'm at a a conference, more or less academic conference, anytime that new things, new connections from one domain to another, no matter who I talk to, is just so just bananas rewarding. I spent some some time recently talking with Emily Roth at the HFES conference. And I hadn't really talked with Emily before before that, uh, conference panel that that we were on together, but just hearing when you talk with somebody who has such a, an impact on a field of research, uh a field of practice, you can't not or at least I can't prevent myself from seeing connections in what they're saying to the local domain. And every time, every conversation we had over over a couple of days, just new bells started ringing and I, uh, many times just was so disappointed that I didn't have my notebook with me at the time. It sounds like a not great answer. I I I can't point to a this bit right here was super rewarding. It's, it's more like a a whole category and it's usually this, again, this bridging translation, uh from one domain or uh to another.

**Laura Milatello:** Yeah, I mean, I think that's a great answer. This the act of of kind of, um, recognizing ideas and adapting them and and seeing the relevance and and bringing them to different communities, um, that in itself is is rewarding. That that's a cool part of your work.

**John Allspaw:** Yeah.

**Laura Milatello:** Yeah. Okay, so just going to switch things up a little bit. Tell us one thing about you the audience probably doesn't know.

**John Allspaw:** Well, that's a tough one.

**Brian Moon:** Um, you're very active on Twitter, John. Maybe maybe that's the reason this is so tough.

**John Allspaw:** Yeah, for well, for the better of the worst. Um, I would say, uh, outside of a a really garden variety answer, which is I'm a guitarist and I like playing guitar. I would say that, um, well, something that that that might be of interest is that when I did my my thesis, my master's thesis in Lund, it was on how engineers work their way through incidents. And I have to say, the literature review for that, I'm pretty sure, uh, the literature review that I put together for my thesis is honestly probably a a who's who. I I probably feel prouder than, uh, than the rest of my thesis. And I am as proud of the literature review. There wasn't one stone unturned. And so my guess is that there's a good chance that some of your listeners, I cited their work. Um, that's probably a bit of an a nerdy answer.

**Laura Milatello:** That's that's a great answer.

**Brian Moon:** That works.

**Brian Moon:** So John, you've been uh pretty involved, I believe in the resilience engineering, uh, movement and activities. So I want to talk for a minute about resilience engineering, but but go at it from this direction. So, let's say you meet a complete stranger who claims to practice resilience engineering and on the pain of death, you're given one question to determine if they do indeed practice resilience engineering. What would you ask?

**John Allspaw:** I would ask them, how easy would it be to have some significant, say, uh, 50% of the company that they work at, stop what they are doing at a moment's notice and completely shift to working on something else? And the reason why I ask that question is, you know, not it's I'm not not asking if it's possible, I'm asking how easy it would be, how straightforward it would be, would give me some idea about how people in the organization, how much flexibility people in the organization have to adapt to things that aren't foreseen, which I think is a a key distinction that a lot of folks struggle with when it comes to resilience engineering. It's not about the adaptation, it's about setting up a situation where adaptation can be effective without a significant amount of drag. As as, uh, as Dave Wood would say, you know, how much capacity for maneuver do they have set and thought about ahead of time for scenarios that they can't predict or anticipate. Does that make sense?

**Brian Moon:** Yeah, so if I if I combine that answer with your earlier comment about sort of shifting the perspective to, um, why wasn't this incident worse? Uh does is that one of the gauges you might use to to think about adaptive capacity?

**John Allspaw:** Yeah. Yeah, absolutely. I think that's uh yeah, right along the same pages. You know, one of the paradoxes in resilience engineering is that it flips the traditional idea of safety upside down. It's was has been said uh that Murphy's law is wrong. Um, what could go wrong almost never does. We just never really pay attention to it because nothing went wrong. And so if you can get good answers, if you can, if you can get people to be curious about what actually goes into preventing incidents from happening, which by the way, is happening all of the time. People just don't see that as being notable. It's, yeah, it's along the same, along the same lines that things could go could go wrong, but they but they don't. And there's no reason, there's nothing that prevents you from bringing your attention to, all right, how did this not go uh nearly as bad as it could have? Well, because you can explore the the, you know, some of the salient rationale for that. And in the end, especially when it comes to softwares, you know, something that I think both of you are quite aware of is that people don't know when when they have expertise, it can be difficult for people to describe how they have that expertise or even what that is. So yeah, that's that's uh, I think you're you're spot on that these are those two comments are basically the same. You're right.

**Laura Milatello:** Interesting. So, you've talked about being a connector, you've talked about, um, this literature review you did. Um, so I'm going to ask you a really hard question. If you had to name three people who have been really influential in your perspective, and you could only pick three, who would they be?

**John Allspaw:** The first two I think are are pretty easy. It's the third one I'm going to struggle with. It would be weird if I didn't say Richard Cook in on multiple, multiple fronts, for multiple work that he's done and multiple things he's written. The second is Lisanne Bainbridge because the Ironies of Automation is possibly the most powerful single article with the with the the longest legs over over such a long time period and it continues to blow minds. It continues to blow my mind. And so I would have to say Lisanne Bainbridge. The third, I'm going to say Yowon Bergstrom. Yowon Bergstrom was my professor in Lund and I would say that the perspective he gave me or that is to say, the scenarios in which I was able to develop the perspectives that I have, entirely influenced by Yowon Bergstrom. If I didn't do the Lund program, I'd be still interested and and and and picking apart uh papers and all that sort of thing. I wouldn't be the critical thinker I am today without Yowon Bergstrom. But top three, that is a really, yeah, you're right, that is a hard question.

**Laura Milatello:** That's kind of mean to make people limit it to three.

**John Allspaw:** Makes for a good podcast though.

**Laura Milatello:** Right, yeah. So, what what's next for you? Where where are you planning to go next?

**John Allspaw:** So, I'll I I'm going to do something here that I that I don't always do and I'd uh and sort of take a a a more speculative visionary uh direction for my answer. I'm going to continue doing what I have been doing. We'll be coming up on almost four years for Adaptive Capacity Labs the end of this month. And that is working with Richard, working with Dave Woods, to keep bridging, keep translating, in some ways, only half joking, keep re-explaining stuff that Dave wrote about 20 years ago, sorry, 30 years ago, to people in software. I'm going to go out on a limb and say the point in time in the tech industry that we're in right now, very much reminds me of those early days of DevOps. Uh, I could be wrong, but I think if we're successful, and I say that we much more much broader than just Adaptive Capacity Labs. If we're successful, then we'll look back at this time, recognizing it as a as a perspective shifting time, much like that those early days of DevOps. I think that in the next couple of years, as organizations, uh software-centered organizations start to understand, how does decision making work? What is expertise? Where does that come from? How is it different than experience? How do we solve problems? What is cognitive work? You know, getting uh a bit more uh clear on answers to those questions, what's going to immediately follow up because engineers got to engineer is going to be a clamoring, a desire for more effective tooling to support cognitive work. We're we're not there yet. You can't really convince somebody they need a tool to solve a problem that they're not aware of yet. Um, so it's going to take some time, but I think that, I'll say 2023, I I I would suspect that we'll start seeing more productive conversations in a in a like in a mainstream way because the the the state of tools that engineers, software engineers use in doing their work, let's just say, I believe that the bar is very low and it's amazing what can be done when you start with a bar that's really low.

**Laura Milatello:** Well, that's exciting. I think that's an exciting space you're in and happy to hear you you're continuing to feel very motivated there.

**John Allspaw:** Yeah.

**Laura Milatello:** Um, so I have one last question before we wrap up, kind of a fun question. Um, if you could instantly become expert in anything at all, what would you choose?

**John Allspaw:** Oh, I would be an expert cocktail maker.

**Laura Milatello:** Ah.

**John Allspaw:** It's a hobby that I have picked up after I left Etsy, my reward for myself for being a CTO of a publicly traded company, which sounds really fancy, but, that was a lot of work. Um, uh, was to learn how to make cocktails and at the rate I'm going, it'll be another 20 years before I feel confident that I could pull off the the really complicated ones. So, that's what I got. Certainly, it's a it is a uh it's a it's a less expensive hobby than a lot of others. So, that's uh that's that's what I'd like to be if I could snap my fingers.

**Laura Milatello:** So I don't know if you've had a chance to listen to our podcast with Penny Sanderson, but she also has an interesting cocktail making.

**John Allspaw:** Oh, I have to open the tab because I'm halfway through the interview with with Penny. Uh so I will I will I'm looking forward to that. Maybe we could join up and and create a an original cocktail.

**Laura Milatello:** Yeah.

**John Allspaw:** Very cool.

**Laura Milatello:** Very cool.

**John Allspaw:** Well, I want to thank you John for speaking with us today. This has really been a pleasure.

**Laura Milatello:** Thanks.

**John Allspaw:** Thank you. I'm I'm absolutely honored. This is uh a huge bucket list for me to to uh to talk with you on this podcast.

**Laura Milatello:** Wow, that's so nice of you to say. So, on that note, thank you for joining us for the NDM podcast. I'm Laura Milatello.

**Brian Moon:** And I'm Brian Moon. Learn more about naturalistic decision making and where to follow us by visiting naturalisticdecisionmaking.org.