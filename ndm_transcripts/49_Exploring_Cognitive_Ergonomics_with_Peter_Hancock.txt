[Music]
The Naturalistic Decision Making podcast with Brian Moon and Laura Millatello. This podcast series brings you interviews with leading NDM researchers who study and support people who make decisions under stress.

[Music]

**Brian:** Welcome to the Naturalistic Decision Making podcast. This is Brian Moon from Paradigm Technologies.

**Laura:** And I'm Laura Millatello from Applied Decision Science. Today, we welcome Peter Hancock. Peter is Provost Distinguished Research Professor in the Department of Psychology and the Institute for Simulation and Training, as well as the Department of Civil and Environmental Engineering, and the Department of Industrial Engineering and Management Systems at the University of Central Florida. Professor Hancock is the author of more than 1,000 refereed scientific articles, chapters, and reports. He has written and edited more than 20 books, including the recent titles, Hoax Springs Eternal: The Psychology of Cognitive Deception, and Transports of Delight: How Technology Materializes Human Imagination. In addition to his over 1,000 publications, Dr. Hancock has also made over 1,000 professional presentations on issues as diverse as human machine interaction, psychological deception, and the history of the reign of Richard III. He has been continuously funded by extramural sources for every one of the 38 years of his professional career. This includes support from NASA, the National Science Foundation, the National Institutes of Health, the National Intelligence Agency, the FAA, the Federal Highway Administration, the Nuclear Regulatory Commission, Darpa, and all the branches of the US Armed Forces. Among his many awards, in 2009, he was named University Pegasus Professor of the University of Central Florida. This represents one of the highest awards at UCF, which is now the second largest single university in the United States. Welcome Peter. Thank you for joining us.

**Peter:** Ah, my pleasure, Laura and Brian, great to see you and yeah, those supposed accolades sound like barnacles on an old ship to me that's slowing down. So, yeah, it's nice to put in the record, but be even better to be young and ready to go again. Anyway, I'm here today and I'm looking forward to it.

**Laura:** Wonderful. Well, we are too. One of my favorite parts of these podcasts is finding out how people got started. So I wanted to ask if you can remember the very first thing you ever published and tell us about that.

**Peter:** I can, but it also leads to a sort of a brief story. I went back to do my master's degree at Loughborough University in England, and Loughborough is very well known for ergonomics, but I didn't go back for ergonomics, I went back to do human biology, and so I was very much interested in physiological systems and sort of feedback models of physiological systems, but it turned out that the human biology common room, which I and my colleagues occupied, sat next to the ergonomics common room, which some other students occupied, and it was only a small barrier, so I got to listen to the ergonomes as they recalled over the top of the barrier and I had listened to some of the conversations and thought, well, that that's extremely interesting. I don't know if that's not more interesting than what I'm doing. So, I sort of I sort of interacted quite a bit with those folks when I was there and so when I came to the US and started work with the opportunity to do human factors at Illinois with with folks like Mike Coles, Chris Wickens, Jack Adams and outstanding people, I was I felt right at home there. My first ever paper was from my Master's thesis, and it was on a feedback model of temperature regulation under extremes of stress. You wouldn't get it past an IRB today. I had three international athletes and I felt quite free to run them into the ground to almost utter exhaustion now. Imagine pedaling at marathon speed for something like four hours in conditions that probably don't exist except in some very strange Amazon forest, 100% humidity at 38 degrees centigrade and and watch people sweat off more than you could possibly imagine. It was great fun and it was good fun to test the model and and see where human beings didn't follow the model. And the model didn't actually predict exhaustion, but all of them actually sort of fell by the wayside in the end. So, things we can't do today, good old IRBs.

**Laura:** So you had a model and you were testing it, like does this really work?

**Peter:** Uh, yeah, exactly. There were at the time, this was, oh gosh, this would be sort of middle 1970s, that that really dates you, but the the majority of the models what what are called passive models, but there had been a model developed which was more a more of an active feedback model by a research scientist. I think he was out of Yale, but I wouldn't swear to it. His name was Stallwich and so I took his model and I adjusted it for the conditions that I was interested in testing. And so I was able to look at that and see where the model actually fails and interestingly, if the model fails because the human is spontaneously more adaptable than the model would have predicted. So, the by the time they hit steady state, not that I did too many steady states, but by the time I hit steady state, the adjusted model did pretty well and and followed along the various temperature measures pretty well, but it was the first sort of 10, 15 minutes of adjustment that the human magnificently adjusts to very quickly and the model took its time to to reach some sort of steady state. Yeah. Professor Millatello, you are going deep into deep into history there. I mean, I'm I'm pretty sure that was well before Ronald Reagan was was shot. So, I'm sure many of the people listening won't even remember some of those things. 19th yeah, 1977, I think.

**Laura:** Yeah, so in the spirit of human interest and history, I think you told me once that you were an athlete.

**Peter:** Yes, in fact I was talking to some folks here, my some of my colleagues at UCF. I was one of those individuals who was pretty darn good at almost everything, but I was outstanding at nothing. And so one of the great problems with that in terms of sports is I could always be sort of number six out of 11 people chosen and keep my end up and sort of basically do pretty well and sometimes do have a good game or a good period of time, but I played with I interacted, I was on teams with people who who won gold medals, for example, and they would just not quite leave me in the dust because there were other people eating that dust, but I I would never get up level with them. So, for example, in my year at Loughborough University and I was there, one of my contemporaries was David Moorcroft, who was the first person to break 13 minutes for 5,000 meters and I think he came fifth in the Montreal Olympic Games 1500 meters. So, he was outstanding. He was world class. I wasn't. So, a little bit more than a little bit behind him on the on some races that occasionally took part in.

**Laura:** Okay. So, so you started out and you were very interested in human performance in this athletic context and then you overheard these ergonomists and got very interested in that. And so then I'm just going to fast forward to where we are now, and I know you have been thinking a lot recently about decision making and writing about it, and I wondered if you would tell us a little bit about how what you are doing now connects with or disagrees with naturalistic decision making.

**Peter:** Sure, that leaps across a good nearly half century in one go. That's that's what podcasts are for, right? So, so yeah, I mean, I'm working in association with folks on some supported work and it became very obvious that one of the questions was contrasting, for example, naturalistic decision making, which of course I I think I rightly associate with Gary's work and the foundational work that he he developed in this area and then sort of compare and contrast as it were with bounded rationality, which I sort of associate with Herbert Simon and this particular work has given me great opportunity to read back into both of those literatures. And one of the questions that of course I have is related to how artificial intelligence can be used to help augment human decision makers and of course, as I think one of your questions said, can it potentially sort of replace human decision making? And so that's a a particular challenge, but in the in the process of facing that challenge, I've come to a a belief that NDM and bounded rationality are actually sort of almost like two faces of the same coin. There is no dissonance there. I think I was fairly strongly influenced by the paper with that wonderful title of failure to disagree. I think it's Kahneman and Klein or it might I might be correct, it might be Klein and Kahneman, but I I think they were perfectly correct. There is very little disagreement between there and I think instead of focusing on Danny Kahneman's sort of take on the area, which I think is more broad spread, I think I was induced to go back and look at Simon, obviously Sciences of the artificial, but the but the his notions obviously precede that sort of collective publication. I think Sciences of the artificial is around 1969, but I think you can trace some of his work back maybe even into the late 50s. And so I've been looking at it and what I've come to believe is that the foundational predicate of my idea is that it's something called biomimetic, and biomimetic is sort of really looking at natural, not naturalistic but natural sorts of processes. And I've come to believe that human beings do very well in the sort of the apocryphal open Savannah sort of environment where they're searching for within an environment certain critical cues. And and those emphasized sort of visual spatial abilities. And so we sort of scan across landscapes usually for critical signals or what we might sort of reasonably call solutions to our immediate problem. We might be searching for food, we might be searching for other things. But I tend to think that looking at the brain in the way it's passed, that the capacity of human beings to search those landscapes is particularly well developed. Now, my opinion has always been that nature doesn't bother to reinvent something once it's been invented something to work. And so what I've been thinking of is that decision making is rather similar to that, except instead of scanning across what might be a natural external environment, the decision maker is scanning across an internal cognate environment in which they are doing exactly the same thing, which is they're surveying a landscape of possibilities and then identifying what might be a a sufficient solution or what Simon called a satisficing solution. So, that was my foundation and then from there, I've come to a a notion that I call the SR Cube notion, which I think might be interesting if you guys want to explore that one.

**Laura:** Definitely. Yeah, I'd like to hear about it.

**Peter:** Okay, so let's take that landscape, cognitive or natural and suggest that the area to be searched can be small, medium or large. Just arbitrarily, we don't have to put physical bounds on it or even cognitive bounds on it. I believe of course, we could do in in games like chess or even go, we could find boundaries if we had to, but just considering sort of small, medium and large spaces to be searched. And then we can have sort of search rates that are slow, fast and medium between them. And so, what I think one of the critical elements is is that search rate. And by search rate, I actually mean a combination of the speed at which the search proceeds and the area to be searched itself. So obviously, something that's a very small area might be searched slowly and something that's a very large area might be searched much more quickly and one can titrate the two as it were to to be equivalent. And so I think search rate and how that's equated with other cognitive mechanisms is is really important. So search rate is the middle one of the SR3 combination. The last one, and I'm putting them in this order intentionally. I'm not taking them as they I believe they occur naturally, but the the last one, I think is not really polemic. It's a stopping rule, right? I mean, I think we're all used to stopping rules. And so one of the questions I think that is critical is what generates the characteristics of stopping rules. So, if I've got an artificial, and I use that term very specifically, if I've got an artificial problem, let's say 2 + 2, my stopping rule, when I hit four, my stopping rule is not only very confidently enacted, it's sort of like one was deterministically enacted. So, we've got a question there. Stopping rules in nature are much less well defined. And this is why I think Simon was so interested in satisficing, which is a sort of a nature of a stopping rule that says, I've got a solution which is good enough for me to work with right now. And I very much like that idea and I tend to think it's underwritten by both physical and cognitive energy or cognitive resources and physical resources and you're constantly asking yourself sort of like questions in economics, which is, okay, I could search some more, but what are my chances of getting a better solution? And so at some point, you hit this threshold of, I think it's the sort of principle of least effort actually, but you hit this threshold and it triggers the stopping rule. Now, I think in what Simon would have referred to as artificial problems, the game of chess or other formalized way of looking at human created situations, then we tend to know there is an answer and we tend to know if we're closer to it or not closer to it. But in natural conditions, we don't have that certitude. We sort of get to a point and go, okay, that works, right? So, thinking of it in a predator prey situation, if I can if I can run away and convince myself that the predator isn't chasing me anymore, I will both figuratively and literally sort of invoke the stopping rule. All very well. So search rate is the middle one, stopping rule is the last one, and we can explore these a little bit more and why what Gary has done and what Herbert Simon did before, actually are both reasonably described by this. But the first one, the ones that starts the sequence, which I've become more and more interested in, is the starting rule, right? The starting rule is the first SR of thing. And why do we start things? Why am I doing this today, for example? What what's my purpose? To see Professor Millatello and Dr. Moon most certainly. Those are those are critically important things and to discuss some of my work, that's great, but was the starting rule you contacting me or me deciding to say yes or me deciding, well, I can spend better time doing something else this afternoon. And so we tend to think of the searching, which is the sort of decision making landscape, and we tend to have looked at the stopping rules to some degree, but we have much less focus on why people start tasks. We sort of take that as given. So, let's take a military context. Let's take something like a air sea rescue mission. We we sort of believe that that is handed to us whole cloth as it were, we're we're going to do that, right? We don't sort of consider what are the original impetus that send us to those tasks because in some tasks which are artificial, the beginning is equally artificial. In some tasks that are natural, the imperative to do the challenges is less well defined. So, the reason I find human factors so interesting and so involving and so applicable is that in the challenges that we face ourselves, they're a combination of both natural challenges, navigating around the world, as for example, in air sea rescue, but they're also a combination of artificial challenges or what are formally called iatrogenic challenges, challenges that are created by the human and society that surrounds them. And the challenge can be artificial one or it can be a natural one or in human factors and particularly in relation to the application of NDM and bounded rationality, it's almost, I would say, almost dominantly the sort of human machine system situation, which then is difficult because you then have to parse out the two. So that's the general framework and I'm certainly able to respond and and say why. So, now bounded rationality in Simon's terms is basically the space that you choose to focus your search on. And so you can focus on a a narrow bounding, which means you will be able to search faster, but it may not include, and probably will not include the optimal solution. And then NDM, which is of course has always been linked towards things like expertise, high-level expertise, the speed of the search is extremely quick. And because again, the task is often what I've what I've then featured as artificial, that is it's known uh, because we have certain sort of obvious descriptive constraints around there, the search is extremely fast and almost seems to be, I won't say instinctual, but I will say that the one of the great things about expertise, especially the sort that Gary referred to very early in his work, is the speed at which they seem to respond. In fact, they respond so fast, it takes a lot of winking as we would say in England to get out the knowledge that they actually did do something. It was almost a spontaneous answer. So I think in those cases, the sort of search rate is extremely accelerated, but also experts are very good at bounding the search area in which they can find a sufficiently acceptable stopping rule to actually achieve it. And so I think the way I see it is bounded rationality might actually expand the area and is related to less well defined in terms of expertise, less well defined sort of capacities, but also I think the search rate itself, which I've got to say I think can be linked to other cognitive mechanisms, the search rate for NDM is extremely high and so high that we then begin to believe that there is something, I won't say magical about it, but I will say, it appears to be qualitatively different, but I really don't think it is. I think a single model can actually encapsulate both. And I do really like that paper failure to disagree and I think if Professor Klein and Professor Simon had been ever able to meet, I think they would have had a magnificent and explosive failure to disagree with each other there.

**Laura:** Gosh, so many interesting things in there. I'm going to jump in but I'm sure you have some comments too, Brian. So one thought I'm having as we're talking about speed is so it's not maybe this is related to the satisficing or the bounded rationality, but the consequences of taking time play a huge role in this, right? So if there's a burning building, you know you need to act quickly even if you can't find the very best answer. If you can save these people's lives, that's good.

**Peter:** Yep. But let me let me let me comment on that. You're perfectly correct and I've also in the work I've been doing, I've also emphasized, and I think we should emphasize, that not taking a decision is also a form of a decision. And so as you say, freezing or not doing something. One of the great problems I think we have Laura is that we often have this problem of hindsight bias, right? Is that in the moment, as it were, you take a decision which for all good reasons in that moment is the best that you think you can exercise. The problem I find with things like after action reviews, but particularly in litigation, is that that decision is so far expanded spatially and temporarily, only to be used in a as a form of blame, it becomes distorted to the degree it's just simply not helpful. And so the individual unless there are obvious sort of, let's say, medical, medical indications to the contrary, the individual is taking the best option that they can find at the time. Now, under that rubric that I talked about with natural situations, the thing we have to face, which human beings very rarely like to face, is there may be no answer. And by no answer, I mean there may be no way, if you're in a burning building and faced with certain circumstances, you can't get out and you can't get the people you were trying to rescue getting out. And that runs very, very counter to the human narrative and everything we see in Hollywood, where everything always works out all right in the end, and you're pretty sure that by reel three after the angst of the end of reel two, when everything goes wrong, you're pretty sure as the viewer, when you get there, that don't worry, it'll all be all right in the end, because they write the narrative like that, and that's the narrative we want to believe. I think there are many, many situations where human beings can't find a resolution, they will find something, but it doesn't necessarily lead to post- hoc success. And so I think Eric Hollnagel's work in the safety one, safety two realm is is useful because Hollnagel asks us to turn away a little bit from the sort of the almost the rubbernecking attraction to disasters and and start talking about the sort of normal behavior, which dominates and and why we succeed, may actually be a little bit different from the antithesis of why we fail. So I think your comment is right on, and time is always a critical arbiter in these, and if you know the clock is counting down, if Tom Brady is going to back to pass and there's less than a minute left and he's two touchdowns down, he's very aware of of those limitations and what he then has to do. But again, football is a human generated artificial challenge. A lot of the ones we face, especially in relation to military conditions, as the ones we are seeing now on the news, are certainly not as well bounded, and they're certainly not as well described and the solutions there are are sometimes extremely elusive.

**Laura:** Nice. Brian, did you want to jump in?

**Brian:** Sure. I know you do. As you say, there's a lot here. I'm kind of wondering also if you can help sort of tie this to the work that you do in terms of, it's well known that UCF is very much a leading university with regard to simulation-based training and and those sorts of applications. I'm wondering, are you exploring this kind of framework in simulation-based training or how how do you go about studying this framework that you're talking about?

**Peter:** Yeah, yeah, that's that's a good point. I would say Brian right now, I mean, I can look back in retrospect and fit some of the projects and sort of research supported programs that I've done, I can fit it in. I'm not personally doing so much of that myself anymore. We talked about exactly how old and creaky I am, and I think towards the end of your existence, at the certainly the end of your profession, you're probably more interested in the trying to encapsulate the bigger picture. That's not to say that my students don't, they certainly do. Some of my students have been working over with the US Navy, and in fact, my own daughter who is a now a tenured professor at Cal State Long Beach has been here with North CST on sabbatical and I think she's been working on those sort of things. So training, yeah, I think if you can begin to train, I think you would focus on the picture that I've given you is how to search faster and how to bound the space effectively more quickly. So if I can find a way of searching more quickly, and I think in naturalistic decision making that accrues from the fact that you are able to put together the interaction of a series of critical cues more quickly, that's the speed element. But if you can also bound the necessary search space, then you can get to a satisficing solution maybe in time in a time critical situation. And I'm tending to think that this is not unallied to what James J Gibson called affordances, and even though those ideas of direct perception and indirect decision making or cognitive decision making, don't sit well alongside each other theoretically, I think there ought to be efforts to try and integrate them together. So how is it that somebody is able to see the solution? I I would go back to the idea of I know there's a interesting paper by Chase Chi and Feltovich at the base of this sort of some of this this work. And of course, they I think they were at Carnegie Melon and Simon was at Carnegie Melon and it seems that with practice you can become an expert chess player not only just sort of recognizes the position, but recognizes the potential opportunities. So I think that's the sort of thing I would train. I would also say that you should design things in relation to doing that. One of the things that I've recently written on for our journal, Human Factors Journal, is and and you do get more attracted to these larger questions is, why as rational, I use that in inverted commas, why as rational sort of people, we don't react to the existential threats that we have. And I've come to believe more and more that one of the reasons we don't is it's not directly in front of us. Today you, I and Laura are sitting in pretty nice places. We are not, for example, aware that you're losing somewhere in the region of square miles of the seafloor almost every day, because we're not at the bottom of the seafloor and we don't see that, literally see it. And so I think there's a very great advantage of rendering the problem space into a visual space. So if I'm answering your question about simulation and training, I would try to render the problem space as being a visual representation that's directly and immediately perceivable, and then maybe the affordance structure becomes an obvious one at that point. So out of sight, out of mind is a great problem for existential problems. I don't face the problem of of lack of water or lack of food and I can't constantly keep it in front of me, even though I know it's aware there, I'm aware of it cognitively, but in terms of direct perception, it's not there. If it was, maybe I would react to that problem because I'm immediately seeing it and maybe then I get some answers. So in answer to your question, I think we need representational spaces. I think we need to provide those not only in training, but also in the actual performance itself. So in my view, simulation and training will slowly but surely meld into a sort of augmented real-time augmented reality assistance system. I don't think we'll stop, take people out, put them in a simulator, try to replicate the environment, then try to find implications and sort of inductions that we can draw from there. I think we will have both of those happening at the same time and fairly soon. I think the technology is gallops along at an incredible rate. And so I'm pretty sure that is what you'll see. So it'll be, it won't be serial team training, it won't be block training, it'll be real-time augmentation as you're doing it and and rightfully so. You may be able to get the sort of the matrix instant expertise notion, although you had a question about that and I thought it was a very interesting one. I've been thinking about it ever since I read that.

**Laura:** Okay, I don't want to go too deep, but I just want to go back a little bit to the discussion of the search space. So, the NDM community talks about recognition prime decision making quite a bit and this notion that if you are an expert, there are a lot of situations where you just recognize this is familiar, and based on that, you know what cues to pay attention to, you know what to expect, you know what a reasonable goal is in this situation and you kind of know what to do. So, there's no real search. What do you think about that notion? Does that?

**Peter:** Well, there there there is search, but it's at such a speed that you don't recognize it as search. I mean, the concantation of a pattern of cues is so familiar that the search happens, I'm almost tempted to say sort of below conscious attention. I think also what you find is, I really like one of the original vignettes that Gary brought up, I think with firefighters where the guy said, I just knew there was something wrong. I mean, I think that's the idea of not declarative conscious knowledge, it's just the pattern of cues has told this guy, do this and do it now to get out. Of course, one of the problems with things like that is we don't get to interview the people who aren't successful. So, we don't get to talk to people who say, well, I was searching for, you know, a pattern, but my expertise didn't allow me to identify it. So, again, there are limitations, natural limitations to what we can access because we always access those successful people. And indeed, you can argue, maybe that's why they're exceptional experts. But I think what I'm saying Laura is that there is, but because they bound the search space so well, because of their expertise, because they're able to search so quickly, it's now no longer a sort of a conscious thing as I would do if I'm doing I'm a beginner, I'm having a game of chess, I'm going, well, what happens if I move here and then he moves there? What happens if he does that and I do this? So you're going through all those logical sort of situations, whereas a grandmaster, an international grandmaster looks at it, and because of that recognition, makes the move and we all turn around and go, we sit back and wonder going, hey, how did you possibly do that? But by narrowing the search space and that speed of recognition, it just looks qualitatively different. And I don't think it is qualitatively different. I think it's just the quantitative difference in speed and bounding is the thing that makes it appear to be qualitatively different, which is why in terms of science, which is why we give it different names and why we compare and contrast the two. But as I say, I think there is an integrative resolution, certainly to those two approaches, if not some others.

**Laura:** Nice. Okay. Yeah, interesting. So if people are interested in this, have you have you published about this yet?

**Peter:** No, not yet. So stay tuned. Stay tuned. Well, yeah, I mean, stay tuned, but just not to go too deeply into it. But this is work I'm doing with a an organization and in reality, you know as well as I know there are sort of rules and restrictions about what you can and can't do in such things, but the organization I'm working with is extremely supportive and they're really good people and I know that this will sort of soon, hopefully soon appear. I'm really not sure where it should appear. The problem with me is I tend to write very discursively and as some reviewers have told me recently, I tend to write mostly for myself. I tend to use long words and Romontade when they want simple things and I don't want those anymore. So that's a compromise I have to search for in order to get it into into the appropriate location. But again, looking at some of the precedents, it's very interesting as you're very aware that sometimes when you have something as innovative as NDM, it just doesn't seem to fit very well or doesn't get ready acceptance in major, major journals, which can be a very very conservative in what they want to have within their own region of of interest. So, I think it's unfortunate that a lot of the major work in NDM, I think, sort of appears in in journals designed for it as opposed to sort of the absolute major journals in in some areas. So, again, that's a frustration I'm sure that Gary Klein faced himself. I'm sure it's a frustration that Dave Woods and other people in parallel sort of areas have faced and we are somewhat high-bound in what we will accept and of course eventually if the the movement is strong enough and informative enough, then it gets to be mainstream and then they chuck out the next innovation as well. So, plus ca change, plus c'est la même choses as our good French colleagues will say.

**Brian:** So I have a question along that line. I've seen you operate in public at HCPs conferences. You are not shy. You are quite pleased to take over the room with insightful comments. You're also though a university-based researcher and have been for most of your career. We went through your publications lists and you obviously produced a lot. But I'm curious if there was a sort of a point in your career where you sort of stepped back and said, I have something I want to say and I don't hear people saying the same sort of thing. I have a statement I want to make or, you know, I'm seeing something a lot differently than other people, where you sort of stepped out into the four, if you will, and sort of became a bit more vocal about your perspectives. I mean, you're talking now about, you know, a framework that is advancing and in some ways critiquing, in some ways building on prior sort of, you know, heavy work. So I'm just curious if for you personally, was there a point in your career or maybe points in your career where you decided to sort of step out and be a bit more outspoken or be a bit more forceful with your perspectives?

**Peter:** Yeah, I think that's a very, very good point, Brian. When you said I've seen you operate in public, I wondered what was going to come in the next sentence, but I I thank you for there. My daughter was trying to express to me what imposter syndrome was and I said, what? And she said, yeah, naturally. So, I think if you want my most critiqueful individual, you should access her. Your point is very well taken. So let me let me put it in a little story. We had a dog in our family and who got to be rather old. I think he was 16 years old and about when he got to the age of something like 15, he we we didn't allow him in the bedroom because my wife didn't want dog in the bedroom. And then about 15 years of age towards the end of his existence, we would find him in the bedroom quite often curled up in the corner and I I think he'd sort of said to himself literally, hey, I'm too old, I just don't care anymore. I don't I don't care what they're going to do. And I think you do get to that point in your own career and I I would hate to think I'm over the top of being the sort of the curmudgeons. It's a very strange world to go from Anfa to to aging curmudgeon without going through the middle part. But yes, certainly, I mean, we all have a limited lifespan and I think you've got to come out and say those things. And I think it's very fair that we try to engage in those in in our community and outside and I think you'll find Brian that if you look, I'm much more associated with panels in the last maybe 10 years in my work and I I would say one of the things I've probably left off reporting experimental data, although, as I say, my lab collects it, but I think you're perfectly correct. The larger issues and also explaining your own position, I I think are fine. I think looking objectively, I probably am a little more fond of my own voice than I ought to be, and I think the word bombast has been brought up on some occasions and it would be foolish if we didn't know ourselves under those circumstances. But the interesting thing is I do listen quite a lot. I know people think that more comes out than goes in, but not. And I personally I found the sort of the last, I would say, eight months of being able to go back and have the privilege to go through and read people's, what I think is foundational and really, really fascinating work has been a great thing for me. So, yes, I think that's true. I think you can go a number of ways. I think you can become very jaundiced, you can disengage. I've seen that happen within our community and beyond our community, and you can argue that it's false optimism to try to keep doing that in the face of what I've written about as being really quite prohibitive challenges. And as I said to Laura when we began the, the first thing I did was how people react in extremes of heat. So, I'm very aware of what a heating world will do to us and that won't be good. So, I do feel that and I also feel it's an obligation a little bit. I've been very lucky across my career. People have supported me, I'll correct up Laura just a little bit. I've had 41 years in academics and 41 years of external support. So, in some ways, the the tax dollar has supported me and and enabled me to do all those things. So, there is a bit of a sense of paying back that you should do at that point. As I contemplate things like retirement, I often wonder to myself, what else would I do if I retired? And I I'm pretty sure I would do the same sort of thing. So, I'm not there yet, but it's been very salutary for me to note that several of my colleagues and peers have uh I won't say down tools, but they've moved away from the immediate coal face of action. And so I have to be cognizant of what other people are doing in in my peer group as well. So, I've been thinking of those things Brian, but as long as I can entertain you in public and exchange some hot air, I think I'll try to keep going at least till the end of the week. Deal.

**Laura:** Wonderful. So I wanted to ask if you you kind of reflect back on your career, is there one project that really stands out to you as particularly fulfilling that's you're really proud of? This is this is work that really mattered.

**Peter:** Yeah, I did read that and I I sort of thought back. Obviously, there are a variety of examples and some of them are somewhat well known and but this one isn't particularly well known, but I was very proud of it because it meant I had to get over the top of a variety of technical methodological issues. So the question that tried to face was what happens to people and their control behavior in the last one or two seconds before you have a collision? And you can imagine that like we talked about earlier about expertise, you can imagine it's very, very difficult to examine experimentally. No IRB is going to let you collide two people together in vehicles, however well strapped they are and whatever demolition derby. I mean, demolition derby is fine, but it it doesn't go for head-on collisions too often. So, that's a real question. How do you put somebody in a very realistic collision likely condition and then examine their behavior and what they do? And then more importantly, what they probably ought to do to avoid collision. So, this was work done at the University of Minnesota and we created, not specifically for this, but it was part of our lab facility. We had two full vehicle simulations. That is two full vehicles and in one case a completely wrap around screen, one 360 degrees and then the other case something like 180 degrees. And so you have two simulators, now what are you going to do? So now what you've got to do is you've got to put people in a common environment, a common virtual environment. And that doesn't sound too problematic now, but this was 1992-ish, no, sorry, this is about 19, 1999. And so now you've got to create a common model, which runs a common model between the two simulations. Then you've got to do all the sort of coloring, the lovely texturing and whatever, and you it all has to happen in real time. You can't drop below something like 33 hertz and we we were trying to get to 60 as a mutual environment. So, we I had computer science kids crawling all over our lab. We had two Harris 4408 Nighthawk to do the computation. We had a wonderful Silicon Graphics engine. These will now sound like things in the museum and Hall of Fame, but they were really top of the line at the time and so we created those environments, but we got the latency down below where we thought was acceptable and certainly well below 33. But now what are you going to do? So now you have to what do you say to somebody? I'm bringing you into the lab in order for you to have a collision? Well, that's no good because you've already given them the answer, right? So, in other words, what you're looking at is literally a one shot trial. And now it's not only one person, you've got two people, you've got to coordinate. So, one person came in one end of the lab, which they never saw anybody else, they just went into their simulator, and the other driver came in the other end of the lab, and they didn't see anybody else, they got in their simulator. So, they weren't aware that there was anybody else in the world or in the virtual world they're in. Now, you've got two people in a virtual world, great, that's fun. Now, how are you going to make them have a collision, right? You can't have them drive around the world just pretending they might have a collision. So, I think we did something really cute and I'm very pleased with it. We created an environment where there was a hill, and what we did by a series of sort of interesting software jiggery pokery, we brought them both to the top of the hill, sorry, the bottom of the hill on either side sitting at a red light. And when the person got there, we then could let them go and let them go over the top of the hill, and we could control the curvature of the hill, so we could control not their speed, but we could control the preview that they would have before they had a collision. Now, each person thought they were on a single direction road, they weren't because there was somebody coming at them, and they could choose different lanes, it wasn't a single lane highway. So you brought in two people and many of them didn't have a collision, they stayed on the respective right lane. So if the two of them stay on the right lane, they just pass each other by. And now you're done, okay? Now you got to throw those two people out and start again. So on occasions, and it we and we collected 60 pairs, we had a collision between the two, you've only got one trial, and the only instruction you have given them when they come in is drive safely. Those are the only instructions. So now you have people driving around the world as they should, in some ways it is simulation, no way to get over that, but you've now brought them into a collision likely situation and when the other vehicle comes over the top of the hill, in this case, you've got two subjects and you can track what they actually do. Now, we did have other configurations, but the hill one is probably the best because you can control the reveal so that you can control the preview time. And the answer is people should just turn right. So, if everybody who came at each other, let's say on a wrong way accident, just turn right and just maybe went into the curb, okay, would be all right, but people don't. And so that was work that I did with a student from psychology, uh, Selma de Ridder, who was originally a student came from the Netherlands, and was published in ergonomics and I think it's been cited sort of 30, 40 times, but I think it's much more valuable than that. The only comparable one I'm still aware of, although I don't track the literature probably as I should is some interesting work by Dan McGee at the University of Iowa. Dan did something of a similar situation because Iowa obviously has preeminent facilities and they were able to do that. So I think of all the things, maybe if that had been put into a greater dissemination, it it might have helped just save people's existence, which I think is one of the obligations that we we ought to have. That's not to say I haven't had lots of fun with lots of other things that have had some impact to a degree. On good days, you think you've had an impact, on bad days, you get more realistic about it. But anyway, you try and you keep trying. So that that was the project, I think, and one of the projects I think I'm most proud of.

**Laura:** Nice. And so I think you were saying you were a little disappointed that it didn't get more publicity, that it didn't get applied. Is that right? Or?

**Peter:** Yeah, I I mean it for me it brought fortune and glory as Indiana Jones would say, right? I did it it did win the IEA medal, which is it had to win the IEA prize for the year, and then I think it won the 2003 IEA medal, which is held once every triennial Congress and and so it sort of got some boost from that. But no, I I don't see it referenced in the transportation community as much as I would like, but that's sort of somewhat beyond my capacity. Although, my students often send out things to people to put things in their hands. I'm sure that's annoying as well.

**Brian:** But it's one of those great examples too where, you know, the research we do in our community could have vast effects on the world. We don't ever train teenagers how to crash or really how to avoid crashes, right? We never put them in those circumstances. And you're offering a prototype of a way to do that and but it doesn't see the light of day.

**Peter:** Yeah, you're right. I mean, independent of me, you're you're perfectly correct. I mean, when you actually are driving, we teach them as you say, how to get from origin to destination. But in reality, our greatest fear is that they will be involved in a collision, and a serious collision, and a really bad outcome. So, that's what you ought to be teaching. I mean, not hands at 10:02 on the steering wheel, although that might be laudable for control purposes, but it's what you do in those situations. And interestingly, Brian, I think that's perfectly correct because when you look at beginners, as we've been talking about, beginners versus experts, the beginners are still searching for the pattern. And so you see a lot of over over representation of collisions in teenagers because they're still searching for the pattern. As you say, they might never have ever had a close shave before they have a serious accident. And I've had some close shaves, I'm sure you have, and I I'm sort of like, oh, I I know what I'm going to maybe look for next time. So, again, the subject of expertise and decision making raises itself yet again, and the application of the knowledge that the community generates, as you say, is much more important than the public recognition that is given. And I'm looking at that dissonance exactly right now. I think it's to do with an area I've called naive realism. It's to do with what people believe they know and understand versus what is actually the case. So, I'm trying to find out why human factors or HSI or whatever the name you want to put out there, is not really right to the forefront of public consciousness, when as you rightly point out, so many issues come back to that sort of interaction.

**Laura:** This is another fascinating topic, but sadly, we are just about out of time. So, I wanted to ask just one sort of fun question here at the end. If you could instantly become an expert in something, you don't have to train, nothing, you're just instantly an expert, what would it be?

**Peter:** The answer to that is nothing. I've thought very long and hard about your question. I've thought ever since I received it, the journey is the thing, right? I don't want the knowledge for the sake of the knowledge itself, I want the journey that allows me to understand and integrate with things. So even if I could get into the helicopter and Tanc could give me the immediate information, that that might be of momentary sort of utilization. I'm sure I can think of lots of things where I'd love to be sort of able to do something, wouldn't it be nice to stand up and be a a concert violinist just to impress your friends, but I think it is the journey itself. And so I think in the same way that science is not a static arrival, it is the process of there. And maybe I'll link it back one more time, which is that expertise is a progressive exposure and search. And I think it is the journey that gave that. You rightly point out, of course, though, it would be fabulous to walk up to the front of an airplane that had been somehow badly damaged and be heroic and jump into the controls and land safely. All all of those things appeal back to the human narrative of the hero, but now I'm sitting thinking about it and going, well, if you could actually do that, you could do it for almost everything, wouldn't you? Then my wife would have me cooking tonight and so I'm going I'm going to let that one go. But I really appreciate you having me here today. It's been lots and lots of fun. I've certainly been more than happy to come back and even try to get through to Brian's application, which I apologize for not being able to do.

**Laura:** Well, this has been so much fun. Thank you. Yeah, we really really enjoyed it. So, for the NDM podcast, I'm Laura Millatello.

**Brian:** And I'm Brian Moon. Learn more about Naturalistic Decision Making and where to find us by visiting Naturalistic Decision Making.org.

[Music]